{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pennylane as qml\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch.utils.tensorboard.writer.SummaryWriter'; 'torch.utils.tensorboard.writer' is not a package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtensorboard\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mwriter\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mSummaryWriter\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpennylane\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mqml\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch.utils.tensorboard.writer.SummaryWriter'; 'torch.utils.tensorboard.writer' is not a package"
     ]
    }
   ],
   "source": [
    "import torch.utils.tensorboard.writer.SummaryWriter\n",
    "import torch\n",
    "import pennylane as qml\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from qml_mor.models import IQPEReuploadSU2Parity\n",
    "from qml_mor.optimize import AdamTorch\n",
    "from qml_mor.datagen import DataGenCapacity\n",
    "\n",
    "torch.manual_seed(0)\n",
    "num_samples=1\n",
    "num_qubits = 3\n",
    "num_reups = 1\n",
    "num_layers = 1\n",
    "sizex = num_qubits\n",
    "\n",
    "datagen = DataGenCapacity(sizex=sizex, num_samples=num_samples)\n",
    "\n",
    "omega = 0.0\n",
    "init_theta = torch.randn(num_reups, num_qubits, requires_grad=True)\n",
    "theta = torch.randn(\n",
    "    num_reups, num_layers, num_qubits - 1, 2, requires_grad=True\n",
    ")\n",
    "W = torch.randn(2**num_qubits, requires_grad=True)\n",
    "\n",
    "params = [init_theta, theta, W]\n",
    "\n",
    "dev = qml.device(\"default.qubit\", wires=num_qubits, shots=None)\n",
    "\n",
    "model = IQPEReuploadSU2Parity(dev, params)\n",
    "\n",
    "X = torch.randn(10, 3)\n",
    "Ypred = model(X)\n",
    "\n",
    "print(Ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 1.189484261845844\n",
      "epoch: 1, loss: 0.5423136393775891\n",
      "epoch: 2, loss: 0.6503892819932726\n",
      "epoch: 3, loss: 0.7347527804931335\n",
      "epoch: 4, loss: 0.64403208723232\n",
      "epoch: 5, loss: 0.4944367531471815\n",
      "epoch: 6, loss: 0.3852144738352533\n",
      "epoch: 7, loss: 0.3602780605096297\n",
      "epoch: 8, loss: 0.3940922676079256\n",
      "epoch: 9, loss: 0.41731134734073255\n",
      "epoch: 10, loss: 0.3936982925091894\n",
      "epoch: 11, loss: 0.33862136715967883\n",
      "epoch: 12, loss: 0.28723191377490565\n",
      "epoch: 13, loss: 0.26524849639864545\n",
      "epoch: 14, loss: 0.27400147327648583\n",
      "epoch: 15, loss: 0.2925266469388939\n",
      "epoch: 16, loss: 0.29686600829585574\n",
      "epoch: 17, loss: 0.28009562707989194\n",
      "epoch: 18, loss: 0.25403021920357866\n",
      "epoch: 19, loss: 0.2356087233447096\n",
      "epoch: 20, loss: 0.23249534712322198\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 45\u001b[0m\n\u001b[1;32m     42\u001b[0m dataset \u001b[39m=\u001b[39m TensorDataset(X, Y)\n\u001b[1;32m     43\u001b[0m loader \u001b[39m=\u001b[39m DataLoader(dataset, batch_size\u001b[39m=\u001b[39mbatch_size, shuffle\u001b[39m=\u001b[39mshuffle)\n\u001b[0;32m---> 45\u001b[0m opt_params \u001b[39m=\u001b[39m opt\u001b[39m.\u001b[39;49moptimize(qnn_model, loader)\n",
      "File \u001b[0;32m~/Research/QC/qml-mor/qml_mor/optimize.py:145\u001b[0m, in \u001b[0;36mAdamTorch.optimize\u001b[0;34m(self, model, data)\u001b[0m\n\u001b[1;32m    143\u001b[0m pred \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack([model(batch_X[k], params) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(Nx)])\n\u001b[1;32m    144\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_fn(pred, batch_Y)\n\u001b[0;32m--> 145\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m    146\u001b[0m opt\u001b[39m.\u001b[39mstep()\n\u001b[1;32m    148\u001b[0m total_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem() \u001b[39m*\u001b[39m Nx\n",
      "File \u001b[0;32m~/anaconda3/envs/QML-MOR/lib/python3.10/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/QML-MOR/lib/python3.10/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pennylane as qml\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from qml_mor.models import IQPEReuploadSU2Parity\n",
    "from qml_mor.optimize import AdamTorch\n",
    "from qml_mor.datagen import DataGenCapacity\n",
    "\n",
    "num_samples=1\n",
    "num_qubits = 3\n",
    "num_reups = 1\n",
    "num_layers = 1\n",
    "sizex = num_qubits\n",
    "\n",
    "datagen = DataGenCapacity(sizex=sizex, num_samples=num_samples)\n",
    "\n",
    "omega = 0.0\n",
    "init_theta = torch.randn(num_reups, num_qubits, requires_grad=True)\n",
    "theta = torch.randn(\n",
    "    num_reups, num_layers, num_qubits - 1, 2, requires_grad=True\n",
    ")\n",
    "W = torch.randn(2**num_qubits, requires_grad=True)\n",
    "\n",
    "params = [init_theta, theta, W]\n",
    "\n",
    "model = IQPEReuploadSU2Parity(omega)\n",
    "dev = qml.device(\"default.qubit\", wires=num_qubits, shots=None)\n",
    "\n",
    "@qml.qnode(dev, interface=\"torch\")\n",
    "def qnn_model(x, params):\n",
    "    return model.qfunction(x, params)\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "num_epochs = 300\n",
    "opt = AdamTorch(params, loss_fn, num_epochs=num_epochs, amsgrad=True)\n",
    "\n",
    "N = 10\n",
    "batch_size=int(\"inf\")\n",
    "shuffle=True\n",
    "data = datagen.gen_data(N)\n",
    "X = data[\"X\"]\n",
    "Y = data[\"Y\"][0]\n",
    "dataset = TensorDataset(X, Y)\n",
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "opt_params = opt.optimize(qnn_model, loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4940, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0056, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "Nx = X.size(0)\n",
    "y_pred = torch.stack([qnn_model(X[k], opt_params) for k in range(Nx)])\n",
    "mre = torch.mean(torch.abs((Y - y_pred) / y_pred))\n",
    "\n",
    "print(mre)\n",
    "print(loss_fn(y_pred, Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1065, -1.6840,  0.0495],\n",
      "        [-2.0481,  0.0943,  1.3129],\n",
      "        [ 0.8609,  1.6568, -0.3898],\n",
      "        [-0.6508,  0.2920,  1.7724],\n",
      "        [ 0.0770, -0.4211,  0.1416]])\n",
      "tensor([-1.1391, -0.6884, -0.1555,  0.0701, -0.5088])\n",
      "===========\n",
      "2\n",
      "tensor([[-0.6508,  0.2920,  1.7724],\n",
      "        [ 0.0770, -0.4211,  0.1416]])\n",
      "tensor([ 0.0701, -0.5088])\n",
      "***********\n",
      "2\n",
      "tensor([[ 0.8609,  1.6568, -0.3898],\n",
      "        [-0.1065, -1.6840,  0.0495]])\n",
      "tensor([-0.1555, -1.1391])\n",
      "***********\n",
      "1\n",
      "tensor([[-2.0481,  0.0943,  1.3129]])\n",
      "tensor([-0.6884])\n",
      "***********\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "X = torch.randn(5, 3)\n",
    "Y = torch.randn(5)\n",
    "batch_size = 2\n",
    "\n",
    "dataset = TensorDataset(X, Y)\n",
    "shuffle = True\n",
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "print(X)\n",
    "print(Y)\n",
    "print(\"===========\")\n",
    "for X_, Y_ in loader:\n",
    "    print(X_.size(0))\n",
    "    print(X_)\n",
    "    print(Y_)\n",
    "    print(\"***********\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'X': tensor([[[-2.3104, -0.3733, -1.0608],\n",
      "         [ 0.9995, -0.8840, -1.2755],\n",
      "         [-0.6232, -0.8664, -1.2956],\n",
      "         [ 1.5236,  0.3237,  2.0177]],\n",
      "\n",
      "        [[ 1.1357, -1.2269,  0.0714],\n",
      "         [ 0.3380,  0.1535, -0.6333],\n",
      "         [-1.2609, -0.7270, -1.2655],\n",
      "         [-1.1195,  1.1665,  0.9262]],\n",
      "\n",
      "        [[ 0.7970,  0.2117,  0.1356],\n",
      "         [-0.0339, -0.3099,  0.2402],\n",
      "         [-1.3488,  0.2444, -0.0137],\n",
      "         [-0.1996, -1.6564,  0.9139]]], dtype=torch.float64), 'sigmas': tensor([[ 1,  1, -1,  1],\n",
      "        [-1, -1,  1, -1]])}\n"
     ]
    }
   ],
   "source": [
    "from qml_mor.datagen import DataGenRademacher, NormalPrior\n",
    "prior = NormalPrior(3, seed=0)\n",
    "radem = DataGenRademacher(prior, 2, 3, seed=None)\n",
    "data = radem.gen_data(4)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "101\n"
     ]
    }
   ],
   "source": [
    "num = 5\n",
    "bistring = bin(num)[2:]\n",
    "print(type(bistring))\n",
    "print(bistring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "QuantumFunctionError",
     "evalue": "The number of shots has to be explicitly set on the device when using sample-based measurements.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mQuantumFunctionError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[75], line 75\u001b[0m\n\u001b[1;32m     72\u001b[0m qnode \u001b[39m=\u001b[39m qml\u001b[39m.\u001b[39mQNode(iqpe_reupload_su2_meas, dev, interface\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtorch\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     73\u001b[0m \u001b[39m#drawer = qml.draw(qnode, expansion_strategy=\"device\")\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[39m#print(drawer(x, init_theta, theta, W))\u001b[39;00m\n\u001b[0;32m---> 75\u001b[0m probs \u001b[39m=\u001b[39m qnode(x, init_theta, theta, W, omega)\n\u001b[1;32m     76\u001b[0m probs\n",
      "File \u001b[0;32m~/anaconda3/envs/QML-MOR/lib/python3.10/site-packages/pennylane/qnode.py:847\u001b[0m, in \u001b[0;36mQNode.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    843\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_original_device()\n\u001b[1;32m    845\u001b[0m     \u001b[39mreturn\u001b[39;00m res\n\u001b[0;32m--> 847\u001b[0m res \u001b[39m=\u001b[39m qml\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    848\u001b[0m     [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtape],\n\u001b[1;32m    849\u001b[0m     device\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice,\n\u001b[1;32m    850\u001b[0m     gradient_fn\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgradient_fn,\n\u001b[1;32m    851\u001b[0m     interface\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minterface,\n\u001b[1;32m    852\u001b[0m     gradient_kwargs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgradient_kwargs,\n\u001b[1;32m    853\u001b[0m     override_shots\u001b[39m=\u001b[39;49moverride_shots,\n\u001b[1;32m    854\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexecute_kwargs,\n\u001b[1;32m    855\u001b[0m )\n\u001b[1;32m    857\u001b[0m \u001b[39mif\u001b[39;00m old_interface \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    858\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minterface \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/QML-MOR/lib/python3.10/site-packages/pennylane/interfaces/execution.py:651\u001b[0m, in \u001b[0;36mexecute\u001b[0;34m(tapes, device, gradient_fn, interface, mode, gradient_kwargs, cache, cachesize, max_diff, override_shots, expand_fn, max_expansion, device_batch_transform)\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[39mreturn\u001b[39;00m batch_fn(res)\n\u001b[1;32m    649\u001b[0m \u001b[39mif\u001b[39;00m gradient_fn \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbackprop\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m interface \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    650\u001b[0m     \u001b[39mreturn\u001b[39;00m batch_fn(\n\u001b[0;32m--> 651\u001b[0m         qml\u001b[39m.\u001b[39;49minterfaces\u001b[39m.\u001b[39;49mcache_execute(\n\u001b[1;32m    652\u001b[0m             batch_execute, cache, return_tuple\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, expand_fn\u001b[39m=\u001b[39;49mexpand_fn\n\u001b[1;32m    653\u001b[0m         )(tapes)\n\u001b[1;32m    654\u001b[0m     )\n\u001b[1;32m    656\u001b[0m \u001b[39m# the default execution function is batch_execute\u001b[39;00m\n\u001b[1;32m    657\u001b[0m execute_fn \u001b[39m=\u001b[39m qml\u001b[39m.\u001b[39minterfaces\u001b[39m.\u001b[39mcache_execute(batch_execute, cache, expand_fn\u001b[39m=\u001b[39mexpand_fn)\n",
      "File \u001b[0;32m~/anaconda3/envs/QML-MOR/lib/python3.10/site-packages/pennylane/interfaces/execution.py:206\u001b[0m, in \u001b[0;36mcache_execute.<locals>.wrapper\u001b[0;34m(tapes, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[39mreturn\u001b[39;00m (res, []) \u001b[39mif\u001b[39;00m return_tuple \u001b[39melse\u001b[39;00m res\n\u001b[1;32m    204\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    205\u001b[0m     \u001b[39m# execute all unique tapes that do not exist in the cache\u001b[39;00m\n\u001b[0;32m--> 206\u001b[0m     res \u001b[39m=\u001b[39m fn(execution_tapes\u001b[39m.\u001b[39;49mvalues(), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    208\u001b[0m final_res \u001b[39m=\u001b[39m []\n\u001b[1;32m    210\u001b[0m \u001b[39mfor\u001b[39;00m i, tape \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(tapes):\n",
      "File \u001b[0;32m~/anaconda3/envs/QML-MOR/lib/python3.10/site-packages/pennylane/interfaces/execution.py:131\u001b[0m, in \u001b[0;36mcache_execute.<locals>.fn\u001b[0;34m(tapes, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfn\u001b[39m(tapes: Sequence[QuantumTape], \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):  \u001b[39m# pylint: disable=function-redefined\u001b[39;00m\n\u001b[1;32m    130\u001b[0m     tapes \u001b[39m=\u001b[39m [expand_fn(tape) \u001b[39mfor\u001b[39;00m tape \u001b[39min\u001b[39;00m tapes]\n\u001b[0;32m--> 131\u001b[0m     \u001b[39mreturn\u001b[39;00m original_fn(tapes, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/QML-MOR/lib/python3.10/contextlib.py:79\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[1;32m     77\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds):\n\u001b[1;32m     78\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 79\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[0;32m~/anaconda3/envs/QML-MOR/lib/python3.10/site-packages/pennylane/_qubit_device.py:656\u001b[0m, in \u001b[0;36mQubitDevice.batch_execute\u001b[0;34m(self, circuits)\u001b[0m\n\u001b[1;32m    653\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreset()\n\u001b[1;32m    655\u001b[0m     \u001b[39m# TODO: Insert control on value here\u001b[39;00m\n\u001b[0;32m--> 656\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexecute(circuit)\n\u001b[1;32m    657\u001b[0m     results\u001b[39m.\u001b[39mappend(res)\n\u001b[1;32m    659\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtracker\u001b[39m.\u001b[39mactive:\n",
      "File \u001b[0;32m~/anaconda3/envs/QML-MOR/lib/python3.10/site-packages/pennylane/devices/default_qubit_torch.py:235\u001b[0m, in \u001b[0;36mDefaultQubitTorch.execute\u001b[0;34m(self, circuit, **kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[39mif\u001b[39;00m params_cuda_device \u001b[39m!=\u001b[39m specified_device_cuda:\n\u001b[1;32m    228\u001b[0m             warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    229\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTorch device \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_torch_device\u001b[39m}\u001b[39;00m\u001b[39m specified \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    230\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mupon PennyLane device creation does not match the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    231\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mTorch device of the gate parameters; \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    232\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_torch_device\u001b[39m}\u001b[39;00m\u001b[39m will be used.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    233\u001b[0m             )\n\u001b[0;32m--> 235\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mexecute(circuit, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/QML-MOR/lib/python3.10/site-packages/pennylane/_qubit_device.py:436\u001b[0m, in \u001b[0;36mQubitDevice.execute\u001b[0;34m(self, circuit, **kwargs)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[39m# generate computational basis samples\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshots \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m circuit\u001b[39m.\u001b[39mis_sampled:\n\u001b[0;32m--> 436\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_samples \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_samples()\n\u001b[1;32m    438\u001b[0m measurements \u001b[39m=\u001b[39m circuit\u001b[39m.\u001b[39mmeasurements\n\u001b[1;32m    439\u001b[0m counts_exist \u001b[39m=\u001b[39m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(m, CountsMP) \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m measurements)\n",
      "File \u001b[0;32m~/anaconda3/envs/QML-MOR/lib/python3.10/site-packages/pennylane/_qubit_device.py:1218\u001b[0m, in \u001b[0;36mQubitDevice.generate_samples\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1214\u001b[0m number_of_states \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_wires\n\u001b[1;32m   1216\u001b[0m rotated_prob \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39manalytic_probability()\n\u001b[0;32m-> 1218\u001b[0m samples \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msample_basis_states(number_of_states, rotated_prob)\n\u001b[1;32m   1219\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstates_to_binary(samples, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_wires)\n",
      "File \u001b[0;32m~/anaconda3/envs/QML-MOR/lib/python3.10/site-packages/pennylane/devices/default_qubit_torch.py:324\u001b[0m, in \u001b[0;36mDefaultQubitTorch.sample_basis_states\u001b[0;34m(self, number_of_states, state_probability)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msample_basis_states\u001b[39m(\u001b[39mself\u001b[39m, number_of_states, state_probability):\n\u001b[1;32m    312\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Sample from the computational basis states based on the state\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[39m    probability.\u001b[39;00m\n\u001b[1;32m    314\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[39m        List[int]: the sampled basis states\u001b[39;00m\n\u001b[1;32m    323\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 324\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49msample_basis_states(\n\u001b[1;32m    325\u001b[0m         number_of_states, state_probability\u001b[39m.\u001b[39;49mcpu()\u001b[39m.\u001b[39;49mdetach()\u001b[39m.\u001b[39;49mnumpy()\n\u001b[1;32m    326\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/QML-MOR/lib/python3.10/site-packages/pennylane/_qubit_device.py:1235\u001b[0m, in \u001b[0;36mQubitDevice.sample_basis_states\u001b[0;34m(self, number_of_states, state_probability)\u001b[0m\n\u001b[1;32m   1222\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Sample from the computational basis states based on the state\u001b[39;00m\n\u001b[1;32m   1223\u001b[0m \u001b[39mprobability.\u001b[39;00m\n\u001b[1;32m   1224\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1232\u001b[0m \u001b[39m    array[int]: the sampled basis states\u001b[39;00m\n\u001b[1;32m   1233\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1234\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshots \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1235\u001b[0m     \u001b[39mraise\u001b[39;00m qml\u001b[39m.\u001b[39mQuantumFunctionError(\n\u001b[1;32m   1236\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe number of shots has to be explicitly set on the device \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1237\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mwhen using sample-based measurements.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1238\u001b[0m     )\n\u001b[1;32m   1240\u001b[0m shots \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshots\n\u001b[1;32m   1242\u001b[0m basis_states \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(number_of_states)\n",
      "\u001b[0;31mQuantumFunctionError\u001b[0m: The number of shots has to be explicitly set on the device when using sample-based measurements."
     ]
    }
   ],
   "source": [
    "import pennylane as qml\n",
    "import torch\n",
    "from qml_mor.models import IQPEReuploadSU2Parity\n",
    "\n",
    "num_qubits  = 3\n",
    "num_reps    = 2\n",
    "num_layers  = 2\n",
    "omega       = 1.\n",
    "torch.manual_seed(0)\n",
    "x           = torch.randn(num_qubits, requires_grad=False)\n",
    "init_theta  = torch.randn(num_reps, num_qubits, requires_grad=True)\n",
    "theta       = torch.randn(num_reps, num_layers, num_qubits-1, 2, requires_grad=True)\n",
    "W           = torch.randn(2**num_qubits, requires_grad=True)\n",
    "\n",
    "params = [init_theta, theta, W]\n",
    "\n",
    "def iqpe_reupload_su2_parity(\n",
    "    x, init_theta, theta, W, omega: float = 0.0\n",
    "):\n",
    "    \"\"\"\n",
    "    Quantum function that calculates the expectation value\n",
    "    of the parity of Pauli Z operators.\n",
    "\n",
    "    Args:\n",
    "        x (Tensor): Input tensor of shape (num_qubits,)\n",
    "        init_theta (Tensor): Initial rotation angles for each qubit,\n",
    "            of shape (reps, num_qubits)\n",
    "        theta (Tensor): Rotation angles for each layer and each qubit,\n",
    "            of shape (reps, num_layers, num_qubits-1, 2)\n",
    "        W (Tensor): Observable weights of shape (2^num_qubits,)\n",
    "        omega (float, optional): Exponential feature scaling factor. Defaults to 0.0.\n",
    "\n",
    "    Returns:\n",
    "        QFuncOutput: Expectation value of the parity of Pauli Z operators\n",
    "    \"\"\"\n",
    "\n",
    "    shape_init = init_theta.shape\n",
    "    shape = theta.shape\n",
    "    if len(shape_init) != 2:\n",
    "        raise ValueError(\"Initial theta must be a 2-dim tensor\")\n",
    "    if len(shape) != 4:\n",
    "        raise ValueError(\"Theta must be a 4-dim tensor\")\n",
    "\n",
    "    num_qubits = len(x)\n",
    "    reps = shape_init[0]\n",
    "    wires = range(num_qubits)\n",
    "\n",
    "    for layer in range(reps):\n",
    "        features = 2 ** (omega * layer) * x\n",
    "        initial_layer_weights = init_theta[layer]\n",
    "        weights = theta[layer]\n",
    "\n",
    "        qml.IQPEmbedding(features=features, wires=wires)\n",
    "        qml.SimplifiedTwoDesign(\n",
    "            initial_layer_weights=initial_layer_weights,\n",
    "            weights=weights,\n",
    "            wires=wires,\n",
    "        )\n",
    "\n",
    "def iqpe_reupload_su2_meas(\n",
    "    x, init_theta, theta, W, omega: float = 0.0\n",
    "):\n",
    "    iqpe_reupload_su2_parity(x, init_theta, theta, W, omega)\n",
    "    obs = parities(len(x))\n",
    "    H = qml.Hamiltonian(W, obs)\n",
    "\n",
    "    return qml.sample()\n",
    "\n",
    "#qnn_model = IQPEReuploadSU2Parity(params, omega=1.0)\n",
    "\n",
    "dev = qml.device(\"default.qubit\", wires=num_qubits, shots=None)\n",
    "qnode = qml.QNode(iqpe_reupload_su2_meas, dev, interface=\"torch\")\n",
    "#drawer = qml.draw(qnode, expansion_strategy=\"device\")\n",
    "#print(drawer(x, init_theta, theta, W))\n",
    "probs = qnode(x, init_theta, theta, W, omega)\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 0],\n",
      "        [0, 0, 0],\n",
      "        [1, 1, 1],\n",
      "        [0, 0, 1],\n",
      "        [1, 0, 1],\n",
      "        [0, 1, 1],\n",
      "        [0, 0, 1],\n",
      "        [0, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1]])\n",
      "['110', '000', '111', '001', '101', '011', '001', '011', '111', '111']\n",
      "{'110': 1, '111': 3, '001': 2, '011': 2, '101': 1, '000': 1}\n"
     ]
    }
   ],
   "source": [
    "samples = probs\n",
    "bitstrings = [''.join(str(b.item()) for b in sample) for sample in samples]\n",
    "bitstring_counts = {bs: bitstrings.count(bs) for bs in set(bitstrings)}\n",
    "print(samples)\n",
    "print(bitstrings)\n",
    "print(bitstring_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1869, 0.1343, 0.0647, 0.0437, 0.0794, 0.0204, 0.3466, 0.1239],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>)\n",
      "  (0.19186942279338837) [I0]\n",
      "+ (0.3703935444355011) [Z0]\n",
      "+ (0.7748488187789917) [Z2]\n",
      "+ (0.9398099184036255) [Z1]\n",
      "+ (-1.5091077089309692) [Z0 Z2]\n",
      "+ (-0.8919953107833862) [Z0 Z1]\n",
      "+ (1.4565025568008423) [Z1 Z2]\n",
      "+ (-0.40334352850914) [Z0 Z1 Z2]\n"
     ]
    }
   ],
   "source": [
    "from qml_mor.models import IQPEReuploadSU2Parity\n",
    "\n",
    "model = IQPEReuploadSU2Parity()\n",
    "\n",
    "qnode = qml.QNode(model.probabilities, dev, interface=\"torch\")\n",
    "probs = qnode(x, params)\n",
    "print(probs)\n",
    "print(model.Hamiltonian(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110\n",
      "<Wires = [0, 1, 2]>\n",
      "1\n",
      "------\n",
      "110\n",
      "<Wires = [0, 1]>\n",
      "-1\n",
      "------\n",
      "110\n",
      "<Wires = [0, 2]>\n",
      "-1\n",
      "------\n",
      "110\n",
      "<Wires = [1, 2]>\n",
      "1\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "H = model.Hamiltonian(params)\n",
    "sum = 0.0\n",
    "b = \"110\"\n",
    "\n",
    "for idx, O in enumerate(H.ops):\n",
    "\n",
    "    if not isinstance(O.name, list):\n",
    "        if O.name == \"Identity\":\n",
    "            sum += H.coeffs[idx]\n",
    "        elif O.name == \"PauliZ\":\n",
    "            i = O.wires[0]\n",
    "            sign = (-1)**(int(b[-1-i]))\n",
    "            sum += sign*H.coeffs[idx]\n",
    "        else:\n",
    "            raise ValueError(\"All operators must be PauliZ or Identity.\")\n",
    "    else:\n",
    "        if not all(name==\"PauliZ\" for name in O.name):\n",
    "            raise ValueError(\"All operators must be PauliZ or Identity.\")\n",
    "        \n",
    "        sign = 1\n",
    "        for w in O.wires:\n",
    "            sign *= (-1)**(int(b[-1-w]))\n",
    "\n",
    "        sum += sign*H.coeffs[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([9.1056e-02, 1.1951e-02, 5.1757e-02, 1.0884e-02, 1.3633e-01, 3.6482e-02,\n",
      "        2.2475e-02, 9.7780e-03, 3.6049e-02, 7.9458e-02, 1.0691e-01, 3.5220e-03,\n",
      "        2.1416e-02, 2.7098e-01, 5.8704e-05, 1.1090e-01], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "tensor([0.3707, 0.6293], dtype=torch.float64, grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print(probs)\n",
    "marginal = qml.math.marginal_prob(probs, axis=[0])\n",
    "print(marginal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0.19186942279338837) [I0]\n",
      "+ (0.3703935444355011) [Z0]\n",
      "+ (0.7748488187789917) [Z2]\n",
      "+ (0.9398099184036255) [Z1]\n",
      "+ (-1.5091077089309692) [Z0 Z2]\n",
      "+ (-0.8919953107833862) [Z0 Z1]\n",
      "+ (1.4565025568008423) [Z1 Z2]\n",
      "+ (-0.40334352850914) [Z0 Z1 Z2]\n",
      "[PauliZ(wires=[0]) @ PauliZ(wires=[1]) @ PauliZ(wires=[2]), PauliZ(wires=[0]) @ PauliZ(wires=[1]), PauliZ(wires=[0]) @ PauliZ(wires=[2]), PauliZ(wires=[0]), PauliZ(wires=[1]) @ PauliZ(wires=[2]), PauliZ(wires=[1]), PauliZ(wires=[2]), Identity(wires=[0])]\n"
     ]
    }
   ],
   "source": [
    "from qml_mor.models import parities\n",
    "\n",
    "n = 3\n",
    "test = parities(n)\n",
    "H = qml.Hamiltonian(W, test)\n",
    "print(H)\n",
    "print(H.ops)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature layer\n",
    "def feature_layer(x):\n",
    "    num_qubits = len(x)\n",
    "    qml.IQPEmbedding(x, wires=range(num_qubits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variational layer\n",
    "def variational_layer(init_theta, theta, num_qubits):\n",
    "    qml.SimplifiedTwoDesign(initial_layer_weights=init_theta, weights=theta, wires=range(num_qubits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observable / output layer\n",
    "def sequence_generator(n):\n",
    "    if n == 0:\n",
    "        return [[]]\n",
    "    else:\n",
    "        sequences = []\n",
    "        for sequence in sequence_generator(n-1):\n",
    "            sequences.append(sequence + [n-1])\n",
    "            sequences.append(sequence)\n",
    "        return sequences\n",
    "    \n",
    "def parities(n):\n",
    "    \n",
    "    seq = sequence_generator(n)\n",
    "    ops = []\n",
    "    for par in seq:\n",
    "        if par:\n",
    "            tmp = qml.PauliZ(par[0])\n",
    "            if len(par) > 1:\n",
    "                for i in par[1:]:\n",
    "                    tmp = tmp @ qml.PauliZ(i)\n",
    "\n",
    "            ops.append(tmp)\n",
    "\n",
    "    ops.append(qml.Identity(0))\n",
    "\n",
    "    return ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pennylane.templates import IQPEmbedding, SimplifiedTwoDesign\n",
    "# QNN model\n",
    "@qml.qnode(dev, interface='torch')\n",
    "def qnn_model(x, init_theta, theta, W, omega=0.):\n",
    "\n",
    "    num_qubits = len(x)\n",
    "    shape_init = init_theta.shape\n",
    "    reps       = 1\n",
    "    if len(shape_init) < 1:\n",
    "        init_theta = [init_theta]\n",
    "        shape_init = init_theta.shape\n",
    "    reps       = shape_init[0]\n",
    "\n",
    "    shape_theta = theta.shape\n",
    "    reps_       = 1\n",
    "    if len(shape_theta) < 3:\n",
    "        theta       = [theta]\n",
    "        shape_theta = theta.shape\n",
    "    reps_       = shape_theta[0]\n",
    "\n",
    "    assert reps == reps_\n",
    "    for l in range(reps):\n",
    "        qml.IQPEmbedding(features=2**(omega*l)*x, wires=range(num_qubits))\n",
    "        qml.SimplifiedTwoDesign(initial_layer_weights=init_theta[l], weights=theta[l], wires=range(num_qubits))\n",
    "\n",
    "    obs = parities(num_qubits)\n",
    "    H   = qml.Hamiltonian(W, obs)\n",
    "\n",
    "    return qml.expval(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane.templates import IQPEmbedding\n",
    "\n",
    "n_wires = 3\n",
    "n_layers = 2\n",
    "\n",
    "dev = qml.device(\"default.qubit\", wires=n_wires)\n",
    "@qml.qnode(dev, interface='torch')\n",
    "def iqpe_circuit(features):\n",
    "    for layer in range(n_layers):\n",
    "        # Apply the IQPEmbedding template in a loop\n",
    "        IQPEmbedding(features=features[layer], wires=range(n_wires))\n",
    "\n",
    "    return [qml.expval(qml.PauliZ(wires=i)) for i in range(n_wires)]\n",
    "\n",
    "features = np.random.random((n_layers, n_wires))\n",
    "\n",
    "result1 = iqpe_circuit(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_qubits  = 3\n",
    "num_reps    = 0\n",
    "num_layers  = 0\n",
    "omega       = 1.\n",
    "x           = torch.randn(num_qubits, requires_grad=False)\n",
    "init_theta  = torch.randn(num_reps, num_qubits, requires_grad=True)\n",
    "theta       = torch.randn(num_reps, num_layers, num_qubits-1, 2, requires_grad=True)\n",
    "W           = torch.randn(2**num_qubits, requires_grad=True)\n",
    "\n",
    "result1 = qnn_model(x, init_theta, theta, W)\n",
    "result2 = qnn_model(x, init_theta, theta, W)\n",
    "\n",
    "ret = torch.stack([result1, result2])\n",
    "result1.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import qmc\n",
    "def generate_samples_r(d, S):\n",
    "    sampler = qmc.LatinHypercube(d=d)\n",
    "    r_samples = sampler.random(n=S)\n",
    "    return r_samples\n",
    "r = generate_samples_r(10, 2)\n",
    "print(len(r[0]))\n",
    "\n",
    "tmp = set()\n",
    "rng = np.random.default_rng(seed=0)\n",
    "b1 = tuple(rng.integers(0, 2, size=4))\n",
    "b2 = tuple(rng.integers(0, 2, size=4))\n",
    "tmp.add(b1)\n",
    "tmp.add(b2)\n",
    "print(tmp)\n",
    "arr = np.array(list(tmp))\n",
    "print(arr)\n",
    "arr[0, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Original list of tensors\n",
    "tensor_list = [torch.tensor([1., 2., 3.], requires_grad=True),\n",
    "               torch.tensor([4., 5., 6.], requires_grad=False)]\n",
    "\n",
    "est_params = [\n",
    "                        t.detach().clone().requires_grad_(t.requires_grad)\n",
    "                        for t in tensor_list\n",
    "                    ]\n",
    "tensor_list *= 2\n",
    "print(tensor_list)\n",
    "print(est_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = (f\"Stopping early\\n\"\n",
    "       \"Loss not improving\")\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the quantum device\n",
    "dev = qml.device(\"default.qubit\", wires=2)\n",
    "\n",
    "# Define the custom model as a PennyLane QNode\n",
    "@qml.qnode(dev, interface=\"torch\")\n",
    "def custom_model(x, y):\n",
    "    # Apply your quantum circuit here, which uses input x and trainable parameters y\n",
    "    # As an example, we'll use a simple circuit with one rotation gate parameterized by y:\n",
    "    qml.RY(y[0], wires=0)\n",
    "    qml.RX(x, wires=1)\n",
    "    qml.CNOT(wires=[0, 1])\n",
    "    return qml.expval(qml.PauliZ(1))\n",
    "\n",
    "# Define the dataset (x_data, y_data)\n",
    "x_data = torch.tensor([0.1, 0.2, 0.3, 0.4, 0.5], dtype=torch.float32)\n",
    "y_data = torch.tensor([0.5, 0.4, 0.3, 0.2, 0.1], dtype=torch.float32)\n",
    "\n",
    "# Initialize the trainable parameters\n",
    "params = torch.tensor([0.0], dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "# Set the hyperparameters\n",
    "learning_rate = 0.01\n",
    "epochs = 100\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam([params], lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    predictions = torch.tensor([custom_model(x, params) for x in x_data], dtype=torch.float32)\n",
    "    loss = loss_fn(predictions, y_data)\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")\n",
    "\n",
    "print(f\"Trained parameters: {params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_qubits  = 3\n",
    "num_reps    = 3\n",
    "num_layers  = 0\n",
    "omega       = 1.\n",
    "x           = torch.randn(num_qubits, requires_grad=False)\n",
    "init_theta  = torch.randn(num_reps, num_qubits, requires_grad=True)\n",
    "theta       = torch.randn(num_reps, num_layers, num_qubits-1, 2, requires_grad=True)\n",
    "W           = torch.randn(2**num_qubits, requires_grad=True)\n",
    "def qnn_model(x, init_theta, theta, W, omega=0.):\n",
    "\n",
    "    num_qubits = len(x)\n",
    "    shape_init = init_theta.shape\n",
    "    reps       = 1\n",
    "    if len(shape_init) < 1:\n",
    "        init_theta = [init_theta]\n",
    "        shape_init = init_theta.shape\n",
    "    reps       = shape_init[0]\n",
    "\n",
    "    shape_theta = theta.shape\n",
    "    reps_       = 1\n",
    "    if len(shape_theta) < 3:\n",
    "        theta       = [theta]\n",
    "        shape_theta = theta.shape\n",
    "    reps_       = shape_theta[0]\n",
    "\n",
    "    assert reps == reps_\n",
    "    for l in range(reps):\n",
    "        qml.IQPEmbedding(features=2**(omega*l)*x, wires=range(num_qubits))\n",
    "        qml.SimplifiedTwoDesign(initial_layer_weights=init_theta[l], weights=theta[l], wires=range(num_qubits))\n",
    "\n",
    "    obs = parities(num_qubits)\n",
    "    H   = qml.Hamiltonian(W, obs)\n",
    "\n",
    "    return qml.expval(H)\n",
    "\n",
    "result = qnn_model(x, init_theta, theta, W)\n",
    "print(result.shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = parities(3)\n",
    "for x in tmp:\n",
    "    print(type(x))\n",
    "    print(issubclass(type(x), qml.operation.Observable))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "num_qubits  = 3\n",
    "num_reps    = 3\n",
    "num_layers  = 0\n",
    "omega       = 1.\n",
    "x           = torch.randn(num_qubits, requires_grad=False)\n",
    "init_theta  = torch.randn(num_reps, num_qubits, requires_grad=True)\n",
    "theta       = torch.randn(num_reps, num_layers, num_qubits-1, 2, requires_grad=True)\n",
    "W           = torch.randn(2**num_qubits, requires_grad=True)\n",
    "\n",
    "print(qml.draw_mpl(qnn_model)(x, init_theta, theta, W, omega))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets for Capacity Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_dataset(N, samples=10, seed=0):\n",
    "    sizex   = num_qubits\n",
    "    scale   = 2.\n",
    "    shift   = -1.\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    x       = scale*torch.rand(N, sizex, requires_grad=False) + shift\n",
    "    y       = scale*torch.rand(samples, N, requires_grad=False) + shift\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model specs\n",
    "num_qubits  = 3\n",
    "num_reps    = 2\n",
    "num_layers  = 2\n",
    "omega       = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial parameters\n",
    "seed = 0\n",
    "torch.manual_seed(seed)\n",
    "init_theta  = torch.randn(num_reps, num_qubits, requires_grad=True)\n",
    "theta       = torch.randn(num_reps, num_layers, num_qubits-1, 2, requires_grad=True)\n",
    "W           = torch.randn(2**num_qubits, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "def square_loss(targets, predictions):\n",
    "    loss = 0\n",
    "    for t, p in zip(targets, predictions):\n",
    "        loss += (t - p) ** 2\n",
    "    loss = loss / len(targets)\n",
    "    return 0.5*loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# capacity estimation parameters\n",
    "Nmin     = 1\n",
    "Nmax     = 5\n",
    "samples  = 10\n",
    "steps    = 300\n",
    "eps_stop = 1e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = {}\n",
    "for N in range(Nmin, Nmax):\n",
    "    x, y = gen_dataset(N, samples)\n",
    "    \n",
    "    mre_sample = []\n",
    "    for s in range(samples):\n",
    "        print('===================================')\n",
    "        def cost(init_theta, theta, W):\n",
    "            pred = [qnn_model(x[k], init_theta, theta, W) for k in range(N)]\n",
    "            loss = square_loss(y[s], pred)\n",
    "            return loss\n",
    "        \n",
    "        # optimize\n",
    "        opt = torch.optim.Adam([init_theta, theta, W], lr=0.1, amsgrad=True)\n",
    "        for n in range(steps):\n",
    "            opt.zero_grad()\n",
    "            loss = cost(init_theta, theta, W)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            if n%10 == 9 or n == steps - 1:\n",
    "                print(f'{n+1}: {loss}')\n",
    "\n",
    "            if loss <= eps_stop:\n",
    "                break\n",
    "\n",
    "        # compute prediction errors\n",
    "        y_pred = torch.tensor([qnn_model(x[k], init_theta, theta, W) for k in range(N)], requires_grad=False)\n",
    "        mre    = torch.mean(torch.abs((y[s]-y_pred)/y_pred))\n",
    "        mre_sample.append(mre)\n",
    "\n",
    "    mre_N = torch.mean(torch.tensor(mre_sample))\n",
    "    summary[f'N = {N}'] = mre_N.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for count, eps in enumerate(summary.values()):\n",
    "    m = int(np.log2(1./eps.item()))\n",
    "    C = (count+1)*m\n",
    "    print(C)\n",
    "print(torch.numel(init_theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = [-0.5, 13.1, 2]\n",
    "max(C)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = torch.tensor([qnn_model(x[k], init_theta, theta, W) for k in range(N)], requires_grad=False)\n",
    "mre    = torch.mean(torch.abs((y[s]-y_pred)/y_pred))\n",
    "print(mre.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cutoff precision converted to bits of precision\n",
    "cutoff = np.sqrt(eps_stop)\n",
    "m      = np.log2(1./cutoff)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x)\n",
    "print(init_theta)\n",
    "print(theta)\n",
    "print(W)\n",
    "print(y[s])\n",
    "print(y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QML-MOR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "46e7eb4246c13550057ff7606884a772512028b1851bd0c4d2a0ba2e0c036465"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
