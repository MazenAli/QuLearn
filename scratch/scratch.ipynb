{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "import torch\n",
    "from qulearn.qlayer import AltRotCXLayer, HamiltonianLayer\n",
    "\n",
    "num_qubits = 3\n",
    "n_layers = 2\n",
    "wires = range(0, num_qubits)\n",
    "dev = qml.device(\"default.qubit\", wires=wires, shots=None)\n",
    "layer = AltRotCXLayer(wires, n_layers=n_layers, dtype=torch.float64)\n",
    "obs = [qml.PauliZ(0)]\n",
    "model = HamiltonianLayer(layer, observables=obs, qdevice=dev, dtype=torch.float64, interface=\"torch\", diff_method=\"backprop\")\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "y = torch.tensor([-0.25], dtype=torch.float64)\n",
    "drawer = qml.draw(model.qnode, show_all_wires=True, expansion_strategy=\"device\")\n",
    "print(drawer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "Z = np.array([[1, 0], [0, -1]])\n",
    "I = np.eye(2)\n",
    "matrices = [np.kron(np.kron(a, b), c) for a in [I, Z] for b in [I, Z] for c in [I, Z]]\n",
    "coefficients = np.random.rand(len(matrices))\n",
    "\n",
    "M = sum(matrices[i]*coefficients[i] for i in range(2))\n",
    "eigenvalues = np.linalg.eigvals(M)\n",
    "print(eigenvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "opt = Adam(model.parameters(), lr=0.1)\n",
    "opt.zero_grad()\n",
    "pred = model()\n",
    "loss = loss_fn(pred, y)\n",
    "loss.backward()\n",
    "opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawer = qml.draw(model.qnode, show_all_wires=True, expansion_strategy=\"device\")\n",
    "print(drawer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scalar2vector(x, L):\n",
    "    # Check if input is within the expected range\n",
    "    if not -1 <= x < 1:\n",
    "        raise ValueError(\"x must be in the range [-1, 1)\")\n",
    "    if L <= 0:\n",
    "        raise ValueError(\"L must be a positive integer\")\n",
    "    \n",
    "    # Initialize binary and remainder variables\n",
    "    binary = [0] * L\n",
    "    reference = 0.0\n",
    "\n",
    "    # Create binary variables\n",
    "    for i in range(L):\n",
    "        if x >= reference:\n",
    "            binary[i] = 1\n",
    "            if i < L-1:\n",
    "                reference += 0.5**(i+1)\n",
    "        else:\n",
    "            if i < L-1:\n",
    "                reference -= 0.5**(i+1)\n",
    "\n",
    "    # Adjust remainder\n",
    "    remainder = x - reference\n",
    "    remainder *= 2 ** (L - 1)\n",
    "\n",
    "    return (binary, remainder)\n",
    "\n",
    "def vector2scalar(binary, remainder):\n",
    "    L = len(binary)\n",
    "    sum = -1.0\n",
    "    for j, ij in enumerate(binary):\n",
    "        sum += 2.0**(-j)*ij\n",
    "        \n",
    "    sum += remainder*2.0**(1-L)\n",
    "    \n",
    "    return sum\n",
    "\n",
    "x = torch.tensor([0.8])\n",
    "L = 3\n",
    "vec = scalar2vector(x, L)\n",
    "orig = vector2scalar(*vec)\n",
    "print(x)\n",
    "print(vec)\n",
    "print(orig)\n",
    "\n",
    "if x < 0:\n",
    "    print(\"less than 0\")\n",
    "if x > 0:\n",
    "    print(\"larger than 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qulearn.qlayer import CircuitLayer\n",
    "import pennylane as qml\n",
    "\n",
    "class QTT1DEncoding(CircuitLayer):\n",
    "    \n",
    "    def __init__(self, wires, level):\n",
    "        super().__init__(wires)\n",
    "        self.level = level\n",
    "        \n",
    "    def circuit(self, x):\n",
    "        binary, y = scalar2vector(x, self.level)\n",
    "        \n",
    "        for index, b in enumerate(binary):\n",
    "            if b == 1:\n",
    "                qml.PauliX(self.wires[index])\n",
    "                \n",
    "        qml.RZ(0.0, self.wires[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qulearn.qlayer import CircuitLayer, AltRotCXLayer\n",
    "import pennylane as qml\n",
    "from pennylane import IQPEmbedding\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class Hadamards(CircuitLayer):\n",
    "    \n",
    "    def __init__(self, wires):\n",
    "        super().__init__(wires)\n",
    "        \n",
    "    def circuit(self, x):\n",
    "        for wire in self.wires:\n",
    "            qml.Hadamard(wire)\n",
    "\n",
    "class Exp1DEncoding(CircuitLayer):\n",
    "    \n",
    "    def __init__(self, wires):\n",
    "        super().__init__(wires)\n",
    "        \n",
    "    def circuit(self, x):\n",
    "        lrelu = torch.nn.LeakyReLU(0.01)\n",
    "        for j, wire in enumerate(self.wires):\n",
    "            x_ = torch.asin(lrelu(x))\n",
    "            x_ = lrelu(x)\n",
    "            x_ = 2**j*x\n",
    "            qml.RZ(x_.item(), wire)\n",
    "            \n",
    "class ParallelIQPEncoding(CircuitLayer):\n",
    "    \n",
    "    def __init__(self, wires, num_features, omega = 1.0):\n",
    "        super().__init__(wires)\n",
    "        self.num_features = num_features\n",
    "        self.omega = omega\n",
    "        \n",
    "        assert self.num_wires >= self.num_features\n",
    "        assert self.num_wires % self.num_features == 0\n",
    "        \n",
    "    def circuit(self, x):\n",
    "        num_features = x.shape[-1]\n",
    "        assert num_features == self.num_features\n",
    "        \n",
    "        freq = 0\n",
    "        for i in range(0, len(self.wires), num_features):\n",
    "            x_ = 2**(freq*self.omega)*x\n",
    "            qml.IQPEmbedding(x_, wires=self.wires[i: i+num_features])\n",
    "            freq += 1\n",
    "            \n",
    "class ParallelEntangledIQPEncoding(CircuitLayer):\n",
    "    \n",
    "    def __init__(self, wires, num_features, omega = 1.0):\n",
    "        super().__init__(wires)\n",
    "        self.num_features = num_features\n",
    "        self.omega = omega\n",
    "        \n",
    "        assert self.num_wires >= self.num_features\n",
    "        assert self.num_wires % self.num_features == 0\n",
    "        \n",
    "    def circuit(self, x):\n",
    "        num_features = x.shape[-1]\n",
    "        assert num_features == self.num_features\n",
    "        \n",
    "        num_repeats = int(self.num_wires/num_features)\n",
    "        \n",
    "        x_large = []\n",
    "        for j in range(0, num_repeats):\n",
    "            x_ = 2**(j*self.omega)*x\n",
    "            x_large.append(x_)\n",
    "            \n",
    "        x_final = torch.cat(x_large)\n",
    "        qml.IQPEmbedding(x_final, wires=self.wires)\n",
    "        \n",
    "\n",
    "class QuantumKernel(nn.Module):\n",
    "    \n",
    "    def __init__(self, embed, X_train):\n",
    "        super().__init__()\n",
    "        self.embed = embed\n",
    "        self.X_train = X_train\n",
    "        self.num_samples = X_train.shape[0]\n",
    "        self.alpha = nn.Parameter(\n",
    "            torch.empty(\n",
    "                self.num_samples,\n",
    "                device=self.X_train.device,\n",
    "                dtype=self.X_train.dtype,\n",
    "            )\n",
    "        )\n",
    "        nn.init.normal_(self.alpha)\n",
    "        \n",
    "        self.qdevice = qml.device(wires=self.embed.wires, name=\"default.qubit\", shots=None)\n",
    "        self.qnode = self.set_qnode()\n",
    "        \n",
    "    \n",
    "    def kernel_circ(self, x, x_):\n",
    "        self.embed(x)\n",
    "        qml.adjoint(self.embed)(x_)\n",
    "        state = torch.zeros(self.embed.num_wires, dtype=torch.int32, device=x.device)\n",
    "        projector = qml.Projector(state, self.embed.wires)\n",
    "        return qml.expval(projector)\n",
    "    \n",
    "    def kernel_matrix(self, x, x_):\n",
    "        # assert shape has length 2\n",
    "        \n",
    "        K = torch.empty((x.shape[0], x_.shape[0]), dtype=x.dtype, device=x.device)\n",
    "        for i, xi in enumerate(x):\n",
    "            for j, xj in enumerate(x_):\n",
    "                Kij = self.qnode(xi, xj)\n",
    "                K[i, j] = Kij\n",
    "        return K\n",
    "    \n",
    "    def kernel_ridge_regression(self, labels, lambda_reg) -> None:\n",
    "        # sets optimal alpha (closed form solution)\n",
    "        K = self.kernel_matrix(self.X_train, self.X_train)\n",
    "        I = torch.eye(self.num_samples, dtype=labels.dtype, device=labels.device)\n",
    "        M = K+lambda_reg*I\n",
    "        self.alpha = nn.Parameter(torch.linalg.solve(M, labels))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        K = self.kernel_matrix(x, self.X_train)\n",
    "        out = torch.matmul(K, self.alpha)\n",
    "        return out\n",
    "    \n",
    "    def set_qnode(self):\n",
    "        circuit = self.kernel_circ\n",
    "        qnode = qml.QNode(\n",
    "            circuit,\n",
    "            self.qdevice,\n",
    "            interface=\"torch\",\n",
    "            diff_method=\"backprop\"\n",
    "        )\n",
    "        self.qnode = qnode\n",
    "        return self.qnode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "class Test(Enum):\n",
    "    one = 1\n",
    "    two = 2\n",
    "    \n",
    "print(Test.one.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.tensor([[0.1]])\n",
    "x2 = torch.tensor([[0.2]])\n",
    "x3 = torch.tensor([[0.3]])\n",
    "x = torch.cat((x1, x2, x3), dim=1)\n",
    "print(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from qulearn.qlayer import ParallelEntangledIQPEncoding, ParallelIQPEncoding, MeasurementLayer, MeasurementType, IQPERYCZLayer, RYCZLayer\n",
    "from qulearn.qkernel import QKernel\n",
    "from qulearn.trainer import RidgeRegression\n",
    "import torch\n",
    "from torch.nn import MSELoss\n",
    "import logging\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "num_features = 2\n",
    "num_feature_repeat = 2\n",
    "wires = num_features*num_feature_repeat\n",
    "embed = ParallelEntangledIQPEncoding(wires, num_features=num_features, omega=1.0, n_repeat=2)\n",
    "var = RYCZLayer(wires=wires, n_layers=1)\n",
    "#embed = IQPERYCZLayer(wires=wires, num_uploads=1, num_varlayers=0, num_repeat=2, omega=1.0)\n",
    "#embed = ParallelIQPEncoding(wires, num_features=1, omega=1.0, n_repeat=2)\n",
    "obs = qml.PauliZ(0)\n",
    "num_samples = 10\n",
    "X_train = torch.randn((num_samples, num_features))\n",
    "labels = torch.randn((num_samples, 1))\n",
    "model = QKernel(embed, X_train)\n",
    "#model = MeasurementLayer(var, embed, measurement_type=MeasurementType.Expectation, observable=obs)\n",
    "drawer = qml.draw(model.qnode, show_all_wires=True, expansion_strategy=\"device\")\n",
    "x1 = torch.tensor([0.1, 0.3])\n",
    "x2 = torch.tensor([0.2, 0.3])\n",
    "print(drawer(x1, x2))\n",
    "\n",
    "# #test = model.qnode(x1, x2)\n",
    "# test = model.kernel_matrix(X_train, X_train)\n",
    "# print(test.shape)\n",
    "# print(test)\n",
    "\n",
    "# predicted = model(X_train)\n",
    "# fn = MSELoss()\n",
    "# loss_before = fn(predicted, labels)\n",
    "\n",
    "# lambda_reg = 1.0\n",
    "# metrics = {\"mse_loss\": fn}\n",
    "# logger = logging.getLogger(__name__)\n",
    "# logger.setLevel(level=logging.INFO)\n",
    "# trainer = RidgeRegression(lambda_reg, metrics, logger)\n",
    "# dataset = TensorDataset(X_train, labels)\n",
    "# train_loader = DataLoader(dataset, batch_size=num_samples)\n",
    "# valid_loader = DataLoader(dataset, batch_size=num_samples)\n",
    "# trainer.train(model, train_loader, valid_loader)\n",
    "\n",
    "# predicted = model(X_train)\n",
    "# loss_after = fn(predicted, labels)\n",
    "\n",
    "# print(f\"Loss before: {loss_before} | Loss after: {loss_after}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.randn((num_samples, num_features))\n",
    "model.X_train = X_train\n",
    "print(model.alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in model.named_parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qulearn.qlayer import HamiltonianLayer, AltRotCXLayer, IQPEmbeddingLayer\n",
    "import torch\n",
    "\n",
    "observables = [qml.PauliZ(0), qml.Identity(0)]#, qml.PauliZ(1), qml.PauliZ(2), qml.PauliZ(3)]\n",
    "wires = 1*3\n",
    "embed = ParallelEntangledIQPEncoding(wires, num_features=1)\n",
    "#embed = ParallelIQPEncoding(wires, num_features=1)\n",
    "varlayer1 = AltRotCXLayer(wires=3, n_layers=2)\n",
    "varlayer2 = AltRotCXLayer(wires=3, n_layers=2)\n",
    "model = HamiltonianLayer(varlayer1, embed, varlayer2, observables=observables)\n",
    "drawer = qml.draw(model.qnode, show_all_wires=True, expansion_strategy=\"device\")\n",
    "\n",
    "x = torch.rand((1, 2))*2.0-1.0\n",
    "x = torch.tensor([[-0.74]])\n",
    "y = model(x)\n",
    "print(y)\n",
    "x_ = x[0]\n",
    "print(drawer(x_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qulearn.qlayer import HamiltonianLayer, AltRotCXLayer, IQPEmbeddingLayer\n",
    "import torch\n",
    "\n",
    "observables = [qml.PauliZ(0)]#, qml.PauliZ(1), qml.PauliZ(2), qml.PauliZ(3)]\n",
    "#embed = QTT1DEncoding(wires=4, level=3)\n",
    "#embed = IQPEmbeddingLayer(wires=1, n_repeat=1)\n",
    "hads = Hadamards(wires=4)\n",
    "embed = Exp1DEncoding(wires=4)\n",
    "varlayer1 = AltRotCXLayer(wires=4, n_layers=2)\n",
    "varlayer2 = AltRotCXLayer(wires=4, n_layers=2)\n",
    "model = HamiltonianLayer(hads, varlayer1, embed, varlayer2, observables=observables)\n",
    "drawer = qml.draw(model.qnode, show_all_wires=True, expansion_strategy=\"device\")\n",
    "\n",
    "x = torch.rand((1, 1))*2.0-1.0\n",
    "x = torch.tensor([[-0.74]])\n",
    "y = model(x)\n",
    "print(y)\n",
    "print(drawer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "def fourier_series(x, n, c):\n",
    "    \"\"\"\n",
    "    Compute the truncated Fourier series evaluated at an input x.\n",
    "    \"\"\"\n",
    "    k = torch.arange(-n, n+1)\n",
    "    terms = c[k+n]*torch.exp(1j*k*x)\n",
    "    y = torch.real(torch.sum(terms, dim=1))\n",
    "    y = y/torch.max(torch.abs(y))\n",
    "    return y\n",
    "\n",
    "def generate_dataset(num_samples, n, c):\n",
    "    \"\"\"\n",
    "    Generate a dataset of random samples x with corresponding y values evaluated \n",
    "    at x using a truncated Fourier series.\n",
    "    \"\"\"\n",
    "    x = torch.rand(num_samples, 1, dtype=torch.float64)*2.0-1.0\n",
    "    y = fourier_series(x, n, c)\n",
    "    return x, y\n",
    "\n",
    "def get_data_loader(x, y, batch_size=5):\n",
    "    \"\"\"\n",
    "    Convert the dataset into a PyTorch DataLoader.\n",
    "    \"\"\"\n",
    "    dataset = TensorDataset(x.unsqueeze(-1), y.unsqueeze(-1))\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "    return dataloader\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "n = 10  # Number of terms in the Fourier series\n",
    "c_positive = torch.rand(n) + 1j*torch.rand(n)  # Random coefficients for positive k\n",
    "c_negative = torch.conj(c_positive)  # Coefficients for negative k are the conjugate of those for positive k\n",
    "c_positive = c_positive.flip(dims=[0])\n",
    "c_zero = torch.rand(1)  # Coefficient for k=0 is just a real number\n",
    "c = torch.cat((c_negative, c_zero, c_positive))\n",
    "\n",
    "# Generate a dataset and data loader\n",
    "x, y = generate_dataset(25, n, c)\n",
    "y = torch.where(x <= 0, torch.tensor(0, dtype=torch.float64), torch.tensor(1, dtype=torch.float64))\n",
    "dataloader = get_data_loader(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from qulearn.qlayer import MeasurementLayer, MeasurementType, IQPEAltRotCXLayer, HamiltonianLayer\n",
    "num_features = 3\n",
    "interface='torch'\n",
    "diff_method='backprop'\n",
    "qdev = qml.device(\"default.qubit\", wires=num_features, shots=None)\n",
    "circuit = IQPEAltRotCXLayer(wires=num_features, num_uploads=1, num_varlayers=1, num_repeat=3, omega=torch.tensor(0.0))\n",
    "obs = qml.PauliZ(0)\n",
    "model = HamiltonianLayer(circuit, observables=[obs], qdevice=qdev, interface=interface, diff_method=diff_method)\n",
    "drawer = qml.draw(model.qnode, show_all_wires=True, expansion_strategy=\"device\")\n",
    "x = torch.randn(num_features)\n",
    "print(drawer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from qulearn.trainer import SupervisedTrainer\n",
    "import logging\n",
    "opt = Adam(model.parameters(), lr=0.1, amsgrad=True)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "logger = logging.getLogger(\"SupTrainer\")\n",
    "logger.setLevel(level=logging.INFO)\n",
    "trainer = SupervisedTrainer(opt, loss_fn, num_epochs=50, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(model, dataloader, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qulearn.fat import fat_shattering_dim\n",
    "from qulearn.datagen import DataGenFat, UniformPrior\n",
    "prior = UniformPrior(sizex=num_features, seed=0)\n",
    "gamma=0.1\n",
    "datagen = DataGenFat(prior=prior, Sb=10, Sr=5, gamma=2.0*gamma, seed=0, batch_size=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = fat_shattering_dim(model, datagen=datagen, trainer=trainer, dmin=1, dmax=100, gamma=gamma, dstep=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qulearn.fat import check_shattering\n",
    "#check = check_shattering(model, datagen, trainer, 1, gamma=gamma)\n",
    "#print(check)\n",
    "print(dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dim)\n",
    "data = datagen.gen_data(1)\n",
    "loader = datagen.data_to_loader(data, 0, 1)\n",
    "for x, y in loader:\n",
    "    print(x)\n",
    "    print(y)\n",
    "print(data[\"b\"])\n",
    "print(data[\"r\"])\n",
    "print(0.07260766+gamma*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import symbols, Matrix, cos, sin, pi\n",
    "\n",
    "# Define a ParameterVector for theta\n",
    "n = 1  # Adjust this for the number of parameters you need\n",
    "theta = symbols('theta0:{}'.format(n))\n",
    "\n",
    "# Initial state |0>\n",
    "ket_0 = Matrix([[1], [0]])\n",
    "\n",
    "# Pauli Z matrix\n",
    "Z = Matrix([[1, 0], [0, -1]])\n",
    "\n",
    "# Define the Rz rotation matrix using the first parameter from theta\n",
    "Rz = Matrix([\n",
    "    [cos(theta[0]/2) - 1j*sin(theta[0]/2), 0],\n",
    "    [0, cos(theta[0]/2) + 1j*sin(theta[0]/2)]\n",
    "])\n",
    "\n",
    "# Apply the Rz gate to the initial state\n",
    "psi = Rz * ket_0\n",
    "\n",
    "# Compute the expectation value of Z\n",
    "expectation_Z = (psi.H * Z * psi)[0]\n",
    "\n",
    "expectation_Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-19 21:34:42.460940: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-19 21:34:44.123519: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2040\n"
     ]
    }
   ],
   "source": [
    "import pennylane as qml\n",
    "from qulearn.qlayer import AltRotCXLayer, ParallelEntangledIQPEncoding, ParallelIQPEncoding, MeasurementLayer, MeasurementType, IQPERYCZLayer, RYCZLayer, IQPEAltRotCXLayer, HadamardLayer\n",
    "from qulearn.qkernel import QKernel\n",
    "from qulearn.trainer import RidgeRegression\n",
    "import torch\n",
    "from torch.nn import MSELoss\n",
    "import logging\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "num_features = 12\n",
    "num_feature_repeat = 1\n",
    "wires = num_features*num_feature_repeat\n",
    "embed = ParallelEntangledIQPEncoding(wires, num_features=num_features, omega=1.0, n_repeat=1)\n",
    "#embed = ParallelIQPEncoding(wires, num_features=num_features, omega=1.0, n_repeat=1)\n",
    "embedvar = IQPEAltRotCXLayer(wires=wires, num_uploads=1, num_varlayers=1, num_repeat=20, omega=1.0)\n",
    "hads = HadamardLayer(wires=wires)\n",
    "#var = AltRotCXLayer(wires=wires, n_layers=10)\n",
    "#embed = IQPERYCZLayer(wires=wires, num_uploads=1, num_varlayers=0, num_repeat=2, omega=1.0)\n",
    "#embed = ParallelIQPEncoding(wires, num_features=1, omega=1.0, n_repeat=2)\n",
    "obs = qml.PauliZ(0)\n",
    "num_samples = 100\n",
    "X_train = torch.randn((num_samples, num_features))\n",
    "labels = torch.randn((num_samples, 1))\n",
    "#model = QKernel(embed, X_train)\n",
    "model = MeasurementLayer(embedvar, measurement_type=MeasurementType.Entropy, observable=obs)\n",
    "#model = MeasurementLayer(embed, var, measurement_type=MeasurementType.Expectation, observable=obs)\n",
    "drawer = qml.draw(model.qnode, show_all_wires=True, expansion_strategy=\"device\")\n",
    "x1 = torch.tensor([0.1, 0.2])\n",
    "x2 = torch.tensor([0.2, 0.3])\n",
    "#print(drawer(x1))\n",
    "model.subwires = [0, 1]\n",
    "#print(model(x1))\n",
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's import necessary packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "input_dim = 1\n",
    "# Define the LeakyReLU network\n",
    "class LeakyReLUNet(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(LeakyReLUNet, self).__init__()\n",
    "        # Define layers of the network (You can adjust the number of neurons as needed)\n",
    "        self.fc1 = nn.Linear(input_dim, 8)  # First fully connected layer\n",
    "        self.fc2 = nn.Linear(8, 8)         # Second fully connected layer\n",
    "        self.fc3 = nn.Linear(8, 1)          # Output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "        x = F.leaky_relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "# Initialize the network\n",
    "model = LeakyReLUNet(input_dim)\n",
    "\n",
    "# Print the model architecture\n",
    "print(model)\n",
    "print([p.shape for p in model.parameters() if p.requires_grad])\n",
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchviz import make_dot\n",
    "# Create a random tensor to represent a sample input\n",
    "x = torch.randn(1, input_dim)  # Assuming a batch size of 1\n",
    "y = model(x)\n",
    "\n",
    "# Visualize the network\n",
    "make_dot(y, params=dict(model.named_parameters())).render(\"network\", format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = torch.randn(num_features)\n",
    "subsystems = [list(range(i+1)) for i in range(wires-1)]\n",
    "entropies = []\n",
    "for subsystem in subsystems:\n",
    "    model.subwires = subsystem\n",
    "    entropies.append(model(x).item())\n",
    "max_entropies = [np.log2(min(2**len(subsystem), 2**(wires - len(subsystem)))) for subsystem in subsystems]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "x = list(range(wires-1))\n",
    "plt.plot(x, entropies, '-o', label='Computed Entropy')\n",
    "plt.plot(x, max_entropies, '-o', label='Maximum Entropy')\n",
    "\n",
    "plt.xlabel('Subsystem')\n",
    "plt.ylabel('VN Entropy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.title('Computed vs Maximum Entropy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# assuming model is your pytorch model\n",
    "# model = ...\n",
    "\n",
    "# Generate 100 random inputs between -1 and 1\n",
    "inputs = torch.linspace(-2, 2, 100)\n",
    "inputs = inputs.unsqueeze(-1)\n",
    "\n",
    "# Ensure the model is in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Disable gradient calculations\n",
    "with torch.no_grad():\n",
    "    # Run the inputs through the model\n",
    "    outputs = model(inputs)\n",
    "\n",
    "# Convert tensors to numpy arrays for plotting\n",
    "inputs = inputs.numpy()\n",
    "outputs = outputs.numpy()\n",
    "\n",
    "# Create the scatter plot\n",
    "plt.scatter(inputs, outputs)\n",
    "#plt.scatter(x, y)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/mazen/Research/QC/QuLearn/examples/compare_models\")\n",
    "from model_builder import QNNModel, QNNStatModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = QNNStatModel(num_features=1, num_reuploads=1, num_varlayers=1, num_repeats=1, omega=0.0, double_wires=False, id=\"0\")\n",
    "for p in model.parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "import torch\n",
    "drawer = qml.draw(model.qnn.qnode, show_all_wires=True, expansion_strategy=\"device\")\n",
    "x = torch.randn(1, 1)\n",
    "print(model(x))\n",
    "print(drawer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# assuming model is your PyTorch model\n",
    "# model = ...\n",
    "\n",
    "# Ensure the model is in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Disable gradient calculations\n",
    "with torch.no_grad():\n",
    "    # Define input range\n",
    "    x = np.linspace(-2, 2, 50)\n",
    "    y = np.linspace(-2, 2, 50)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "\n",
    "    # Combine inputs and reshape for model input\n",
    "    inputs = np.array([X.flatten(), Y.flatten()]).T\n",
    "    inputs = torch.Tensor(inputs)\n",
    "\n",
    "    # Compute outputs\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    # Convert tensors to numpy arrays for plotting\n",
    "    inputs = inputs.numpy()\n",
    "    outputs = outputs.numpy()\n",
    "\n",
    "    # Reshape output for heatmap\n",
    "    Z = outputs.reshape(50, 50)\n",
    "\n",
    "    # Create the heatmap\n",
    "    plt.imshow(Z, extent=[-2, 2, -2, 2], origin='lower')\n",
    "    plt.colorbar(label='Model output')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Create a 3D plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot_surface(X, Y, Z, cmap='viridis')\n",
    "\n",
    "# Set labels\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_zlabel('Model output')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import qmc\n",
    "\n",
    "def generate_lhs_samples(n_samples, n_dims, lower_bound, upper_bound):\n",
    "    \"\"\"Generates Latin Hypercube Samples in the specified range.\"\"\"\n",
    "    sampler = qmc.LatinHypercube(d=n_dims)\n",
    "    sample = sampler.random(n=n_samples)\n",
    "    return lower_bound + sample * (upper_bound - lower_bound)\n",
    "\n",
    "import torch\n",
    "\n",
    "def generate_model_samples(model, n_samples):\n",
    "    \"\"\"Generates a list of lists of model parameters, sampled using LHS.\"\"\"\n",
    "    model_parameters = list(filter(lambda p: p.requires_grad, model.parameters()))\n",
    "\n",
    "    lower_bound = -2 * np.pi\n",
    "    upper_bound = 2 * np.pi\n",
    "    samples = []\n",
    "    for p in model_parameters:\n",
    "        n_dims = p.numel()\n",
    "        sample_parameter = generate_lhs_samples(n_samples=n_samples, n_dims=n_dims, lower_bound=lower_bound, upper_bound=upper_bound)\n",
    "        samples.append(sample_parameter)\n",
    "    parameter_list = [[torch.tensor(samples[j][i], device=None, dtype=None) for j in range(len(samples))] for i in range(n_samples)]\n",
    "\n",
    "    return parameter_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = generate_model_samples(model, 5)\n",
    "print(len(test))\n",
    "for t in test:\n",
    "    print(len(t))\n",
    "    for x in t:\n",
    "        print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for input, label in dataloader:\n",
    "    print(input)\n",
    "    print(label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(level=logging.INFO)\n",
    "logger.info(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qulearn.qlayer import IQPEmbeddingLayer\n",
    "from qulearn.qlayer import QEvalType\n",
    "import torch\n",
    "import pennylane as qml\n",
    "from qulearn.observable import parity_all_hamiltonian \n",
    "\n",
    "numq = 3\n",
    "wires = range(numq)\n",
    "qdev = qml.device(\"lightning.qubit\", wires=numq, shots=None)\n",
    "@qml.qnode(qdev)\n",
    "def qnode():\n",
    "    return qml.expval(qml.PauliZ(0))\n",
    "\n",
    "out = qnode()\n",
    "print(out)\n",
    "print(qdev.shots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "t = torch.nn.Parameter(torch.zeros(3, 3))\n",
    "print(t)\n",
    "torch.nn.init.uniform_(t, a=0.0, b=2*math.pi)\n",
    "print(t)\n",
    "a = [0, 1]\n",
    "b = [0, 2]\n",
    "print(a==b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qulearn.qlayer import IQPEmbeddingLayer, RYCZLayer, MeasurementLayer, HamiltonianLayer, MeasurementType, EmbedVarLayer, CircuitLayer\n",
    "import pennylane as qml\n",
    "import torch\n",
    "from qulearn.observable import parities_all_observables\n",
    "\n",
    "observable = qml.PauliZ(0)\n",
    "num_wires = 3\n",
    "num_reup = 1\n",
    "num_layers = 1\n",
    "num_repeat = 1\n",
    "qdev = qml.device('default.qubit', wires=num_wires, shots=None)\n",
    "\n",
    "upload_layer = IQPEmbeddingLayer(num_wires, num_reup)\n",
    "var_layer = RYCZLayer(num_wires, num_layers)\n",
    "embedvar = EmbedVarLayer(upload_layer, var_layer, n_repeat=num_repeat, omega=1.0)\n",
    "measure_layer = MeasurementLayer(embedvar, qdevice=qdev, measurement_type=MeasurementType.Expectation, observable=observable)\n",
    "obs = parities_all_observables(num_wires)\n",
    "ham_layer = HamiltonianLayer(embedvar, observables=obs, interface='torch', diff_method='backprop')\n",
    "#ham_layer = HamiltonianLayer(upload_layer, observables=obs)\n",
    "\n",
    "x = torch.randn(3, num_wires)\n",
    "drawer = qml.draw_mpl(ham_layer.qnode, show_all_wires=True, expansion_strategy=\"device\")\n",
    "drawer(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.cat((x, x), dim=1)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qulearn.utils import all_bin_sequences\n",
    "from qulearn.observable import sequence2parity_observable\n",
    "from itertools import combinations\n",
    "all = all_bin_sequences(3)\n",
    "pairs = list(combinations(range(3),2 ))\n",
    "print(all)\n",
    "print(pairs)\n",
    "all_obs = sequence2parity_observable(all)\n",
    "pairs_obs = sequence2parity_observable(pairs)\n",
    "\n",
    "print(all_obs)\n",
    "print(pairs_obs)\n",
    "all_obs[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tuple(range(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in ham_layer.parameters():\n",
    "    print(p)\n",
    "print(ham_layer.observable.coeffs)\n",
    "print(ham_layer.observable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = torch.tensor([1., -1., 0.5])\n",
    "print(tmp.numel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qulearn.fim import empirical_fim, compute_fims, mc_integrate_idfim_det\n",
    "\n",
    "FIM = empirical_fim(measure_layer, x)\n",
    "for p in measure_layer.parameters():\n",
    "    print(p)\n",
    "\n",
    "plist = []\n",
    "p1 = torch.randn(4, 3)\n",
    "p2 = torch.randn(4, 3, 2, 2)\n",
    "for i in range(4):\n",
    "    plist.append([p1[i], p2[i]])\n",
    "\n",
    "FIMs = compute_fims(measure_layer, x, plist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integral = mc_integrate_idfim_det(FIMs, 1.0, 1.0)\n",
    "print(integral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin = torch.nn.Linear(3, 1)\n",
    "print(lin(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = upload_layer(x)\n",
    "y2 = var_layer(x)\n",
    "#y3 = measure_layer(x)\n",
    "y4 = ham_layer(x)\n",
    "\n",
    "print(y3)\n",
    "print(y4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(y3)\n",
    "log_prob = torch.log(y3)\n",
    "print(torch.log(y3))\n",
    "print(x.shape)\n",
    "\n",
    "measure_layer.zero_grad()\n",
    "log_prob.backward(retain_graph=True)\n",
    "grad_list = [\n",
    "    p.grad.view(-1)\n",
    "    for p in measure_layer.parameters()\n",
    "    if p.requires_grad and p.grad is not None\n",
    "]\n",
    "grad = torch.cat(grad_list)\n",
    "prod = torch.outer(grad, grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in measure_layer.state_dict().items():\n",
    "    print(key)\n",
    "    print(val)\n",
    "    print(\"====\")\n",
    "\n",
    "print(\"************************************\")\n",
    "\n",
    "for key, val in ham_layer.state_dict().items():\n",
    "    print(key)\n",
    "    print(val)\n",
    "    print(\"====\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class HybridModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.ll_in = nn.Linear(3, 3, dtype=torch.float64)\n",
    "        self.meas = ham_layer\n",
    "        self.ll_out = nn.Linear(1, 1, dtype=torch.float64)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        y = self.ll_in(x)\n",
    "        y = self.meas(y)\n",
    "        y = self.ll_out(y)\n",
    "\n",
    "        return y\n",
    "    \n",
    "hybrid = HybridModel()\n",
    "x = torch.rand(3, dtype=torch.float64)\n",
    "y = hybrid(x)\n",
    "print(y)\n",
    "for key, val in hybrid.state_dict().items():\n",
    "    print(key)\n",
    "    print(val)\n",
    "    print(\"======\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in measure_layer.state_dict().items():\n",
    "    print(key)\n",
    "    print(val)\n",
    "    print(\"=====\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class MyType(Enum):\n",
    "\n",
    "    TypeA = 0\n",
    "    TypeB = 1\n",
    "\n",
    "x = MyType.TypeA\n",
    "y = \"blub\"\n",
    "\n",
    "if x == MyType.TypeA:\n",
    "    print(x)\n",
    "\n",
    "if not isinstance(y, MyType):\n",
    "    raise NotImplementedError(\"QEvalType not implemented\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Linear\n",
    "model = Linear(3, 1)\n",
    "X = torch.tensor([[0.1, 1.1, -2.2], [0.6, 4.1, -3.2], [-0.1, -2.1, -2.2]])\n",
    "Y = model(X)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(\"runs/test\")\n",
    "for i in range(10):\n",
    "    val = 1e-01\n",
    "    writer.add_scalar(\"foobar1\", val, i)\n",
    "    writer.add_scalars(\"loss\", {\"train\": val, \"valid\": val+1.0}, i)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pennylane as qml\n",
    "from qml_mor.models import IQPEReuploadSU2Parity, ModelType\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "num_samples=1\n",
    "num_qubits = 3\n",
    "num_reups = 1\n",
    "num_layers = 1\n",
    "sizex = num_qubits\n",
    "\n",
    "omega = 0.0\n",
    "init_theta = torch.randn(num_reups, num_qubits, requires_grad=True)\n",
    "theta = torch.randn(\n",
    "    num_reups, num_layers, num_qubits - 1, 2, requires_grad=True\n",
    ")\n",
    "W = torch.randn(2**num_qubits, requires_grad=True)\n",
    "\n",
    "params = [init_theta, theta, W]\n",
    "\n",
    "dev = qml.device(\"default.qubit\", wires=num_qubits, shots=None)\n",
    "\n",
    "model = IQPEReuploadSU2Parity(dev, params, model_type=ModelType.Expectation)\n",
    "X = torch.randn(10, 3)\n",
    "Ypred = model(X)\n",
    "print(Ypred)\n",
    "print(Ypred.shape)\n",
    "\n",
    "loss = torch.nn.MSELoss()\n",
    "test = loss(Ypred, Ypred)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Parameter\n",
    "P = model.parameters()\n",
    "for p in P:\n",
    "    print(p)\n",
    "print(\"====================\")\n",
    "save = model.state_dict().copy()\n",
    "\n",
    "init_theta = torch.randn(num_reups, num_qubits, requires_grad=True)\n",
    "theta = torch.randn(\n",
    "    num_reups, num_layers, num_qubits - 1, 2, requires_grad=True\n",
    ")\n",
    "W = torch.randn(2**num_qubits, requires_grad=True)\n",
    "\n",
    "params = [init_theta, theta, W]\n",
    "\n",
    "model = IQPEReuploadSU2Parity(dev, params)\n",
    "\n",
    "P = model.parameters()\n",
    "for p in P:\n",
    "    print(p)\n",
    "print(\"====================\")\n",
    "model.load_state_dict(save)\n",
    "P = model.parameters()\n",
    "for p in P:\n",
    "    print(p)\n",
    "print(\"====================\")\n",
    "print(save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"8\"\n",
    "from qulearn.qlayer import IQPEmbeddingLayer, RYCZLayer, MeasurementLayer, HamiltonianLayer, MeasurementType, EmbedVarLayer, CircuitLayer\n",
    "import pennylane as qml\n",
    "import torch\n",
    "from qulearn.observable import parities_all_observables\n",
    "\n",
    "observable = qml.PauliZ(0)\n",
    "num_wires = 3\n",
    "num_reup = 1\n",
    "num_layers = 1\n",
    "num_repeat = 3\n",
    "qdev = qml.device('default.qubit', wires=num_wires, shots=None)\n",
    "\n",
    "upload_layer = IQPEmbeddingLayer(num_wires, num_reup)\n",
    "var_layer = RYCZLayer(num_wires, num_layers)\n",
    "embedvar = EmbedVarLayer(upload_layer, var_layer, n_repeat=num_repeat, omega=1.0)\n",
    "obs = parities_all_observables(num_wires)\n",
    "ham_layer = HamiltonianLayer(embedvar,  qdevice=qdev, observables=obs, interface='torch', diff_method='adjoint')\n",
    "\n",
    "x = torch.zeros(3, num_wires)\n",
    "print(ham_layer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "N = 100\n",
    "torch.manual_seed(0)\n",
    "X = torch.randn(N, 10, dtype=torch.float64)\n",
    "#Y = torch.randn(N, 1, dtype=torch.float64)\n",
    "A = torch.randn(10, 1, dtype=torch.float64)\n",
    "b = torch.randn(1, dtype=torch.float64)\n",
    "eps = torch.randn(N, dtype=torch.float64)*0.001\n",
    "Y = torch.matmul(X, A) + b + eps\n",
    "model = torch.nn.Linear(10, 1, bias=True, dtype=torch.float64)\n",
    "batch_size=4\n",
    "shuffle=True\n",
    "\n",
    "dataset = TensorDataset(X, Y)\n",
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from qulearn.trainer import SupervisedTrainer\n",
    "import logging\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "opt = Adam(model.parameters(), lr=0.1, amsgrad=True)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "metrics = {\"L1\": loss_fn, \"L2\": loss_fn}\n",
    "writer = SummaryWriter()\n",
    "logger = logging.getLogger(\"SupTrainer\")\n",
    "logger.setLevel(level=logging.INFO)\n",
    "trainer = SupervisedTrainer(opt, loss_fn, metrics, 200, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(model, loader, loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "trainer.train(ham_layer, loader, loader) # lightning + torch + adjoint (+ omp-num-threads=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "trainer.train(ham_layer, loader, loader) # default + torch + backprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "trainer.train(ham_layer, loader, loader) # default + torch + adjoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -T lprof0 -u 1.0 -f trainer._train_step trainer.train(ham_layer, loader, loader)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class MeasurementType(Enum):\n",
    "    \"\"\"Measurement type for a measurement layer.\"\"\"\n",
    "\n",
    "    \"\"\"Expectation: return expected value of observable.\"\"\"\n",
    "    Expectation\n",
    "    \"\"\"Probabilities: return vector of probabilities.\"\"\"\n",
    "    Probabilities = \"probabilities\"\n",
    "    \"\"\"Samples: return measurement samples.\"\"\"\n",
    "    Samples = \"samples\"\n",
    "\n",
    "example = MeasurementType.Expectation\n",
    "print(type(example.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qml_mor.trainer import RegressionTrainer\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim import Adam\n",
    "from datetime import datetime\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=0.1, amsgrad=True)\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('runs/check_{}'.format(timestamp))\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "training = RegressionTrainer(optimizer, loss_fn, writer)\n",
    "loss = training.train(model, loader, loader)\n",
    "print(loss)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"model_bestmre\"\n",
    "state = torch.load(path)\n",
    "model.load_state_dict(state)\n",
    "Ypred = model(X)\n",
    "print(Y)\n",
    "print(\"==============\")\n",
    "print(Ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs/fashion_trainer_20230517_113403"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pennylane as qml\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from qml_mor.models import IQPEReuploadSU2Parity\n",
    "from qml_mor.trainer import AdamTorch\n",
    "from qml_mor.datagen import DataGenCapacity\n",
    "\n",
    "num_samples=1\n",
    "num_qubits = 3\n",
    "num_reups = 1\n",
    "num_layers = 1\n",
    "sizex = num_qubits\n",
    "\n",
    "datagen = DataGenCapacity(sizex=sizex, num_samples=num_samples)\n",
    "\n",
    "omega = 0.0\n",
    "init_theta = torch.randn(num_reups, num_qubits, requires_grad=True)\n",
    "theta = torch.randn(\n",
    "    num_reups, num_layers, num_qubits - 1, 2, requires_grad=True\n",
    ")\n",
    "W = torch.randn(2**num_qubits, requires_grad=True)\n",
    "\n",
    "params = [init_theta, theta, W]\n",
    "\n",
    "model = IQPEReuploadSU2Parity(omega)\n",
    "dev = qml.device(\"default.qubit\", wires=num_qubits, shots=None)\n",
    "\n",
    "@qml.qnode(dev, interface=\"torch\")\n",
    "def qnn_model(x, params):\n",
    "    return model.qfunction(x, params)\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "num_epochs = 300\n",
    "opt = AdamTorch(params, loss_fn, num_epochs=num_epochs, amsgrad=True)\n",
    "\n",
    "N = 10\n",
    "batch_size=int(\"inf\")\n",
    "shuffle=True\n",
    "data = datagen.gen_data(N)\n",
    "X = data[\"X\"]\n",
    "Y = data[\"Y\"][0]\n",
    "dataset = TensorDataset(X, Y)\n",
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "opt_params = opt.optimize(qnn_model, loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nx = X.size(0)\n",
    "y_pred = torch.stack([qnn_model(X[k], opt_params) for k in range(Nx)])\n",
    "mre = torch.mean(torch.abs((Y - y_pred) / y_pred))\n",
    "\n",
    "print(mre)\n",
    "print(loss_fn(y_pred, Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "X = torch.randn(5, 3)\n",
    "Y = torch.randn(5)\n",
    "batch_size = 2\n",
    "\n",
    "dataset = TensorDataset(X, Y)\n",
    "shuffle = True\n",
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "print(X)\n",
    "print(Y)\n",
    "print(\"===========\")\n",
    "for X_, Y_ in loader:\n",
    "    print(X_.size(0))\n",
    "    print(X_)\n",
    "    print(Y_)\n",
    "    print(\"***********\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qml_mor.datagen import DataGenRademacher, NormalPrior\n",
    "prior = NormalPrior(3, seed=0)\n",
    "radem = DataGenRademacher(prior, 2, 3, seed=None)\n",
    "data = radem.gen_data(4)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pennylane as qml\n",
    "num_qubits = 3\n",
    "W = torch.randn(2**num_qubits, requires_grad=False)\n",
    "from qulearn.qlayer import parity_hamiltonian\n",
    "H = parity_hamiltonian(num_qubits, W)\n",
    "print(W)\n",
    "print(\"======\")\n",
    "Z = qml.PauliZ(wires=0)\n",
    "print(H.coeffs.requires_grad)\n",
    "W_ = torch.nn.Parameter()\n",
    "print(W_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "import torch\n",
    "from qml_mor.models import IQPEReuploadSU2Parity\n",
    "\n",
    "num_qubits  = 3\n",
    "num_reps    = 2\n",
    "num_layers  = 2\n",
    "omega       = 1.\n",
    "torch.manual_seed(0)\n",
    "x           = torch.randn(num_qubits, requires_grad=False)\n",
    "init_theta  = torch.randn(num_reps, num_qubits, requires_grad=True)\n",
    "theta       = torch.randn(num_reps, num_layers, num_qubits-1, 2, requires_grad=True)\n",
    "W           = torch.randn(2**num_qubits, requires_grad=True)\n",
    "\n",
    "params = [init_theta, theta, W]\n",
    "\n",
    "def iqpe_reupload_su2_parity(\n",
    "    x, init_theta, theta, W, omega: float = 0.0\n",
    "):\n",
    "    \"\"\"\n",
    "    Quantum function that calculates the expectation value\n",
    "    of the parity of Pauli Z operators.\n",
    "\n",
    "    Args:\n",
    "        x (Tensor): Input tensor of shape (num_qubits,)\n",
    "        init_theta (Tensor): Initial rotation angles for each qubit,\n",
    "            of shape (reps, num_qubits)\n",
    "        theta (Tensor): Rotation angles for each layer and each qubit,\n",
    "            of shape (reps, num_layers, num_qubits-1, 2)\n",
    "        W (Tensor): Observable weights of shape (2^num_qubits,)\n",
    "        omega (float, optional): Exponential feature scaling factor. Defaults to 0.0.\n",
    "\n",
    "    Returns:\n",
    "        QFuncOutput: Expectation value of the parity of Pauli Z operators\n",
    "    \"\"\"\n",
    "\n",
    "    shape_init = init_theta.shape\n",
    "    shape = theta.shape\n",
    "    if len(shape_init) != 2:\n",
    "        raise ValueError(\"Initial theta must be a 2-dim tensor\")\n",
    "    if len(shape) != 4:\n",
    "        raise ValueError(\"Theta must be a 4-dim tensor\")\n",
    "\n",
    "    num_qubits = len(x)\n",
    "    reps = shape_init[0]\n",
    "    wires = range(num_qubits)\n",
    "\n",
    "    for layer in range(reps):\n",
    "        features = 2 ** (omega * layer) * x\n",
    "        initial_layer_weights = init_theta[layer]\n",
    "        weights = theta[layer]\n",
    "\n",
    "        qml.IQPEmbedding(features=features, wires=wires)\n",
    "        qml.SimplifiedTwoDesign(\n",
    "            initial_layer_weights=initial_layer_weights,\n",
    "            weights=weights,\n",
    "            wires=wires,\n",
    "        )\n",
    "\n",
    "def iqpe_reupload_su2_meas(\n",
    "    x, init_theta, theta, W, omega: float = 0.0\n",
    "):\n",
    "    iqpe_reupload_su2_parity(x, init_theta, theta, W, omega)\n",
    "    obs = parities(len(x))\n",
    "    H = qml.Hamiltonian(W, obs)\n",
    "\n",
    "    return qml.sample()\n",
    "\n",
    "#qnn_model = IQPEReuploadSU2Parity(params, omega=1.0)\n",
    "\n",
    "dev = qml.device(\"default.qubit\", wires=num_qubits, shots=None)\n",
    "qnode = qml.QNode(iqpe_reupload_su2_meas, dev, interface=\"torch\")\n",
    "#drawer = qml.draw(qnode, expansion_strategy=\"device\")\n",
    "#print(drawer(x, init_theta, theta, W))\n",
    "probs = qnode(x, init_theta, theta, W, omega)\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = probs\n",
    "bitstrings = [''.join(str(b.item()) for b in sample) for sample in samples]\n",
    "bitstring_counts = {bs: bitstrings.count(bs) for bs in set(bitstrings)}\n",
    "print(samples)\n",
    "print(bitstrings)\n",
    "print(bitstring_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qml_mor.models import IQPEReuploadSU2Parity\n",
    "\n",
    "model = IQPEReuploadSU2Parity()\n",
    "\n",
    "qnode = qml.QNode(model.probabilities, dev, interface=\"torch\")\n",
    "probs = qnode(x, params)\n",
    "print(probs)\n",
    "print(model.Hamiltonian(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = model.Hamiltonian(params)\n",
    "sum = 0.0\n",
    "b = \"110\"\n",
    "\n",
    "for idx, O in enumerate(H.ops):\n",
    "\n",
    "    if not isinstance(O.name, list):\n",
    "        if O.name == \"Identity\":\n",
    "            sum += H.coeffs[idx]\n",
    "        elif O.name == \"PauliZ\":\n",
    "            i = O.wires[0]\n",
    "            sign = (-1)**(int(b[-1-i]))\n",
    "            sum += sign*H.coeffs[idx]\n",
    "        else:\n",
    "            raise ValueError(\"All operators must be PauliZ or Identity.\")\n",
    "    else:\n",
    "        if not all(name==\"PauliZ\" for name in O.name):\n",
    "            raise ValueError(\"All operators must be PauliZ or Identity.\")\n",
    "        \n",
    "        sign = 1\n",
    "        for w in O.wires:\n",
    "            sign *= (-1)**(int(b[-1-w]))\n",
    "\n",
    "        sum += sign*H.coeffs[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(probs)\n",
    "marginal = qml.math.marginal_prob(probs, axis=[0])\n",
    "print(marginal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qml_mor.models import parities\n",
    "\n",
    "n = 3\n",
    "test = parities(n)\n",
    "H = qml.Hamiltonian(W, test)\n",
    "print(H)\n",
    "print(H.ops)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature layer\n",
    "def feature_layer(x):\n",
    "    num_qubits = len(x)\n",
    "    qml.IQPEmbedding(x, wires=range(num_qubits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variational layer\n",
    "def variational_layer(init_theta, theta, num_qubits):\n",
    "    qml.SimplifiedTwoDesign(initial_layer_weights=init_theta, weights=theta, wires=range(num_qubits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observable / output layer\n",
    "def sequence_generator(n):\n",
    "    if n == 0:\n",
    "        return [[]]\n",
    "    else:\n",
    "        sequences = []\n",
    "        for sequence in sequence_generator(n-1):\n",
    "            sequences.append(sequence + [n-1])\n",
    "            sequences.append(sequence)\n",
    "        return sequences\n",
    "    \n",
    "def parities(n):\n",
    "    \n",
    "    seq = sequence_generator(n)\n",
    "    ops = []\n",
    "    for par in seq:\n",
    "        if par:\n",
    "            tmp = qml.PauliZ(par[0])\n",
    "            if len(par) > 1:\n",
    "                for i in par[1:]:\n",
    "                    tmp = tmp @ qml.PauliZ(i)\n",
    "\n",
    "            ops.append(tmp)\n",
    "\n",
    "    ops.append(qml.Identity(0))\n",
    "\n",
    "    return ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pennylane.templates import IQPEmbedding, SimplifiedTwoDesign\n",
    "# QNN model\n",
    "@qml.qnode(dev, interface='torch')\n",
    "def qnn_model(x, init_theta, theta, W, omega=0.):\n",
    "\n",
    "    num_qubits = len(x)\n",
    "    shape_init = init_theta.shape\n",
    "    reps       = 1\n",
    "    if len(shape_init) < 1:\n",
    "        init_theta = [init_theta]\n",
    "        shape_init = init_theta.shape\n",
    "    reps       = shape_init[0]\n",
    "\n",
    "    shape_theta = theta.shape\n",
    "    reps_       = 1\n",
    "    if len(shape_theta) < 3:\n",
    "        theta       = [theta]\n",
    "        shape_theta = theta.shape\n",
    "    reps_       = shape_theta[0]\n",
    "\n",
    "    assert reps == reps_\n",
    "    for l in range(reps):\n",
    "        qml.IQPEmbedding(features=2**(omega*l)*x, wires=range(num_qubits))\n",
    "        qml.SimplifiedTwoDesign(initial_layer_weights=init_theta[l], weights=theta[l], wires=range(num_qubits))\n",
    "\n",
    "    obs = parities(num_qubits)\n",
    "    H   = qml.Hamiltonian(W, obs)\n",
    "\n",
    "    return qml.expval(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane.templates import IQPEmbedding\n",
    "\n",
    "n_wires = 3\n",
    "n_layers = 2\n",
    "\n",
    "dev = qml.device(\"default.qubit\", wires=n_wires)\n",
    "@qml.qnode(dev, interface='torch')\n",
    "def iqpe_circuit(features):\n",
    "    for layer in range(n_layers):\n",
    "        # Apply the IQPEmbedding template in a loop\n",
    "        IQPEmbedding(features=features[layer], wires=range(n_wires))\n",
    "\n",
    "    return [qml.expval(qml.PauliZ(wires=i)) for i in range(n_wires)]\n",
    "\n",
    "features = np.random.random((n_layers, n_wires))\n",
    "\n",
    "result1 = iqpe_circuit(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_qubits  = 3\n",
    "num_reps    = 0\n",
    "num_layers  = 0\n",
    "omega       = 1.\n",
    "x           = torch.randn(num_qubits, requires_grad=False)\n",
    "init_theta  = torch.randn(num_reps, num_qubits, requires_grad=True)\n",
    "theta       = torch.randn(num_reps, num_layers, num_qubits-1, 2, requires_grad=True)\n",
    "W           = torch.randn(2**num_qubits, requires_grad=True)\n",
    "\n",
    "result1 = qnn_model(x, init_theta, theta, W)\n",
    "result2 = qnn_model(x, init_theta, theta, W)\n",
    "\n",
    "ret = torch.stack([result1, result2])\n",
    "result1.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import qmc\n",
    "def generate_samples_r(d, S):\n",
    "    sampler = qmc.LatinHypercube(d=d)\n",
    "    r_samples = sampler.random(n=S)\n",
    "    return r_samples\n",
    "r = generate_samples_r(10, 2)\n",
    "print(len(r[0]))\n",
    "\n",
    "tmp = set()\n",
    "rng = np.random.default_rng(seed=0)\n",
    "b1 = tuple(rng.integers(0, 2, size=4))\n",
    "b2 = tuple(rng.integers(0, 2, size=4))\n",
    "tmp.add(b1)\n",
    "tmp.add(b2)\n",
    "print(tmp)\n",
    "arr = np.array(list(tmp))\n",
    "print(arr)\n",
    "arr[0, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Original list of tensors\n",
    "tensor_list = [torch.tensor([1., 2., 3.], requires_grad=True),\n",
    "               torch.tensor([4., 5., 6.], requires_grad=False)]\n",
    "\n",
    "est_params = [\n",
    "                        t.detach().clone().requires_grad_(t.requires_grad)\n",
    "                        for t in tensor_list\n",
    "                    ]\n",
    "tensor_list *= 2\n",
    "print(tensor_list)\n",
    "print(est_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = (f\"Stopping early\\n\"\n",
    "       \"Loss not improving\")\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the quantum device\n",
    "dev = qml.device(\"default.qubit\", wires=2)\n",
    "\n",
    "# Define the custom model as a PennyLane QNode\n",
    "@qml.qnode(dev, interface=\"torch\")\n",
    "def custom_model(x, y):\n",
    "    # Apply your quantum circuit here, which uses input x and trainable parameters y\n",
    "    # As an example, we'll use a simple circuit with one rotation gate parameterized by y:\n",
    "    qml.RY(y[0], wires=0)\n",
    "    qml.RX(x, wires=1)\n",
    "    qml.CNOT(wires=[0, 1])\n",
    "    return qml.expval(qml.PauliZ(1))\n",
    "\n",
    "# Define the dataset (x_data, y_data)\n",
    "x_data = torch.tensor([0.1, 0.2, 0.3, 0.4, 0.5], dtype=torch.float32)\n",
    "y_data = torch.tensor([0.5, 0.4, 0.3, 0.2, 0.1], dtype=torch.float32)\n",
    "\n",
    "# Initialize the trainable parameters\n",
    "params = torch.tensor([0.0], dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "# Set the hyperparameters\n",
    "learning_rate = 0.01\n",
    "epochs = 100\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam([params], lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    predictions = torch.tensor([custom_model(x, params) for x in x_data], dtype=torch.float32)\n",
    "    loss = loss_fn(predictions, y_data)\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")\n",
    "\n",
    "print(f\"Trained parameters: {params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_qubits  = 3\n",
    "num_reps    = 3\n",
    "num_layers  = 0\n",
    "omega       = 1.\n",
    "x           = torch.randn(num_qubits, requires_grad=False)\n",
    "init_theta  = torch.randn(num_reps, num_qubits, requires_grad=True)\n",
    "theta       = torch.randn(num_reps, num_layers, num_qubits-1, 2, requires_grad=True)\n",
    "W           = torch.randn(2**num_qubits, requires_grad=True)\n",
    "def qnn_model(x, init_theta, theta, W, omega=0.):\n",
    "\n",
    "    num_qubits = len(x)\n",
    "    shape_init = init_theta.shape\n",
    "    reps       = 1\n",
    "    if len(shape_init) < 1:\n",
    "        init_theta = [init_theta]\n",
    "        shape_init = init_theta.shape\n",
    "    reps       = shape_init[0]\n",
    "\n",
    "    shape_theta = theta.shape\n",
    "    reps_       = 1\n",
    "    if len(shape_theta) < 3:\n",
    "        theta       = [theta]\n",
    "        shape_theta = theta.shape\n",
    "    reps_       = shape_theta[0]\n",
    "\n",
    "    assert reps == reps_\n",
    "    for l in range(reps):\n",
    "        qml.IQPEmbedding(features=2**(omega*l)*x, wires=range(num_qubits))\n",
    "        qml.SimplifiedTwoDesign(initial_layer_weights=init_theta[l], weights=theta[l], wires=range(num_qubits))\n",
    "\n",
    "    obs = parities(num_qubits)\n",
    "    H   = qml.Hamiltonian(W, obs)\n",
    "\n",
    "    return qml.expval(H)\n",
    "\n",
    "result = qnn_model(x, init_theta, theta, W)\n",
    "print(result.shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = parities(3)\n",
    "for x in tmp:\n",
    "    print(type(x))\n",
    "    print(issubclass(type(x), qml.operation.Observable))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "num_qubits  = 3\n",
    "num_reps    = 3\n",
    "num_layers  = 0\n",
    "omega       = 1.\n",
    "x           = torch.randn(num_qubits, requires_grad=False)\n",
    "init_theta  = torch.randn(num_reps, num_qubits, requires_grad=True)\n",
    "theta       = torch.randn(num_reps, num_layers, num_qubits-1, 2, requires_grad=True)\n",
    "W           = torch.randn(2**num_qubits, requires_grad=True)\n",
    "\n",
    "print(qml.draw_mpl(qnn_model)(x, init_theta, theta, W, omega))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets for Capacity Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_dataset(N, samples=10, seed=0):\n",
    "    sizex   = num_qubits\n",
    "    scale   = 2.\n",
    "    shift   = -1.\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    x       = scale*torch.rand(N, sizex, requires_grad=False) + shift\n",
    "    y       = scale*torch.rand(samples, N, requires_grad=False) + shift\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model specs\n",
    "num_qubits  = 3\n",
    "num_reps    = 2\n",
    "num_layers  = 2\n",
    "omega       = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial parameters\n",
    "seed = 0\n",
    "torch.manual_seed(seed)\n",
    "init_theta  = torch.randn(num_reps, num_qubits, requires_grad=True)\n",
    "theta       = torch.randn(num_reps, num_layers, num_qubits-1, 2, requires_grad=True)\n",
    "W           = torch.randn(2**num_qubits, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "def square_loss(targets, predictions):\n",
    "    loss = 0\n",
    "    for t, p in zip(targets, predictions):\n",
    "        loss += (t - p) ** 2\n",
    "    loss = loss / len(targets)\n",
    "    return 0.5*loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# capacity estimation parameters\n",
    "Nmin     = 1\n",
    "Nmax     = 5\n",
    "samples  = 10\n",
    "steps    = 300\n",
    "eps_stop = 1e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = {}\n",
    "for N in range(Nmin, Nmax):\n",
    "    x, y = gen_dataset(N, samples)\n",
    "    \n",
    "    mre_sample = []\n",
    "    for s in range(samples):\n",
    "        print('===================================')\n",
    "        def cost(init_theta, theta, W):\n",
    "            pred = [qnn_model(x[k], init_theta, theta, W) for k in range(N)]\n",
    "            loss = square_loss(y[s], pred)\n",
    "            return loss\n",
    "        \n",
    "        # optimize\n",
    "        opt = torch.optim.Adam([init_theta, theta, W], lr=0.1, amsgrad=True)\n",
    "        for n in range(steps):\n",
    "            opt.zero_grad()\n",
    "            loss = cost(init_theta, theta, W)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            if n%10 == 9 or n == steps - 1:\n",
    "                print(f'{n+1}: {loss}')\n",
    "\n",
    "            if loss <= eps_stop:\n",
    "                break\n",
    "\n",
    "        # compute prediction errors\n",
    "        y_pred = torch.tensor([qnn_model(x[k], init_theta, theta, W) for k in range(N)], requires_grad=False)\n",
    "        mre    = torch.mean(torch.abs((y[s]-y_pred)/y_pred))\n",
    "        mre_sample.append(mre)\n",
    "\n",
    "    mre_N = torch.mean(torch.tensor(mre_sample))\n",
    "    summary[f'N = {N}'] = mre_N.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for count, eps in enumerate(summary.values()):\n",
    "    m = int(np.log2(1./eps.item()))\n",
    "    C = (count+1)*m\n",
    "    print(C)\n",
    "print(torch.numel(init_theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = [-0.5, 13.1, 2]\n",
    "max(C)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = torch.tensor([qnn_model(x[k], init_theta, theta, W) for k in range(N)], requires_grad=False)\n",
    "mre    = torch.mean(torch.abs((y[s]-y_pred)/y_pred))\n",
    "print(mre.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cutoff precision converted to bits of precision\n",
    "cutoff = np.sqrt(eps_stop)\n",
    "m      = np.log2(1./cutoff)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x)\n",
    "print(init_theta)\n",
    "print(theta)\n",
    "print(W)\n",
    "print(y[s])\n",
    "print(y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QML-MOR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "46e7eb4246c13550057ff7606884a772512028b1851bd0c4d2a0ba2e0c036465"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
