{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "import torch\n",
    "from qulearn.qlayer import AltRotCXLayer, HamiltonianLayer\n",
    "\n",
    "num_qubits = 3\n",
    "n_layers = 2\n",
    "wires = range(0, num_qubits)\n",
    "dev = qml.device(\"default.qubit\", wires=wires, shots=None)\n",
    "layer = AltRotCXLayer(wires, n_layers=n_layers, dtype=torch.float64)\n",
    "obs = [qml.PauliZ(0)]\n",
    "model = HamiltonianLayer(layer, observables=obs, qdevice=dev, dtype=torch.float64, interface=\"torch\", diff_method=\"backprop\")\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "y = torch.tensor([-0.25], dtype=torch.float64)\n",
    "drawer = qml.draw(model.qnode, show_all_wires=True, expansion_strategy=\"device\")\n",
    "print(drawer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "opt = Adam(model.parameters(), lr=0.1)\n",
    "opt.zero_grad()\n",
    "pred = model()\n",
    "loss = loss_fn(pred, y)\n",
    "loss.backward()\n",
    "opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawer = qml.draw(model.qnode, show_all_wires=True, expansion_strategy=\"device\")\n",
    "print(drawer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8000])\n",
      "([1, 1, 1], tensor([0.2000]))\n",
      "tensor([0.8000])\n",
      "larger than 0\n"
     ]
    }
   ],
   "source": [
    "def scalar2vector(x, L):\n",
    "    # Check if input is within the expected range\n",
    "    if not -1 <= x < 1:\n",
    "        raise ValueError(\"x must be in the range [-1, 1)\")\n",
    "    if L <= 0:\n",
    "        raise ValueError(\"L must be a positive integer\")\n",
    "    \n",
    "    # Initialize binary and remainder variables\n",
    "    binary = [0] * L\n",
    "    reference = 0.0\n",
    "\n",
    "    # Create binary variables\n",
    "    for i in range(L):\n",
    "        if x >= reference:\n",
    "            binary[i] = 1\n",
    "            if i < L-1:\n",
    "                reference += 0.5**(i+1)\n",
    "        else:\n",
    "            if i < L-1:\n",
    "                reference -= 0.5**(i+1)\n",
    "\n",
    "    # Adjust remainder\n",
    "    remainder = x - reference\n",
    "    remainder *= 2 ** (L - 1)\n",
    "\n",
    "    return (binary, remainder)\n",
    "\n",
    "def vector2scalar(binary, remainder):\n",
    "    L = len(binary)\n",
    "    sum = -1.0\n",
    "    for j, ij in enumerate(binary):\n",
    "        sum += 2.0**(-j)*ij\n",
    "        \n",
    "    sum += remainder*2.0**(1-L)\n",
    "    \n",
    "    return sum\n",
    "\n",
    "x = torch.tensor([0.8])\n",
    "L = 3\n",
    "vec = scalar2vector(x, L)\n",
    "orig = vector2scalar(*vec)\n",
    "print(x)\n",
    "print(vec)\n",
    "print(orig)\n",
    "\n",
    "if x < 0:\n",
    "    print(\"less than 0\")\n",
    "if x > 0:\n",
    "    print(\"larger than 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qulearn.qlayer import CircuitLayer\n",
    "import pennylane as qml\n",
    "\n",
    "class QTT1DEncoding(CircuitLayer):\n",
    "    \n",
    "    def __init__(self, wires, level):\n",
    "        super().__init__(wires)\n",
    "        self.level = level\n",
    "        \n",
    "    def circuit(self, x):\n",
    "        binary, y = scalar2vector(x, self.level)\n",
    "        \n",
    "        for index, b in enumerate(binary):\n",
    "            if b == 1:\n",
    "                qml.PauliX(self.wires[index])\n",
    "                \n",
    "        qml.RZ(0.0, self.wires[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qulearn.qlayer import CircuitLayer, AltRotCXLayer\n",
    "import pennylane as qml\n",
    "from pennylane import IQPEmbedding\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class Hadamards(CircuitLayer):\n",
    "    \n",
    "    def __init__(self, wires):\n",
    "        super().__init__(wires)\n",
    "        \n",
    "    def circuit(self, x):\n",
    "        for wire in self.wires:\n",
    "            qml.Hadamard(wire)\n",
    "\n",
    "class Exp1DEncoding(CircuitLayer):\n",
    "    \n",
    "    def __init__(self, wires):\n",
    "        super().__init__(wires)\n",
    "        \n",
    "    def circuit(self, x):\n",
    "        lrelu = torch.nn.LeakyReLU(0.01)\n",
    "        for j, wire in enumerate(self.wires):\n",
    "            x_ = torch.asin(lrelu(x))\n",
    "            x_ = lrelu(x)\n",
    "            x_ = 2**j*x\n",
    "            qml.RZ(x_.item(), wire)\n",
    "            \n",
    "class ParallelIQPEncoding(CircuitLayer):\n",
    "    \n",
    "    def __init__(self, wires, num_features, omega = 1.0):\n",
    "        super().__init__(wires)\n",
    "        self.num_features = num_features\n",
    "        self.omega = omega\n",
    "        \n",
    "        assert self.num_wires >= self.num_features\n",
    "        assert self.num_wires % self.num_features == 0\n",
    "        \n",
    "    def circuit(self, x):\n",
    "        num_features = x.shape[-1]\n",
    "        assert num_features == self.num_features\n",
    "        \n",
    "        freq = 0\n",
    "        for i in range(0, len(self.wires), num_features):\n",
    "            x_ = 2**(freq*self.omega)*x\n",
    "            qml.IQPEmbedding(x_, wires=self.wires[i: i+num_features])\n",
    "            freq += 1\n",
    "            \n",
    "class ParallelEntangledIQPEncoding(CircuitLayer):\n",
    "    \n",
    "    def __init__(self, wires, num_features, omega = 1.0):\n",
    "        super().__init__(wires)\n",
    "        self.num_features = num_features\n",
    "        self.omega = omega\n",
    "        \n",
    "        assert self.num_wires >= self.num_features\n",
    "        assert self.num_wires % self.num_features == 0\n",
    "        \n",
    "    def circuit(self, x):\n",
    "        num_features = x.shape[-1]\n",
    "        assert num_features == self.num_features\n",
    "        \n",
    "        num_repeats = int(self.num_wires/num_features)\n",
    "        \n",
    "        x_large = []\n",
    "        for j in range(0, num_repeats):\n",
    "            x_ = 2**(j*self.omega)*x\n",
    "            x_large.append(x_)\n",
    "            \n",
    "        x_final = torch.cat(x_large)\n",
    "        qml.IQPEmbedding(x_final, wires=self.wires)\n",
    "        \n",
    "\n",
    "class QuantumKernel(nn.Module):\n",
    "    \n",
    "    def __init__(self, embed, X_train):\n",
    "        super().__init__()\n",
    "        self.embed = embed\n",
    "        self.X_train = X_train\n",
    "        self.num_samples = X_train.shape[0]\n",
    "        self.alpha = nn.Parameter(\n",
    "            torch.empty(\n",
    "                self.num_samples,\n",
    "                device=self.X_train.device,\n",
    "                dtype=self.X_train.dtype,\n",
    "            )\n",
    "        )\n",
    "        nn.init.normal_(self.alpha)\n",
    "        \n",
    "        self.qdevice = qml.device(wires=self.embed.wires, name=\"default.qubit\", shots=None)\n",
    "        self.qnode = self.set_qnode()\n",
    "        \n",
    "    \n",
    "    def kernel_circ(self, x, x_):\n",
    "        self.embed(x)\n",
    "        qml.adjoint(self.embed)(x_)\n",
    "        state = torch.zeros(self.embed.num_wires, dtype=torch.int32, device=x.device)\n",
    "        projector = qml.Projector(state, self.embed.wires)\n",
    "        return qml.expval(projector)\n",
    "    \n",
    "    def kernel_matrix(self, x, x_):\n",
    "        # assert shape has length 2\n",
    "        \n",
    "        K = torch.empty((x.shape[0], x_.shape[0]), dtype=x.dtype, device=x.device)\n",
    "        for i, xi in enumerate(x):\n",
    "            for j, xj in enumerate(x_):\n",
    "                Kij = self.qnode(xi, xj)\n",
    "                K[i, j] = Kij\n",
    "        return K\n",
    "    \n",
    "    def kernel_ridge_regression(self, labels, lambda_reg) -> None:\n",
    "        # sets optimal alpha (closed form solution)\n",
    "        K = self.kernel_matrix(self.X_train, self.X_train)\n",
    "        I = torch.eye(self.num_samples, dtype=labels.dtype, device=labels.device)\n",
    "        M = K+lambda_reg*I\n",
    "        self.alpha = nn.Parameter(torch.linalg.solve(M, labels))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        K = self.kernel_matrix(x, self.X_train)\n",
    "        out = torch.matmul(K, self.alpha)\n",
    "        return out\n",
    "    \n",
    "    def set_qnode(self):\n",
    "        circuit = self.kernel_circ\n",
    "        qnode = qml.QNode(\n",
    "            circuit,\n",
    "            self.qdevice,\n",
    "            interface=\"torch\",\n",
    "            diff_method=\"backprop\"\n",
    "        )\n",
    "        self.qnode = qnode\n",
    "        return self.qnode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one\n"
     ]
    }
   ],
   "source": [
    "from enum import Enum\n",
    "class Test(Enum):\n",
    "    one = 1\n",
    "    two = 2\n",
    "    \n",
    "print(Test.one.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1000, 0.2000, 0.3000]])\n",
      "torch.Size([1, 3])\n"
     ]
    }
   ],
   "source": [
    "x1 = torch.tensor([[0.1]])\n",
    "x2 = torch.tensor([[0.2]])\n",
    "x3 = torch.tensor([[0.3]])\n",
    "x = torch.cat((x1, x2, x3), dim=1)\n",
    "print(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: â”€â”€Hâ”€â”€RZ(0.10)â”€â•­MultiRZ(0.03)â”€â•­MultiRZ(0.02)â”€â•­MultiRZ(0.06)â”€â”€Hâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€RZ(0.10)â”€â”€â”€â”€â”€\n",
      "1: â”€â”€Hâ”€â”€RZ(0.30)â”€â•°MultiRZ(0.03)â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•­MultiRZ(0.06)â”€â•­MultiRZ(0.18)\n",
      "2: â”€â”€Hâ”€â”€RZ(0.20)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•°MultiRZ(0.02)â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•°MultiRZ(0.06)â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "3: â”€â”€Hâ”€â”€RZ(0.60)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•°MultiRZ(0.06)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•°MultiRZ(0.18)\n",
      "\n",
      "â”€â”€â”€RZ(0.20)â€ â”€â”€â”€â”€â”€â”€Hâ€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”€â”€â”€Hâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€RZ(0.30)â”€â”€RZ(0.30)â€ â”€â”€Hâ€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•­MultiRZ(0.18)â€ â”€â•­MultiRZ(0.12)â€ \n",
      "â”€â”€â•­MultiRZ(0.12)â”€â”€Hâ”€â”€â”€â”€â”€â”€â”€â”€â”€RZ(0.20)â”€â”€â”€RZ(0.40)â€ â”€â”€Hâ€ â”€â•­MultiRZ(0.24)â€ â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•°MultiRZ(0.12)â€ \n",
      "â”€â”€â•°MultiRZ(0.12)â”€â”€Hâ”€â”€â”€â”€â”€â”€â”€â”€â”€RZ(0.60)â”€â”€â”€RZ(0.60)â€ â”€â”€Hâ€ â”€â•°MultiRZ(0.24)â€ â”€â•°MultiRZ(0.18)â€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "â”€â”€â•­MultiRZ(0.12)â€ â”€â•­MultiRZ(0.08)â€ â”€â•­MultiRZ(0.06)â€ â”€â”€RZ(0.20)â€ â”€â”€Hâ€ â”€â”¤ â•­<|0000âŸ©âŸ¨0000|>\n",
      "â”€â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•°MultiRZ(0.06)â€ â”€â”€RZ(0.30)â€ â”€â”€Hâ€ â”€â”¤ â”œ<|0000âŸ©âŸ¨0000|>\n",
      "â”€â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•°MultiRZ(0.08)â€ â”€â”€RZ(0.40)â€ â”€â”€â”€â”€â”€â”€â”€Hâ€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”œ<|0000âŸ©âŸ¨0000|>\n",
      "â”€â”€â•°MultiRZ(0.12)â€ â”€â”€RZ(0.60)â€ â”€â”€â”€â”€â”€â”€â”€Hâ€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â•°<|0000âŸ©âŸ¨0000|>\n"
     ]
    }
   ],
   "source": [
    "import pennylane as qml\n",
    "from qulearn.qlayer import ParallelEntangledIQPEncoding, ParallelIQPEncoding, MeasurementLayer, MeasurementType, IQPERYCZLayer, RYCZLayer\n",
    "from qulearn.qkernel import QKernel\n",
    "from qulearn.trainer import RidgeRegression\n",
    "import torch\n",
    "from torch.nn import MSELoss\n",
    "import logging\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "num_features = 2\n",
    "num_feature_repeat = 2\n",
    "wires = num_features*num_feature_repeat\n",
    "embed = ParallelEntangledIQPEncoding(wires, num_features=num_features, omega=1.0, n_repeat=2)\n",
    "var = RYCZLayer(wires=wires, n_layers=1)\n",
    "#embed = IQPERYCZLayer(wires=wires, num_uploads=1, num_varlayers=0, num_repeat=2, omega=1.0)\n",
    "#embed = ParallelIQPEncoding(wires, num_features=1, omega=1.0, n_repeat=2)\n",
    "obs = qml.PauliZ(0)\n",
    "num_samples = 10\n",
    "X_train = torch.randn((num_samples, num_features))\n",
    "labels = torch.randn((num_samples, 1))\n",
    "model = QKernel(embed, X_train)\n",
    "#model = MeasurementLayer(var, embed, measurement_type=MeasurementType.Expectation, observable=obs)\n",
    "drawer = qml.draw(model.qnode, show_all_wires=True, expansion_strategy=\"device\")\n",
    "x1 = torch.tensor([0.1, 0.3])\n",
    "x2 = torch.tensor([0.2, 0.3])\n",
    "print(drawer(x1, x2))\n",
    "\n",
    "# #test = model.qnode(x1, x2)\n",
    "# test = model.kernel_matrix(X_train, X_train)\n",
    "# print(test.shape)\n",
    "# print(test)\n",
    "\n",
    "# predicted = model(X_train)\n",
    "# fn = MSELoss()\n",
    "# loss_before = fn(predicted, labels)\n",
    "\n",
    "# lambda_reg = 1.0\n",
    "# metrics = {\"mse_loss\": fn}\n",
    "# logger = logging.getLogger(__name__)\n",
    "# logger.setLevel(level=logging.INFO)\n",
    "# trainer = RidgeRegression(lambda_reg, metrics, logger)\n",
    "# dataset = TensorDataset(X_train, labels)\n",
    "# train_loader = DataLoader(dataset, batch_size=num_samples)\n",
    "# valid_loader = DataLoader(dataset, batch_size=num_samples)\n",
    "# trainer.train(model, train_loader, valid_loader)\n",
    "\n",
    "# predicted = model(X_train)\n",
    "# loss_after = fn(predicted, labels)\n",
    "\n",
    "# print(f\"Loss before: {loss_before} | Loss after: {loss_after}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([ 0.1966, -0.6014, -1.9185,  1.5255, -0.2749,  0.9446,  1.4418, -0.5243,\n",
      "         1.4246,  0.6802], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([ 0.6956,  1.4973,  0.7855, -0.1049, -0.1006, -1.0421, -2.0959,  1.6524,\n",
      "         0.7331, -0.6246], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "X_train = torch.randn((num_samples, num_features))\n",
    "model.X_train = X_train\n",
    "print(model.alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in model.named_parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1502]], dtype=torch.float64, grad_fn=<StackBackward0>)\n",
      "0: â”€â”€Rot(3.29,1.29,4.89)â”€â•­â—â”€â”€Rot(5.83,4.20,4.55)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•­â—â”€â”€Rot(2.65,1.80,1.61)â”€â”€H\n",
      "1: â”€â”€Rot(4.93,1.90,2.11)â”€â•°Xâ”€â”€Rot(3.50,6.04,2.57)â”€â•­â—â”€â”€Rot(1.05,0.74,2.00)â”€â•°Xâ”€â”€Rot(3.14,2.05,4.68)â”€â•­â—\n",
      "2: â”€â”€Rot(4.15,1.39,1.70)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•°Xâ”€â”€Rot(5.92,1.35,3.28)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•°X\n",
      "\n",
      "â”€â”€â”€RZ(-0.74)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•­MultiRZ(1.10)â”€â•­MultiRZ(2.19)â”€â”€Rot(5.34,5.52,3.31)\n",
      "â”€â”€â”€Rot(5.69,1.43,4.57)â”€â”€Hâ”€â”€RZ(-1.48)â”€â•°MultiRZ(1.10)â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•­MultiRZ(4.38)â”€â”€â”€â”€â”€â”€\n",
      "â”€â”€â”€Rot(3.14,2.17,6.22)â”€â”€Hâ”€â”€RZ(-2.96)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•°MultiRZ(2.19)â”€â•°MultiRZ(4.38)â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•­â—â”€â”€Rot(5.09,2.05,1.73)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•­â—â”€â”€Rot(0.26,1.71,4.18)â”€â”€â”€\n",
      "â”€â”€â”€Rot(0.73,0.65,3.33)â”€â•°Xâ”€â”€Rot(4.81,3.33,3.23)â”€â•­â—â”€â”€Rot(3.59,0.14,4.84)â”€â•°Xâ”€â”€Rot(5.11,0.94,5.60)â”€â•­â—\n",
      "â”€â”€â”€Rot(2.34,0.86,3.43)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•°Xâ”€â”€Rot(2.27,2.83,0.50)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•°X\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  <ğ“—(0.22,-0.18)>\n",
      "â”€â”€â”€Rot(0.48,2.07,4.84)â”€â”¤                 \n",
      "â”€â”€â”€Rot(4.19,3.60,3.65)â”€â”¤                 \n"
     ]
    }
   ],
   "source": [
    "from qulearn.qlayer import HamiltonianLayer, AltRotCXLayer, IQPEmbeddingLayer\n",
    "import torch\n",
    "\n",
    "observables = [qml.PauliZ(0), qml.Identity(0)]#, qml.PauliZ(1), qml.PauliZ(2), qml.PauliZ(3)]\n",
    "wires = 1*3\n",
    "embed = ParallelEntangledIQPEncoding(wires, num_features=1)\n",
    "#embed = ParallelIQPEncoding(wires, num_features=1)\n",
    "varlayer1 = AltRotCXLayer(wires=3, n_layers=2)\n",
    "varlayer2 = AltRotCXLayer(wires=3, n_layers=2)\n",
    "model = HamiltonianLayer(varlayer1, embed, varlayer2, observables=observables)\n",
    "drawer = qml.draw(model.qnode, show_all_wires=True, expansion_strategy=\"device\")\n",
    "\n",
    "x = torch.rand((1, 2))*2.0-1.0\n",
    "x = torch.tensor([[-0.74]])\n",
    "y = model(x)\n",
    "print(y)\n",
    "x_ = x[0]\n",
    "print(drawer(x_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2440]], dtype=torch.float64, grad_fn=<StackBackward0>)\n",
      "0: â”€â”€Hâ”€â”€Rot(4.65,6.05,3.35)â”€â•­â—â”€â”€Rot(5.03,2.60,1.64)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•­â—â”€â”€Rot(5.60,5.53,4.53)\n",
      "1: â”€â”€Hâ”€â”€Rot(1.61,3.54,2.16)â”€â•°Xâ”€â”€Rot(4.84,6.06,1.09)â”€â•­â—â”€â”€Rot(4.01,0.02,0.82)â”€â•°Xâ”€â”€Rot(0.80,0.59,1.19)\n",
      "2: â”€â”€Hâ”€â”€Rot(3.93,5.23,0.30)â”€â•­â—â”€â”€Rot(2.81,2.31,1.08)â”€â•°Xâ”€â”€Rot(4.96,5.36,5.90)â”€â•­â—â”€â”€Rot(5.54,5.53,3.42)\n",
      "3: â”€â”€Hâ”€â”€Rot(5.85,0.61,5.95)â”€â•°Xâ”€â”€Rot(3.72,4.99,3.14)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•°Xâ”€â”€Rot(0.50,1.74,0.20)\n",
      "\n",
      "â”€â”€â”€RZ(-0.74)â”€â”€Rot(0.70,0.49,4.14)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•­â—â”€â”€Rot(1.12,2.04,3.48)â”€â”€â”€\n",
      "â”€â”€â•­â—â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Rot(4.18,5.30,2.82)â”€â”€RZ(-1.48)â”€â”€Rot(4.77,4.37,3.40)â”€â•°Xâ”€â”€Rot(5.90,5.89,3.90)â”€â•­â—\n",
      "â”€â”€â•°Xâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Rot(2.60,2.68,3.42)â”€â”€RZ(-2.96)â”€â”€Rot(2.56,2.86,1.60)â”€â•­â—â”€â”€Rot(5.20,6.03,5.36)â”€â•°X\n",
      "â”€â”€â”€RZ(-5.92)â”€â”€Rot(5.86,2.88,4.09)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•°Xâ”€â”€Rot(0.18,0.46,4.21)â”€â”€â”€\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•­â—â”€â”€Rot(4.87,0.41,2.15)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  <ğ“—(1.45)>\n",
      "â”€â”€â”€Rot(2.50,2.40,0.46)â”€â•°Xâ”€â”€Rot(5.97,6.17,2.62)â”€â•­â—â”€â”€Rot(3.39,3.62,5.26)â”€â”¤           \n",
      "â”€â”€â”€Rot(0.40,3.84,5.58)â”€â•­â—â”€â”€Rot(2.47,4.61,2.68)â”€â•°Xâ”€â”€Rot(4.18,3.25,2.45)â”€â”¤           \n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•°Xâ”€â”€Rot(5.81,4.52,0.87)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤           \n"
     ]
    }
   ],
   "source": [
    "from qulearn.qlayer import HamiltonianLayer, AltRotCXLayer, IQPEmbeddingLayer\n",
    "import torch\n",
    "\n",
    "observables = [qml.PauliZ(0)]#, qml.PauliZ(1), qml.PauliZ(2), qml.PauliZ(3)]\n",
    "#embed = QTT1DEncoding(wires=4, level=3)\n",
    "#embed = IQPEmbeddingLayer(wires=1, n_repeat=1)\n",
    "hads = Hadamards(wires=4)\n",
    "embed = Exp1DEncoding(wires=4)\n",
    "varlayer1 = AltRotCXLayer(wires=4, n_layers=2)\n",
    "varlayer2 = AltRotCXLayer(wires=4, n_layers=2)\n",
    "model = HamiltonianLayer(hads, varlayer1, embed, varlayer2, observables=observables)\n",
    "drawer = qml.draw(model.qnode, show_all_wires=True, expansion_strategy=\"device\")\n",
    "\n",
    "x = torch.rand((1, 1))*2.0-1.0\n",
    "x = torch.tensor([[-0.74]])\n",
    "y = model(x)\n",
    "print(y)\n",
    "print(drawer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "def fourier_series(x, n, c):\n",
    "    \"\"\"\n",
    "    Compute the truncated Fourier series evaluated at an input x.\n",
    "    \"\"\"\n",
    "    k = torch.arange(-n, n+1)\n",
    "    terms = c[k+n]*torch.exp(1j*k*x)\n",
    "    y = torch.real(torch.sum(terms, dim=1))\n",
    "    y = y/torch.max(torch.abs(y))\n",
    "    return y\n",
    "\n",
    "def generate_dataset(num_samples, n, c):\n",
    "    \"\"\"\n",
    "    Generate a dataset of random samples x with corresponding y values evaluated \n",
    "    at x using a truncated Fourier series.\n",
    "    \"\"\"\n",
    "    x = torch.rand(num_samples, 1, dtype=torch.float64)*2.0-1.0\n",
    "    y = fourier_series(x, n, c)\n",
    "    return x, y\n",
    "\n",
    "def get_data_loader(x, y, batch_size=5):\n",
    "    \"\"\"\n",
    "    Convert the dataset into a PyTorch DataLoader.\n",
    "    \"\"\"\n",
    "    dataset = TensorDataset(x.unsqueeze(-1), y.unsqueeze(-1))\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "    return dataloader\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "n = 10  # Number of terms in the Fourier series\n",
    "c_positive = torch.rand(n) + 1j*torch.rand(n)  # Random coefficients for positive k\n",
    "c_negative = torch.conj(c_positive)  # Coefficients for negative k are the conjugate of those for positive k\n",
    "c_positive = c_positive.flip(dims=[0])\n",
    "c_zero = torch.rand(1)  # Coefficient for k=0 is just a real number\n",
    "c = torch.cat((c_negative, c_zero, c_positive))\n",
    "\n",
    "# Generate a dataset and data loader\n",
    "x, y = generate_dataset(25, n, c)\n",
    "y = torch.where(x <= 0, torch.tensor(0, dtype=torch.float64), torch.tensor(1, dtype=torch.float64))\n",
    "dataloader = get_data_loader(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from qulearn.qlayer import MeasurementLayer, MeasurementType, IQPEAltRotCXLayer, HamiltonianLayer\n",
    "num_features = 3\n",
    "interface='torch'\n",
    "diff_method='backprop'\n",
    "qdev = qml.device(\"default.qubit\", wires=num_features, shots=None)\n",
    "circuit = IQPEAltRotCXLayer(wires=num_features, num_uploads=1, num_varlayers=1, num_repeat=3, omega=torch.tensor(0.0))\n",
    "obs = qml.PauliZ(0)\n",
    "model = HamiltonianLayer(circuit, observables=[obs], qdevice=qdev, interface=interface, diff_method=diff_method)\n",
    "drawer = qml.draw(model.qnode, show_all_wires=True, expansion_strategy=\"device\")\n",
    "x = torch.randn(num_features)\n",
    "print(drawer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from qulearn.trainer import SupervisedTrainer\n",
    "import logging\n",
    "opt = Adam(model.parameters(), lr=0.1, amsgrad=True)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "logger = logging.getLogger(\"SupTrainer\")\n",
    "logger.setLevel(level=logging.INFO)\n",
    "trainer = SupervisedTrainer(opt, loss_fn, num_epochs=50, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:SupTrainer:Train - Epoch: 1, Loss: 0.237778, Metrics: \n",
      "INFO:SupTrainer:Validate - Epoch: 1, Loss: 0.237778, Metrics: \n",
      "INFO:SupTrainer:Train - Epoch: 2, Loss: 0.238333, Metrics: \n",
      "INFO:SupTrainer:Validate - Epoch: 2, Loss: 0.238333, Metrics: \n",
      "INFO:SupTrainer:Train - Epoch: 3, Loss: 0.236954, Metrics: \n",
      "INFO:SupTrainer:Validate - Epoch: 3, Loss: 0.236954, Metrics: \n",
      "INFO:SupTrainer:Train - Epoch: 4, Loss: 0.231336, Metrics: \n",
      "INFO:SupTrainer:Validate - Epoch: 4, Loss: 0.231336, Metrics: \n",
      "INFO:SupTrainer:Train - Epoch: 5, Loss: 0.225725, Metrics: \n",
      "INFO:SupTrainer:Validate - Epoch: 5, Loss: 0.225725, Metrics: \n",
      "INFO:SupTrainer:Train - Epoch: 6, Loss: 0.223778, Metrics: \n",
      "INFO:SupTrainer:Validate - Epoch: 6, Loss: 0.223778, Metrics: \n",
      "INFO:SupTrainer:Train - Epoch: 7, Loss: 0.223378, Metrics: \n",
      "INFO:SupTrainer:Validate - Epoch: 7, Loss: 0.223378, Metrics: \n",
      "INFO:SupTrainer:Train - Epoch: 8, Loss: 0.223603, Metrics: \n",
      "INFO:SupTrainer:Validate - Epoch: 8, Loss: 0.223603, Metrics: \n",
      "INFO:SupTrainer:Train - Epoch: 9, Loss: 0.223477, Metrics: \n",
      "INFO:SupTrainer:Validate - Epoch: 9, Loss: 0.223477, Metrics: \n",
      "INFO:SupTrainer:Train - Epoch: 10, Loss: 0.223101, Metrics: \n",
      "INFO:SupTrainer:Validate - Epoch: 10, Loss: 0.223101, Metrics: \n",
      "INFO:SupTrainer:Train - Epoch: 11, Loss: 0.223024, Metrics: \n",
      "INFO:SupTrainer:Validate - Epoch: 11, Loss: 0.223024, Metrics: \n",
      "INFO:SupTrainer:Train - Epoch: 12, Loss: 0.223071, Metrics: \n",
      "INFO:SupTrainer:Validate - Epoch: 12, Loss: 0.223071, Metrics: \n",
      "INFO:SupTrainer:Train - Epoch: 13, Loss: 0.222950, Metrics: \n",
      "INFO:SupTrainer:Validate - Epoch: 13, Loss: 0.222950, Metrics: \n",
      "INFO:SupTrainer:Train - Epoch: 14, Loss: 0.222932, Metrics: \n",
      "INFO:SupTrainer:Validate - Epoch: 14, Loss: 0.222932, Metrics: \n",
      "INFO:SupTrainer:Train - Epoch: 15, Loss: 0.222966, Metrics: \n",
      "INFO:SupTrainer:Validate - Epoch: 15, Loss: 0.222966, Metrics: \n",
      "INFO:SupTrainer:Train - Epoch: 16, Loss: 0.222933, Metrics: \n",
      "INFO:SupTrainer:Validate - Epoch: 16, Loss: 0.222933, Metrics: \n",
      "INFO:SupTrainer:Train - Epoch: 17, Loss: 0.222922, Metrics: \n",
      "INFO:SupTrainer:Validate - Epoch: 17, Loss: 0.222922, Metrics: \n",
      "INFO:SupTrainer:Train - Epoch: 18, Loss: 0.222942, Metrics: \n",
      "INFO:SupTrainer:Validate - Epoch: 18, Loss: 0.222942, Metrics: \n",
      "INFO:SupTrainer:Train - Epoch: 19, Loss: 0.222939, Metrics: \n",
      "INFO:SupTrainer:Validate - Epoch: 19, Loss: 0.222939, Metrics: \n",
      "INFO:SupTrainer:Train - Epoch: 20, Loss: 0.222930, Metrics: \n",
      "INFO:SupTrainer:Validate - Epoch: 20, Loss: 0.222930, Metrics: \n",
      "INFO:SupTrainer:Train - Epoch: 21, Loss: 0.222942, Metrics: \n",
      "INFO:SupTrainer:Validate - Epoch: 21, Loss: 0.222942, Metrics: \n",
      "INFO:SupTrainer:Train - Epoch: 22, Loss: 0.222948, Metrics: \n",
      "INFO:SupTrainer:Validate - Epoch: 22, Loss: 0.222948, Metrics: \n",
      "INFO:SupTrainer:Train - Epoch: 23, Loss: 0.222942, Metrics: \n",
      "INFO:SupTrainer:Validate - Epoch: 23, Loss: 0.222942, Metrics: \n",
      "INFO:SupTrainer:Train - Epoch: 24, Loss: 0.222942, Metrics: \n",
      "INFO:SupTrainer:Validate - Epoch: 24, Loss: 0.222942, Metrics: \n",
      "INFO:SupTrainer:Train - Epoch: 25, Loss: 0.222946, Metrics: \n",
      "INFO:SupTrainer:Validate - Epoch: 25, Loss: 0.222946, Metrics: \n",
      "INFO:SupTrainer:Train - Epoch: 26, Loss: 0.222946, Metrics: \n",
      "INFO:SupTrainer:Validate - Epoch: 26, Loss: 0.222946, Metrics: \n",
      "INFO:SupTrainer:Train - Epoch: 27, Loss: 0.222946, Metrics: \n",
      "INFO:SupTrainer:Validate - Epoch: 27, Loss: 0.222946, Metrics: \n",
      "INFO:SupTrainer:Train - Epoch: 28, Loss: 0.222948, Metrics: \n",
      "INFO:SupTrainer:Validate - Epoch: 28, Loss: 0.222948, Metrics: \n",
      "INFO:SupTrainer:Train - Epoch: 29, Loss: 0.222949, Metrics: \n",
      "INFO:SupTrainer:Validate - Epoch: 29, Loss: 0.222949, Metrics: \n",
      "INFO:SupTrainer:Train - Epoch: 30, Loss: 0.222948, Metrics: \n",
      "INFO:SupTrainer:Validate - Epoch: 30, Loss: 0.222948, Metrics: \n",
      "INFO:SupTrainer:Train - Epoch: 31, Loss: 0.222949, Metrics: \n",
      "INFO:SupTrainer:Validate - Epoch: 31, Loss: 0.222949, Metrics: \n",
      "INFO:SupTrainer:Train - Epoch: 32, Loss: 0.222950, Metrics: \n",
      "INFO:SupTrainer:Validate - Epoch: 32, Loss: 0.222950, Metrics: \n",
      "INFO:SupTrainer:Train - Epoch: 33, Loss: 0.222950, Metrics: \n",
      "INFO:SupTrainer:Validate - Epoch: 33, Loss: 0.222950, Metrics: \n",
      "INFO:SupTrainer:Train - Epoch: 34, Loss: 0.222951, Metrics: \n",
      "INFO:SupTrainer:Validate - Epoch: 34, Loss: 0.222951, Metrics: \n",
      "INFO:SupTrainer:Train - Epoch: 35, Loss: 0.222952, Metrics: \n",
      "INFO:SupTrainer:Validate - Epoch: 35, Loss: 0.222952, Metrics: \n",
      "INFO:SupTrainer:Train - Epoch: 36, Loss: 0.222952, Metrics: \n",
      "INFO:SupTrainer:Validate - Epoch: 36, Loss: 0.222952, Metrics: \n",
      "INFO:SupTrainer:Train - Epoch: 37, Loss: 0.222952, Metrics: \n",
      "INFO:SupTrainer:Validate - Epoch: 37, Loss: 0.222952, Metrics: \n",
      "INFO:SupTrainer:Train - Epoch: 38, Loss: 0.222953, Metrics: \n",
      "INFO:SupTrainer:Validate - Epoch: 38, Loss: 0.222953, Metrics: \n",
      "INFO:SupTrainer:Train - Epoch: 39, Loss: 0.222953, Metrics: \n",
      "INFO:SupTrainer:Validate - Epoch: 39, Loss: 0.222953, Metrics: \n",
      "INFO:SupTrainer:Train - Epoch: 40, Loss: 0.222954, Metrics: \n",
      "INFO:SupTrainer:Validate - Epoch: 40, Loss: 0.222954, Metrics: \n",
      "INFO:SupTrainer:Train - Epoch: 41, Loss: 0.222954, Metrics: \n",
      "INFO:SupTrainer:Validate - Epoch: 41, Loss: 0.222954, Metrics: \n",
      "INFO:SupTrainer:Train - Epoch: 42, Loss: 0.222954, Metrics: \n",
      "INFO:SupTrainer:Validate - Epoch: 42, Loss: 0.222954, Metrics: \n",
      "INFO:SupTrainer:Train - Epoch: 43, Loss: 0.222955, Metrics: \n",
      "INFO:SupTrainer:Validate - Epoch: 43, Loss: 0.222955, Metrics: \n",
      "INFO:SupTrainer:Train - Epoch: 44, Loss: 0.222955, Metrics: \n",
      "INFO:SupTrainer:Validate - Epoch: 44, Loss: 0.222955, Metrics: \n",
      "INFO:SupTrainer:Train - Epoch: 45, Loss: 0.222955, Metrics: \n",
      "INFO:SupTrainer:Validate - Epoch: 45, Loss: 0.222955, Metrics: \n",
      "INFO:SupTrainer:Train - Epoch: 46, Loss: 0.222955, Metrics: \n",
      "INFO:SupTrainer:Validate - Epoch: 46, Loss: 0.222955, Metrics: \n",
      "INFO:SupTrainer:Train - Epoch: 47, Loss: 0.222956, Metrics: \n",
      "INFO:SupTrainer:Validate - Epoch: 47, Loss: 0.222956, Metrics: \n",
      "INFO:SupTrainer:Train - Epoch: 48, Loss: 0.222956, Metrics: \n",
      "INFO:SupTrainer:Validate - Epoch: 48, Loss: 0.222956, Metrics: \n",
      "INFO:SupTrainer:Train - Epoch: 49, Loss: 0.222956, Metrics: \n",
      "INFO:SupTrainer:Validate - Epoch: 49, Loss: 0.222956, Metrics: \n",
      "INFO:SupTrainer:Train - Epoch: 50, Loss: 0.222956, Metrics: \n",
      "INFO:SupTrainer:Validate - Epoch: 50, Loss: 0.222956, Metrics: \n"
     ]
    }
   ],
   "source": [
    "trainer.train(model, dataloader, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qulearn.fat import fat_shattering_dim\n",
    "from qulearn.datagen import DataGenFat, UniformPrior\n",
    "prior = UniformPrior(sizex=num_features, seed=0)\n",
    "gamma=0.1\n",
    "datagen = DataGenFat(prior=prior, Sb=10, Sr=5, gamma=2.0*gamma, seed=0, batch_size=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = fat_shattering_dim(model, datagen=datagen, trainer=trainer, dmin=1, dmax=100, gamma=gamma, dstep=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qulearn.fat import check_shattering\n",
    "#check = check_shattering(model, datagen, trainer, 1, gamma=gamma)\n",
    "#print(check)\n",
    "print(dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dim)\n",
    "data = datagen.gen_data(1)\n",
    "loader = datagen.data_to_loader(data, 0, 1)\n",
    "for x, y in loader:\n",
    "    print(x)\n",
    "    print(y)\n",
    "print(data[\"b\"])\n",
    "print(data[\"r\"])\n",
    "print(0.07260766+gamma*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# assuming model is your pytorch model\n",
    "# model = ...\n",
    "\n",
    "# Generate 100 random inputs between -1 and 1\n",
    "inputs = torch.linspace(-1, 0.99, 100)\n",
    "inputs = inputs.unsqueeze(-1)\n",
    "\n",
    "# Ensure the model is in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Disable gradient calculations\n",
    "with torch.no_grad():\n",
    "    # Run the inputs through the model\n",
    "    outputs = model(inputs)\n",
    "\n",
    "# Convert tensors to numpy arrays for plotting\n",
    "inputs = inputs.numpy()\n",
    "outputs = outputs.numpy()\n",
    "\n",
    "# Create the scatter plot\n",
    "plt.scatter(inputs, outputs)\n",
    "#plt.scatter(x, y)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAoaklEQVR4nO3df3RU9Z3/8dckJBmimQk05geY8kuLpkHCDxPDWunWWNJlU7rds4taIdJKtyy1rrGupBWyYGtwcVm+R6m4noA9x+1C5YsiR4xu8y1nSzeaLT8qEKCiEVCTQIxMAkiQmc/3DzYjQ34wM0nmk5k8H+fMOfCZz535vOfO5L7m3vu54zDGGAEAAFgSZ3sAAABgaCOMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALBqmO0BBMPn8+mjjz5SSkqKHA6H7eEAAIAgGGPU3t6uUaNGKS6u5/0fURFGPvroI2VnZ9seBgAACMPx48d17bXX9nh/VISRlJQUSReLcblclkcDAACC0dbWpuzsbP92vCdREUY6D824XC7CCAAAUeZKp1hwAisAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArAorjKxdu1Zjx46V0+lUQUGB6urqeu2/Zs0aTZw4UcOHD1d2drYefPBBnTt3LqwBAwCA2BJyGNm0aZPKyspUUVGh3bt3a/LkyZo1a5ZOnDjRbf9f/epXWrJkiSoqKnTw4EFVVVVp06ZN+slPftLnwQMAgOjnMMaYUBYoKCjQzTffrKefflrSxd+Nyc7O1v33368lS5Z06f/DH/5QBw8eVE1Njb/toYce0ltvvaWdO3cG9ZxtbW1yu93yeDxc9AxAVPP6jOoaWnWi/ZzSU5zKHzdSkgLapo0ZoV1HP+lzn4F87O76xMfx22EIFOz2O6QrsJ4/f167du1SeXm5vy0uLk5FRUWqra3tdpkZM2bohRdeUF1dnfLz8/Xee+9p+/btmjdvXihPDQBRr3p/o5Zvq1ej5/PD1KnJCZKkU2c/87fFOSTfJV8Tw+0zkI99eZ8st1MVJTkqzs3qoXqgZyGFkZaWFnm9XmVkZAS0Z2Rk6NChQ90uc/fdd6ulpUW33nqrjDG6cOGCfvCDH/R6mKajo0MdHR3+/7e1tYUyTAAYdKr3N2rRC7t1+a7oSzfwnXymf/oM5GNf3qfJc06LXtitZ+6ZSiBByAZ8Ns2OHTv0+OOP6xe/+IV2796tLVu26NVXX9Vjjz3W4zKVlZVyu93+G7/YCyCaeX1Gy7fVdwkisaSztuXb6uW9PKkAVxBSGElLS1N8fLyam5sD2pubm5WZmdntMkuXLtW8efN03333adKkSfqrv/orPf7446qsrJTP5+t2mfLycnk8Hv/t+PHjoQwTAAaVuobWgEMzscpIavScU11Dq+2hIMqEFEYSExM1bdq0gJNRfT6fampqVFhY2O0yZ8+eVVxc4NPEx8dLkno6dzYpKcn/C738Ui+AaHeiPfaDyKWGWr3ou5DOGZGksrIylZaWavr06crPz9eaNWt05swZLViwQJI0f/58jR49WpWVlZKkkpISrV69WlOmTFFBQYGOHDmipUuXqqSkxB9KgHBFcmaC7dkLzFaIXukpTttDiKihVi/6LuQwMnfuXJ08eVLLli1TU1OT8vLyVF1d7T+p9dixYwF7Qh599FE5HA49+uij+vDDD3XNNdeopKREP//5z/uvCgxJkZ6ZYHv2ArMVolf+uJHKcjvV5DkX0+eNOCRluj8P00CwQr7OiA1cZwSX62lmQizr3CfCbIXo1PmelRST71ven+hOsNtvfpsGUWcozEzoDrMVoltxbpaeuWeqMt2BhzBSkxP8e8I6XX40Ltw+A/nYl/fJdDsJIghbyIdpANuGysyE7lw6W6FwwhdsDwchKs7N0h05mVyBFbgMh2kQdbbu/VAPbNxrexhW/Z878zQnb7TtYQBArzhMg5jFmfq8BgBiC2EEUadzZsJQ3CHs0MVZNcxWABBLCCOIOvFxDlWU5EjSkAoknbVWlORwbB5ATCGMICrZmJlge/YCsxUAxCpm0yBqRXpmgu3ZC8xWABCrmE0DAAAGBLNpAABAVCCMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsCiuMrF27VmPHjpXT6VRBQYHq6up67PvVr35VDoejy2327NlhDxoAAMSOkMPIpk2bVFZWpoqKCu3evVuTJ0/WrFmzdOLEiW77b9myRY2Njf7b/v37FR8fr7/5m7/p8+ABAED0CzmMrF69WgsXLtSCBQuUk5OjdevWKTk5WevXr++2/8iRI5WZmem//ed//qeSk5MJIwAAQFKIYeT8+fPatWuXioqKPn+AuDgVFRWptrY2qMeoqqrSnXfeqauuuqrHPh0dHWprawu4AQCA2BRSGGlpaZHX61VGRkZAe0ZGhpqamq64fF1dnfbv36/77ruv136VlZVyu93+W3Z2dijDBAAAUSSis2mqqqo0adIk5efn99qvvLxcHo/Hfzt+/HiERggAACJtWCid09LSFB8fr+bm5oD25uZmZWZm9rrsmTNntHHjRq1YseKKz5OUlKSkpKRQhgYAAKJUSHtGEhMTNW3aNNXU1PjbfD6fampqVFhY2OuyL774ojo6OnTPPfeEN1IAABCTQtozIkllZWUqLS3V9OnTlZ+frzVr1ujMmTNasGCBJGn+/PkaPXq0KisrA5arqqrSt771LX3hC1/on5EDAICYEHIYmTt3rk6ePKlly5apqalJeXl5qq6u9p/UeuzYMcXFBe5wOXz4sHbu3Kk33nijf0YNAABihsMYY2wP4kra2trkdrvl8XjkcrlsDwcAAAQh2O03v00DAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsGmZ7AADg9RnVNbTqRPs5pac4lT9upCQFtE0bM0K7jn4yaPr0Zbn4OEdEX19gsCOMALCqen+jlm+rV6PnnL8tNTlBknTq7Gf+tjiH5DMaNH3CXS7L7VRFSY6Kc7ME4CKHMcZcuZtdbW1tcrvd8ng8crlctocDoJ9U72/Uohd2a9D/EepHnftEnrlnKoEEMS/Y7TfnjACwwuszWr6tfkgFEUn+epdvq5fXN9SqB7pHGAFgRV1Da8ChmaHESGr0nFNdQ6vtoQCDAmEEgBUn2odmELkUrwFwEWEEgBXpKU7bQ7CO1wC4iDACwIr8cSOV5XZqKE5ydejirJrOqb/AUEcYAWBFfJxDFSU5kjSkAklnrRUlOVxvBPhfhBEA1hTnZumZe6Yq0x14uCI1OcF/jY5Ol2+3bfcJd7lMt5NpvcBluOgZAKuKc7N0R04mV2AFhjAuegYAAAYEFz0DAABRgTACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwKqwwsnbtWo0dO1ZOp1MFBQWqq6vrtf+pU6e0ePFiZWVlKSkpSV/60pe0ffv2sAYMAABiy7BQF9i0aZPKysq0bt06FRQUaM2aNZo1a5YOHz6s9PT0Lv3Pnz+vO+64Q+np6dq8ebNGjx6to0ePKjU1tT/GDwAAopzDGGNCWaCgoEA333yznn76aUmSz+dTdna27r//fi1ZsqRL/3Xr1mnVqlU6dOiQEhISwhpkW1ub3G63PB6PXC5XWI8BAAAiK9jtd0iHac6fP69du3apqKjo8weIi1NRUZFqa2u7XeaVV15RYWGhFi9erIyMDOXm5urxxx+X1+vt8Xk6OjrU1tYWcAMAALEppDDS0tIir9erjIyMgPaMjAw1NTV1u8x7772nzZs3y+v1avv27Vq6dKn+5V/+RT/72c96fJ7Kykq53W7/LTs7O5RhAgCAKDLgs2l8Pp/S09P1b//2b5o2bZrmzp2rn/70p1q3bl2Py5SXl8vj8fhvx48fH+hhAgAAS0I6gTUtLU3x8fFqbm4OaG9ublZmZma3y2RlZSkhIUHx8fH+thtvvFFNTU06f/68EhMTuyyTlJSkpKSkUIYGAACiVEh7RhITEzVt2jTV1NT423w+n2pqalRYWNjtMn/2Z3+mI0eOyOfz+dv+9Kc/KSsrq9sgAgAAhpaQD9OUlZXpueee0y9/+UsdPHhQixYt0pkzZ7RgwQJJ0vz581VeXu7vv2jRIrW2tuqBBx7Qn/70J7366qt6/PHHtXjx4v6rAgAARK2QrzMyd+5cnTx5UsuWLVNTU5Py8vJUXV3tP6n12LFjiov7PONkZ2fr9ddf14MPPqibbrpJo0eP1gMPPKBHHnmk/6oAAABRK+TrjNjAdUYAAIg+A3KdEQAAgP5GGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYNUw2wMAAMQGr8+orqFVJ9rPKT3FqWljRmjX0U/8/88fN1KSAvp01xbMcpHs01NbfJwjoq9vLCOMAAD6rHp/o5Zvq1ej55y/Lc4h+cznfVKTEyRJp85+1mtbMMtFsk93bVlupypKclScmyX0ncMYY67cza62tja53W55PB65XC7bwwEAXKJ6f6MWvbBbg35j0o8694k8c89UAkkvgt1+c84IACBsXp/R8m31QyqISPLXu3xbvby+oVZ9/yOMAADCVtfQGnBoZigxkho951TX0Gp7KFGPMAIACNuJ9qEZRC7Fa9B3hBEAQNjSU5y2h2Adr0HfEUYAAGHLHzdSWW6nhuIkV4cuzqrpnPqL8BFGAABhi49zqKIkR5KGVCDprLWiJIfrjfQDwggAoE+Kc7P0zD1TlekOPFxx+TY6NTnBf82O3tqCWS6Sfbpry3Q7mdbbj7joGQCgz4pzs3RHTiZXYEVYuOgZAAAYEFz0DAAARAXCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMCqsMLI2rVrNXbsWDmdThUUFKiurq7Hvs8//7wcDkfAzel0hj1gAAAQW0IOI5s2bVJZWZkqKiq0e/duTZ48WbNmzdKJEyd6XMblcqmxsdF/O3r0aJ8GDQAAYkfIYWT16tVauHChFixYoJycHK1bt07Jyclav359j8s4HA5lZmb6bxkZGX0aNAAAiB0hhZHz589r165dKioq+vwB4uJUVFSk2traHpc7ffq0xowZo+zsbM2ZM0cHDhwIf8QAACCmhBRGWlpa5PV6u+zZyMjIUFNTU7fLTJw4UevXr9fWrVv1wgsvyOfzacaMGfrggw96fJ6Ojg61tbUF3AAAQGwa8Nk0hYWFmj9/vvLy8jRz5kxt2bJF11xzjZ599tkel6msrJTb7fbfsrOzB3qYAADAkpDCSFpamuLj49Xc3BzQ3tzcrMzMzKAeIyEhQVOmTNGRI0d67FNeXi6Px+O/HT9+PJRhAgCAKBJSGElMTNS0adNUU1Pjb/P5fKqpqVFhYWFQj+H1erVv3z5lZWX12CcpKUkulyvgBgAAYtOwUBcoKytTaWmppk+frvz8fK1Zs0ZnzpzRggULJEnz58/X6NGjVVlZKUlasWKFbrnlFl133XU6deqUVq1apaNHj+q+++7r30oAAEBUCjmMzJ07VydPntSyZcvU1NSkvLw8VVdX+09qPXbsmOLiPt/h8sknn2jhwoVqamrSiBEjNG3aNP33f/+3cnJy+q8KAAAQtRzGGGN7EFfS1tYmt9stj8fDIRsAAKJEsNtvfpsGAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVw2wPAAPP6zOqa2jVifZzSk9xKn/cSEm6Ytu0MSO06+gng6ZPT23xcY6Ivp4AgP5FGIlx1fsbtXxbvRo95/xtqckJkqRTZz/rtS3OIfmMBk2f7tqy3E5VlOSoODer2/oBAIOfwxhjrtzNrra2Nrndbnk8HrlcLtvDiRrV+xu16IXdGvQruA8694k8c89UAgkADDLBbr+H7J6RYA5dDOThhYE+vPHmux9ryf/dF9NBRJKMLgaS5dvqdUdOJodsACAKDckwEuyhi4E8vBDJwxuxzkhq9JxTXUOrCid8wfZwAAwBkfxCG+kvvTa+1A25MNLToYvuNt4+0z99BvKxg+kzVJxoP3flTgDQR5H+QhvJL722zsMbUlN7vT6j5dvqY/7QxVCVnuK0PQQAMa7zC+2lQUS6uIG//Mtgd18WB6pPfz12k+ecFr2wW9X7GxVJQyqM1DW0dnkDIfo5dDHNd+6CBICBMBS+0HbWtnxbvbyXJ5UBNKTCCLvxY0/nkc2KkhxOXgUwoIbKF9pLz8OLlCEVRtiNf1FqcoL/2GFvbZdv22336a4t0+1kWi+AiBhqX2gjWe+QOoE1f9xIZbmdavKci+ndbD1JHZ6gtd+ZqlvGX5xxMpjOBOcKrAAGu6H2hTaS9YZ10bO1a9dq1apVampq0uTJk/XUU08pPz//istt3LhRd911l+bMmaOXX3456Ofrz4uedZ58JGnIBBIuDAYAfef1Gd36xP+L+S+0Dl3c67zzka/1+ctesNvvkA/TbNq0SWVlZaqoqNDu3bs1efJkzZo1SydOnOh1uffff18//vGP9ZWvfCXUp+xXxblZeuaeqcp0Bya+SB9eiOThDQ5lAEDfxcc5VFGSI+nzL3mxxtZ5eCHvGSkoKNDNN9+sp59+WpLk8/mUnZ2t+++/X0uWLOl2Ga/Xq9tuu03f/e539bvf/U6nTp2ytmfEP6YYvwIrhzIAYGBwnZHgBbv9DimMnD9/XsnJydq8ebO+9a1v+dtLS0t16tQpbd26tdvlKioq9Pbbb+ull17Svffee8Uw0tHRoY6OjoBisrOz+W0aAMCgwBVYgzMgv03T0tIir9erjIyMgPaMjAwdOnSo22V27typqqoq7d27N+jnqays1PLly0MZGgAAERMf5+j25ycub4tkn/587Egb0Km97e3tmjdvnp577jmlpaUFvVx5ebk8Ho//dvz48QEcJQAAsCmkPSNpaWmKj49Xc3NzQHtzc7MyMzO79H/33Xf1/vvvq6SkxN/m8/kuPvGwYTp8+LAmTJjQZbmkpCQlJSWFMjQAABClQtozkpiYqGnTpqmmpsbf5vP5VFNTo8LCwi79b7jhBu3bt0979+713775zW/qz//8z7V3715lZ2f3vQIAABDVQr7oWVlZmUpLSzV9+nTl5+drzZo1OnPmjBYsWCBJmj9/vkaPHq3Kyko5nU7l5uYGLJ+amipJXdoBAMDQFHIYmTt3rk6ePKlly5apqalJeXl5qq6u9p/UeuzYMcXFDamrzAMAgD4I6wqskTYQ1xkBAAADa8CuwAoAANCfCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsGmZ7AACC4/UZ1TW06kT7OaWnOJU/bqQkBbRNGzNCu45+0mufcJcbyD7xcY5Iv5wABhHCCBAFqvc3avm2ejV6zvnbUpMTJEmnzn7mb4tzSD6jXvuEu9xA9clyO1VRkqPi3KweqgcQ6xzGGHPlbna1tbXJ7XbL4/HI5XLZHg4QUdX7G7Xohd0a9B/UMHXuE3nmnqkEEiDGBLv95pwRYBDz+oyWb6uP2SAiyV/b8m318vpiuVIAPSGMAINYXUNrwKGZWGUkNXrOqa6h1fZQAFhAGAEGsRPtsR9ELjXU6gVwEWEEGMTSU5y2hxBRQ61eABcRRoBBLH/cSGW5nYr1ia8OXZxV0zkVGMDQQhgBBrH4OIcqSnIkKWYDSWddFSU5XG8EGKIII8AgV5ybpWfumapMd+AhjNTkBP91PDpdvi3vrk+4yw1Un0y3k2m9wBDHRc+AKFCcm6U7cjK5AiuAmMRFzwAAwIDgomcAACAqEEYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVkXF5eA7LxLb1tZmeSQAACBYndvtK13sPSrCSHt7uyQpOzvb8kgAAECo2tvb5Xa7e7w/Kn6bxufz6aOPPlJKSoocjv77Qa22tjZlZ2fr+PHjMfubN9QY/WK9PokaY0Gs1yfFfo0DUZ8xRu3t7Ro1apTi4no+MyQq9ozExcXp2muvHbDHd7lcMfnGuhQ1Rr9Yr0+ixlgQ6/VJsV9jf9fX2x6RTpzACgAArCKMAAAAq4Z0GElKSlJFRYWSkpJsD2XAUGP0i/X6JGqMBbFenxT7NdqsLypOYAUAALFrSO8ZAQAA9hFGAACAVYQRAABgFWEEAABYFfNh5Oc//7lmzJih5ORkpaamBrWMMUbLli1TVlaWhg8frqKiIr3zzjsBfVpbW/Wd73xHLpdLqamp+t73vqfTp08PQAW9C3Uc77//vhwOR7e3F1980d+vu/s3btwYiZK6COe1/upXv9pl/D/4wQ8C+hw7dkyzZ89WcnKy0tPT9fDDD+vChQsDWUqPQq2xtbVV999/vyZOnKjhw4fri1/8on70ox/J4/EE9LO1HteuXauxY8fK6XSqoKBAdXV1vfZ/8cUXdcMNN8jpdGrSpEnavn17wP3BfCYjLZQan3vuOX3lK1/RiBEjNGLECBUVFXXpf++993ZZV8XFxQNdRq9CqfH555/vMn6n0xnQZ7Ctx1Dq6+5visPh0OzZs/19Bts6/K//+i+VlJRo1KhRcjgcevnll6+4zI4dOzR16lQlJSXpuuuu0/PPP9+lT6if76CYGLds2TKzevVqU1ZWZtxud1DLrFy50rjdbvPyyy+bP/7xj+ab3/ymGTdunPn000/9fYqLi83kyZPNm2++aX73u9+Z6667ztx1110DVEXPQh3HhQsXTGNjY8Bt+fLl5uqrrzbt7e3+fpLMhg0bAvpdWn8khfNaz5w50yxcuDBg/B6Px3//hQsXTG5urikqKjJ79uwx27dvN2lpaaa8vHygy+lWqDXu27fPfPvb3zavvPKKOXLkiKmpqTHXX3+9+eu//uuAfjbW48aNG01iYqJZv369OXDggFm4cKFJTU01zc3N3fb//e9/b+Lj480///M/m/r6evPoo4+ahIQEs2/fPn+fYD6TkRRqjXfffbdZu3at2bNnjzl48KC59957jdvtNh988IG/T2lpqSkuLg5YV62trZEqqYtQa9ywYYNxuVwB429qagroM5jWY6j1ffzxxwG17d+/38THx5sNGzb4+wy2dbh9+3bz05/+1GzZssVIMi+99FKv/d977z2TnJxsysrKTH19vXnqqadMfHy8qa6u9vcJ9XULVsyHkU4bNmwIKoz4fD6TmZlpVq1a5W87deqUSUpKMv/xH/9hjDGmvr7eSDL/8z//4+/z2muvGYfDYT788MN+H3tP+msceXl55rvf/W5AWzBv3EgIt8aZM2eaBx54oMf7t2/fbuLi4gL+WD7zzDPG5XKZjo6Ofhl7sPprPf761782iYmJ5rPPPvO32ViP+fn5ZvHixf7/e71eM2rUKFNZWdlt/7/92781s2fPDmgrKCgwf/d3f2eMCe4zGWmh1ni5CxcumJSUFPPLX/7S31ZaWmrmzJnT30MNW6g1Xulv7GBbj31dh//6r/9qUlJSzOnTp/1tg20dXiqYvwX/+I//aL785S8HtM2dO9fMmjXL//++vm49ifnDNKFqaGhQU1OTioqK/G1ut1sFBQWqra2VJNXW1io1NVXTp0/39ykqKlJcXJzeeuutiI21P8axa9cu7d27V9/73ve63Ld48WKlpaUpPz9f69evv+JPQA+EvtT47//+70pLS1Nubq7Ky8t19uzZgMedNGmSMjIy/G2zZs1SW1ubDhw40P+F9KK/3k8ej0cul0vDhgX+5FQk1+P58+e1a9eugM9PXFycioqK/J+fy9XW1gb0ly6ui87+wXwmIymcGi939uxZffbZZxo5cmRA+44dO5Senq6JEydq0aJF+vjjj/t17MEKt8bTp09rzJgxys7O1pw5cwI+S4NpPfbHOqyqqtKdd96pq666KqB9sKzDcFzps9gfr1tPouKH8iKpqalJkgI2Up3/77yvqalJ6enpAfcPGzZMI0eO9PeJhP4YR1VVlW688UbNmDEjoH3FihX62te+puTkZL3xxhv6+7//e50+fVo/+tGP+m38wQi3xrvvvltjxozRqFGj9Pbbb+uRRx7R4cOHtWXLFv/jdreOO++LpP5Yjy0tLXrsscf0/e9/P6A90uuxpaVFXq+329f20KFD3S7T07q49PPW2dZTn0gKp8bLPfLIIxo1alTAH/Xi4mJ9+9vf1rhx4/Tuu+/qJz/5ib7xjW+otrZW8fHx/VrDlYRT48SJE7V+/XrddNNN8ng8evLJJzVjxgwdOHBA11577aBaj31dh3V1ddq/f7+qqqoC2gfTOgxHT5/FtrY2ffrpp/rkk0/6/N7vSVSGkSVLluiJJ57otc/Bgwd1ww03RGhE/SvY+vrq008/1a9+9SstXbq0y32Xtk2ZMkVnzpzRqlWr+m0jNtA1XrpRnjRpkrKysnT77bfr3Xff1YQJE8J+3FBEaj22tbVp9uzZysnJ0T/90z8F3DfQ6xGhW7lypTZu3KgdO3YEnOB55513+v89adIk3XTTTZowYYJ27Nih22+/3cZQQ1JYWKjCwkL//2fMmKEbb7xRzz77rB577DGLI+t/VVVVmjRpkvLz8wPao30d2hSVYeShhx7Svffe22uf8ePHh/XYmZmZkqTm5mZlZWX525ubm5WXl+fvc+LEiYDlLly4oNbWVv/yfRFsfX0dx+bNm3X27FnNnz//in0LCgr02GOPqaOjo19+tyBSNXYqKCiQJB05ckQTJkxQZmZmlzPAm5ubJalf1qEUmRrb29tVXFyslJQUvfTSS0pISOi1f3+vx8ulpaUpPj7e/1p2am5u7rGWzMzMXvsH85mMpHBq7PTkk09q5cqV+s1vfqObbrqp177jx49XWlqajhw5EvENWV9q7JSQkKApU6boyJEjkgbXeuxLfWfOnNHGjRu1YsWKKz6PzXUYjp4+iy6XS8OHD1d8fHyf3xc96tMZJ1Ek1BNYn3zySX+bx+Pp9gTWP/zhD/4+r7/+urUTWMMdx8yZM7vMvujJz372MzNixIiwxxqu/nqtd+7caSSZP/7xj8aYz09gvfQM8Geffda4XC5z7ty5/isgCOHW6PF4zC233GJmzpxpzpw5E9RzRWI95ufnmx/+8If+/3u9XjN69OheT2D9y7/8y4C2wsLCLiew9vaZjLRQazTGmCeeeMK4XC5TW1sb1HMcP37cOBwOs3Xr1j6PNxzh1HipCxcumIkTJ5oHH3zQGDP41mO49W3YsMEkJSWZlpaWKz6H7XV4KQV5Amtubm5A21133dXlBNa+vC96HF+flo4CR48eNXv27PFPX92zZ4/Zs2dPwDTWiRMnmi1btvj/v3LlSpOammq2bt1q3n77bTNnzpxup/ZOmTLFvPXWW2bnzp3m+uuvtza1t7dxfPDBB2bixInmrbfeCljunXfeMQ6Hw7z22mtdHvOVV14xzz33nNm3b5955513zC9+8QuTnJxsli1bNuD1dCfUGo8cOWJWrFhh/vCHP5iGhgazdetWM378eHPbbbf5l+mc2vv1r3/d7N2711RXV5trrrnG6tTeUGr0eDymoKDATJo0yRw5ciRgKuGFCxeMMfbW48aNG01SUpJ5/vnnTX19vfn+979vUlNT/TOX5s2bZ5YsWeLv//vf/94MGzbMPPnkk+bgwYOmoqKi26m9V/pMRlKoNa5cudIkJiaazZs3B6yrzr9D7e3t5sc//rGpra01DQ0N5je/+Y2ZOnWquf766yMejsOtcfny5eb111837777rtm1a5e58847jdPpNAcOHPD3GUzrMdT6Ot16661m7ty5XdoH4zpsb2/3b/MkmdWrV5s9e/aYo0ePGmOMWbJkiZk3b56/f+fU3ocfftgcPHjQrF27ttupvb29buGK+TBSWlpqJHW5/fa3v/X30f9ei6GTz+czS5cuNRkZGSYpKcncfvvt5vDhwwGP+/HHH5u77rrLXH311cblcpkFCxYEBJxIudI4GhoautRrjDHl5eUmOzvbeL3eLo/52muvmby8PHP11Vebq666ykyePNmsW7eu276REGqNx44dM7fddpsZOXKkSUpKMtddd515+OGHA64zYowx77//vvnGN75hhg8fbtLS0sxDDz0UMC02kkKt8be//W2372tJpqGhwRhjdz0+9dRT5otf/KJJTEw0+fn55s033/TfN3PmTFNaWhrQ/9e//rX50pe+ZBITE82Xv/xl8+qrrwbcH8xnMtJCqXHMmDHdrquKigpjjDFnz541X//6180111xjEhISzJgxY8zChQv7/Ae+r0Kp8R/+4R/8fTMyMsxf/MVfmN27dwc83mBbj6G+Tw8dOmQkmTfeeKPLYw3GddjT34nOukpLS83MmTO7LJOXl2cSExPN+PHjA7aNnXp73cLlMMbCfE0AAID/xXVGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVv1/PB1fQRt8xYYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(inputs, outputs)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/mazen/Research/QC/QuLearn/examples/compare_models\")\n",
    "from model_builder import QNNModel, QNNStatModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = QNNStatModel(num_features=1, num_reuploads=1, num_varlayers=1, num_repeats=1, omega=0.0, double_wires=False, id=\"0\")\n",
    "for p in model.parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "import torch\n",
    "drawer = qml.draw(model.qnn.qnode, show_all_wires=True, expansion_strategy=\"device\")\n",
    "x = torch.randn(1, 1)\n",
    "print(model(x))\n",
    "print(drawer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# assuming model is your PyTorch model\n",
    "# model = ...\n",
    "\n",
    "# Ensure the model is in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Disable gradient calculations\n",
    "with torch.no_grad():\n",
    "    # Define input range\n",
    "    x = np.linspace(-1, 1, 50)\n",
    "    y = np.linspace(-1, 1, 50)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "\n",
    "    # Combine inputs and reshape for model input\n",
    "    inputs = np.array([X.flatten(), Y.flatten()]).T\n",
    "    inputs = torch.Tensor(inputs)\n",
    "\n",
    "    # Compute outputs\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    # Convert tensors to numpy arrays for plotting\n",
    "    inputs = inputs.numpy()\n",
    "    outputs = outputs.numpy()\n",
    "\n",
    "    # Reshape output for heatmap\n",
    "    Z = outputs.reshape(50, 50)\n",
    "\n",
    "    # Create the heatmap\n",
    "    plt.imshow(Z, extent=[-1, 1, -1, 1], origin='lower')\n",
    "    plt.colorbar(label='Model output')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Create a 3D plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot_surface(X, Y, Z, cmap='viridis')\n",
    "\n",
    "# Set labels\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_zlabel('Model output')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import qmc\n",
    "\n",
    "def generate_lhs_samples(n_samples, n_dims, lower_bound, upper_bound):\n",
    "    \"\"\"Generates Latin Hypercube Samples in the specified range.\"\"\"\n",
    "    sampler = qmc.LatinHypercube(d=n_dims)\n",
    "    sample = sampler.random(n=n_samples)\n",
    "    return lower_bound + sample * (upper_bound - lower_bound)\n",
    "\n",
    "import torch\n",
    "\n",
    "def generate_model_samples(model, n_samples):\n",
    "    \"\"\"Generates a list of lists of model parameters, sampled using LHS.\"\"\"\n",
    "    model_parameters = list(filter(lambda p: p.requires_grad, model.parameters()))\n",
    "\n",
    "    lower_bound = -2 * np.pi\n",
    "    upper_bound = 2 * np.pi\n",
    "    samples = []\n",
    "    for p in model_parameters:\n",
    "        n_dims = p.numel()\n",
    "        sample_parameter = generate_lhs_samples(n_samples=n_samples, n_dims=n_dims, lower_bound=lower_bound, upper_bound=upper_bound)\n",
    "        samples.append(sample_parameter)\n",
    "    parameter_list = [[torch.tensor(samples[j][i], device=None, dtype=None) for j in range(len(samples))] for i in range(n_samples)]\n",
    "\n",
    "    return parameter_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = generate_model_samples(model, 5)\n",
    "print(len(test))\n",
    "for t in test:\n",
    "    print(len(t))\n",
    "    for x in t:\n",
    "        print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for input, label in dataloader:\n",
    "    print(input)\n",
    "    print(label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(level=logging.INFO)\n",
    "logger.info(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qulearn.qlayer import IQPEmbeddingLayer\n",
    "from qulearn.qlayer import QEvalType\n",
    "import torch\n",
    "import pennylane as qml\n",
    "from qulearn.observable import parity_all_hamiltonian \n",
    "\n",
    "numq = 3\n",
    "wires = range(numq)\n",
    "qdev = qml.device(\"lightning.qubit\", wires=numq, shots=None)\n",
    "@qml.qnode(qdev)\n",
    "def qnode():\n",
    "    return qml.expval(qml.PauliZ(0))\n",
    "\n",
    "out = qnode()\n",
    "print(out)\n",
    "print(qdev.shots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "t = torch.nn.Parameter(torch.zeros(3, 3))\n",
    "print(t)\n",
    "torch.nn.init.uniform_(t, a=0.0, b=2*math.pi)\n",
    "print(t)\n",
    "a = [0, 1]\n",
    "b = [0, 2]\n",
    "print(a==b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qulearn.qlayer import IQPEmbeddingLayer, RYCZLayer, MeasurementLayer, HamiltonianLayer, MeasurementType, EmbedVarLayer, CircuitLayer\n",
    "import pennylane as qml\n",
    "import torch\n",
    "from qulearn.observable import parities_all_observables\n",
    "\n",
    "observable = qml.PauliZ(0)\n",
    "num_wires = 3\n",
    "num_reup = 1\n",
    "num_layers = 1\n",
    "num_repeat = 1\n",
    "qdev = qml.device('default.qubit', wires=num_wires, shots=None)\n",
    "\n",
    "upload_layer = IQPEmbeddingLayer(num_wires, num_reup)\n",
    "var_layer = RYCZLayer(num_wires, num_layers)\n",
    "embedvar = EmbedVarLayer(upload_layer, var_layer, n_repeat=num_repeat, omega=1.0)\n",
    "measure_layer = MeasurementLayer(embedvar, qdevice=qdev, measurement_type=MeasurementType.Expectation, observable=observable)\n",
    "obs = parities_all_observables(num_wires)\n",
    "ham_layer = HamiltonianLayer(embedvar, observables=obs, interface='torch', diff_method='backprop')\n",
    "#ham_layer = HamiltonianLayer(upload_layer, observables=obs)\n",
    "\n",
    "x = torch.randn(3, num_wires)\n",
    "drawer = qml.draw_mpl(ham_layer.qnode, show_all_wires=True, expansion_strategy=\"device\")\n",
    "drawer(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.cat((x, x), dim=1)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qulearn.utils import all_bin_sequences\n",
    "from qulearn.observable import sequence2parity_observable\n",
    "from itertools import combinations\n",
    "all = all_bin_sequences(3)\n",
    "pairs = list(combinations(range(3),2 ))\n",
    "print(all)\n",
    "print(pairs)\n",
    "all_obs = sequence2parity_observable(all)\n",
    "pairs_obs = sequence2parity_observable(pairs)\n",
    "\n",
    "print(all_obs)\n",
    "print(pairs_obs)\n",
    "all_obs[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tuple(range(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in ham_layer.parameters():\n",
    "    print(p)\n",
    "print(ham_layer.observable.coeffs)\n",
    "print(ham_layer.observable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = torch.tensor([1., -1., 0.5])\n",
    "print(tmp.numel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qulearn.fim import empirical_fim, compute_fims, mc_integrate_idfim_det\n",
    "\n",
    "FIM = empirical_fim(measure_layer, x)\n",
    "for p in measure_layer.parameters():\n",
    "    print(p)\n",
    "\n",
    "plist = []\n",
    "p1 = torch.randn(4, 3)\n",
    "p2 = torch.randn(4, 3, 2, 2)\n",
    "for i in range(4):\n",
    "    plist.append([p1[i], p2[i]])\n",
    "\n",
    "FIMs = compute_fims(measure_layer, x, plist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integral = mc_integrate_idfim_det(FIMs, 1.0, 1.0)\n",
    "print(integral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin = torch.nn.Linear(3, 1)\n",
    "print(lin(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = upload_layer(x)\n",
    "y2 = var_layer(x)\n",
    "#y3 = measure_layer(x)\n",
    "y4 = ham_layer(x)\n",
    "\n",
    "print(y3)\n",
    "print(y4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(y3)\n",
    "log_prob = torch.log(y3)\n",
    "print(torch.log(y3))\n",
    "print(x.shape)\n",
    "\n",
    "measure_layer.zero_grad()\n",
    "log_prob.backward(retain_graph=True)\n",
    "grad_list = [\n",
    "    p.grad.view(-1)\n",
    "    for p in measure_layer.parameters()\n",
    "    if p.requires_grad and p.grad is not None\n",
    "]\n",
    "grad = torch.cat(grad_list)\n",
    "prod = torch.outer(grad, grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in measure_layer.state_dict().items():\n",
    "    print(key)\n",
    "    print(val)\n",
    "    print(\"====\")\n",
    "\n",
    "print(\"************************************\")\n",
    "\n",
    "for key, val in ham_layer.state_dict().items():\n",
    "    print(key)\n",
    "    print(val)\n",
    "    print(\"====\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class HybridModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.ll_in = nn.Linear(3, 3, dtype=torch.float64)\n",
    "        self.meas = ham_layer\n",
    "        self.ll_out = nn.Linear(1, 1, dtype=torch.float64)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        y = self.ll_in(x)\n",
    "        y = self.meas(y)\n",
    "        y = self.ll_out(y)\n",
    "\n",
    "        return y\n",
    "    \n",
    "hybrid = HybridModel()\n",
    "x = torch.rand(3, dtype=torch.float64)\n",
    "y = hybrid(x)\n",
    "print(y)\n",
    "for key, val in hybrid.state_dict().items():\n",
    "    print(key)\n",
    "    print(val)\n",
    "    print(\"======\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in measure_layer.state_dict().items():\n",
    "    print(key)\n",
    "    print(val)\n",
    "    print(\"=====\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class MyType(Enum):\n",
    "\n",
    "    TypeA = 0\n",
    "    TypeB = 1\n",
    "\n",
    "x = MyType.TypeA\n",
    "y = \"blub\"\n",
    "\n",
    "if x == MyType.TypeA:\n",
    "    print(x)\n",
    "\n",
    "if not isinstance(y, MyType):\n",
    "    raise NotImplementedError(\"QEvalType not implemented\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Linear\n",
    "model = Linear(3, 1)\n",
    "X = torch.tensor([[0.1, 1.1, -2.2], [0.6, 4.1, -3.2], [-0.1, -2.1, -2.2]])\n",
    "Y = model(X)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(\"runs/test\")\n",
    "for i in range(10):\n",
    "    val = 1e-01\n",
    "    writer.add_scalar(\"foobar1\", val, i)\n",
    "    writer.add_scalars(\"loss\", {\"train\": val, \"valid\": val+1.0}, i)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pennylane as qml\n",
    "from qml_mor.models import IQPEReuploadSU2Parity, ModelType\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "num_samples=1\n",
    "num_qubits = 3\n",
    "num_reups = 1\n",
    "num_layers = 1\n",
    "sizex = num_qubits\n",
    "\n",
    "omega = 0.0\n",
    "init_theta = torch.randn(num_reups, num_qubits, requires_grad=True)\n",
    "theta = torch.randn(\n",
    "    num_reups, num_layers, num_qubits - 1, 2, requires_grad=True\n",
    ")\n",
    "W = torch.randn(2**num_qubits, requires_grad=True)\n",
    "\n",
    "params = [init_theta, theta, W]\n",
    "\n",
    "dev = qml.device(\"default.qubit\", wires=num_qubits, shots=None)\n",
    "\n",
    "model = IQPEReuploadSU2Parity(dev, params, model_type=ModelType.Expectation)\n",
    "X = torch.randn(10, 3)\n",
    "Ypred = model(X)\n",
    "print(Ypred)\n",
    "print(Ypred.shape)\n",
    "\n",
    "loss = torch.nn.MSELoss()\n",
    "test = loss(Ypred, Ypred)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Parameter\n",
    "P = model.parameters()\n",
    "for p in P:\n",
    "    print(p)\n",
    "print(\"====================\")\n",
    "save = model.state_dict().copy()\n",
    "\n",
    "init_theta = torch.randn(num_reups, num_qubits, requires_grad=True)\n",
    "theta = torch.randn(\n",
    "    num_reups, num_layers, num_qubits - 1, 2, requires_grad=True\n",
    ")\n",
    "W = torch.randn(2**num_qubits, requires_grad=True)\n",
    "\n",
    "params = [init_theta, theta, W]\n",
    "\n",
    "model = IQPEReuploadSU2Parity(dev, params)\n",
    "\n",
    "P = model.parameters()\n",
    "for p in P:\n",
    "    print(p)\n",
    "print(\"====================\")\n",
    "model.load_state_dict(save)\n",
    "P = model.parameters()\n",
    "for p in P:\n",
    "    print(p)\n",
    "print(\"====================\")\n",
    "print(save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"8\"\n",
    "from qulearn.qlayer import IQPEmbeddingLayer, RYCZLayer, MeasurementLayer, HamiltonianLayer, MeasurementType, EmbedVarLayer, CircuitLayer\n",
    "import pennylane as qml\n",
    "import torch\n",
    "from qulearn.observable import parities_all_observables\n",
    "\n",
    "observable = qml.PauliZ(0)\n",
    "num_wires = 3\n",
    "num_reup = 1\n",
    "num_layers = 1\n",
    "num_repeat = 3\n",
    "qdev = qml.device('default.qubit', wires=num_wires, shots=None)\n",
    "\n",
    "upload_layer = IQPEmbeddingLayer(num_wires, num_reup)\n",
    "var_layer = RYCZLayer(num_wires, num_layers)\n",
    "embedvar = EmbedVarLayer(upload_layer, var_layer, n_repeat=num_repeat, omega=1.0)\n",
    "obs = parities_all_observables(num_wires)\n",
    "ham_layer = HamiltonianLayer(embedvar,  qdevice=qdev, observables=obs, interface='torch', diff_method='adjoint')\n",
    "\n",
    "x = torch.zeros(3, num_wires)\n",
    "print(ham_layer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "N = 100\n",
    "torch.manual_seed(0)\n",
    "X = torch.randn(N, 10, dtype=torch.float64)\n",
    "#Y = torch.randn(N, 1, dtype=torch.float64)\n",
    "A = torch.randn(10, 1, dtype=torch.float64)\n",
    "b = torch.randn(1, dtype=torch.float64)\n",
    "eps = torch.randn(N, dtype=torch.float64)*0.001\n",
    "Y = torch.matmul(X, A) + b + eps\n",
    "model = torch.nn.Linear(10, 1, bias=True, dtype=torch.float64)\n",
    "batch_size=4\n",
    "shuffle=True\n",
    "\n",
    "dataset = TensorDataset(X, Y)\n",
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from qulearn.trainer import SupervisedTrainer\n",
    "import logging\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "opt = Adam(model.parameters(), lr=0.1, amsgrad=True)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "metrics = {\"L1\": loss_fn, \"L2\": loss_fn}\n",
    "writer = SummaryWriter()\n",
    "logger = logging.getLogger(\"SupTrainer\")\n",
    "logger.setLevel(level=logging.INFO)\n",
    "trainer = SupervisedTrainer(opt, loss_fn, metrics, 200, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(model, loader, loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "trainer.train(ham_layer, loader, loader) # lightning + torch + adjoint (+ omp-num-threads=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "trainer.train(ham_layer, loader, loader) # default + torch + backprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "trainer.train(ham_layer, loader, loader) # default + torch + adjoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -T lprof0 -u 1.0 -f trainer._train_step trainer.train(ham_layer, loader, loader)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class MeasurementType(Enum):\n",
    "    \"\"\"Measurement type for a measurement layer.\"\"\"\n",
    "\n",
    "    \"\"\"Expectation: return expected value of observable.\"\"\"\n",
    "    Expectation\n",
    "    \"\"\"Probabilities: return vector of probabilities.\"\"\"\n",
    "    Probabilities = \"probabilities\"\n",
    "    \"\"\"Samples: return measurement samples.\"\"\"\n",
    "    Samples = \"samples\"\n",
    "\n",
    "example = MeasurementType.Expectation\n",
    "print(type(example.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qml_mor.trainer import RegressionTrainer\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim import Adam\n",
    "from datetime import datetime\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=0.1, amsgrad=True)\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('runs/check_{}'.format(timestamp))\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "training = RegressionTrainer(optimizer, loss_fn, writer)\n",
    "loss = training.train(model, loader, loader)\n",
    "print(loss)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"model_bestmre\"\n",
    "state = torch.load(path)\n",
    "model.load_state_dict(state)\n",
    "Ypred = model(X)\n",
    "print(Y)\n",
    "print(\"==============\")\n",
    "print(Ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs/fashion_trainer_20230517_113403"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pennylane as qml\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from qml_mor.models import IQPEReuploadSU2Parity\n",
    "from qml_mor.trainer import AdamTorch\n",
    "from qml_mor.datagen import DataGenCapacity\n",
    "\n",
    "num_samples=1\n",
    "num_qubits = 3\n",
    "num_reups = 1\n",
    "num_layers = 1\n",
    "sizex = num_qubits\n",
    "\n",
    "datagen = DataGenCapacity(sizex=sizex, num_samples=num_samples)\n",
    "\n",
    "omega = 0.0\n",
    "init_theta = torch.randn(num_reups, num_qubits, requires_grad=True)\n",
    "theta = torch.randn(\n",
    "    num_reups, num_layers, num_qubits - 1, 2, requires_grad=True\n",
    ")\n",
    "W = torch.randn(2**num_qubits, requires_grad=True)\n",
    "\n",
    "params = [init_theta, theta, W]\n",
    "\n",
    "model = IQPEReuploadSU2Parity(omega)\n",
    "dev = qml.device(\"default.qubit\", wires=num_qubits, shots=None)\n",
    "\n",
    "@qml.qnode(dev, interface=\"torch\")\n",
    "def qnn_model(x, params):\n",
    "    return model.qfunction(x, params)\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "num_epochs = 300\n",
    "opt = AdamTorch(params, loss_fn, num_epochs=num_epochs, amsgrad=True)\n",
    "\n",
    "N = 10\n",
    "batch_size=int(\"inf\")\n",
    "shuffle=True\n",
    "data = datagen.gen_data(N)\n",
    "X = data[\"X\"]\n",
    "Y = data[\"Y\"][0]\n",
    "dataset = TensorDataset(X, Y)\n",
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "opt_params = opt.optimize(qnn_model, loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nx = X.size(0)\n",
    "y_pred = torch.stack([qnn_model(X[k], opt_params) for k in range(Nx)])\n",
    "mre = torch.mean(torch.abs((Y - y_pred) / y_pred))\n",
    "\n",
    "print(mre)\n",
    "print(loss_fn(y_pred, Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "X = torch.randn(5, 3)\n",
    "Y = torch.randn(5)\n",
    "batch_size = 2\n",
    "\n",
    "dataset = TensorDataset(X, Y)\n",
    "shuffle = True\n",
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "print(X)\n",
    "print(Y)\n",
    "print(\"===========\")\n",
    "for X_, Y_ in loader:\n",
    "    print(X_.size(0))\n",
    "    print(X_)\n",
    "    print(Y_)\n",
    "    print(\"***********\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qml_mor.datagen import DataGenRademacher, NormalPrior\n",
    "prior = NormalPrior(3, seed=0)\n",
    "radem = DataGenRademacher(prior, 2, 3, seed=None)\n",
    "data = radem.gen_data(4)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pennylane as qml\n",
    "num_qubits = 3\n",
    "W = torch.randn(2**num_qubits, requires_grad=False)\n",
    "from qulearn.qlayer import parity_hamiltonian\n",
    "H = parity_hamiltonian(num_qubits, W)\n",
    "print(W)\n",
    "print(\"======\")\n",
    "Z = qml.PauliZ(wires=0)\n",
    "print(H.coeffs.requires_grad)\n",
    "W_ = torch.nn.Parameter()\n",
    "print(W_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "import torch\n",
    "from qml_mor.models import IQPEReuploadSU2Parity\n",
    "\n",
    "num_qubits  = 3\n",
    "num_reps    = 2\n",
    "num_layers  = 2\n",
    "omega       = 1.\n",
    "torch.manual_seed(0)\n",
    "x           = torch.randn(num_qubits, requires_grad=False)\n",
    "init_theta  = torch.randn(num_reps, num_qubits, requires_grad=True)\n",
    "theta       = torch.randn(num_reps, num_layers, num_qubits-1, 2, requires_grad=True)\n",
    "W           = torch.randn(2**num_qubits, requires_grad=True)\n",
    "\n",
    "params = [init_theta, theta, W]\n",
    "\n",
    "def iqpe_reupload_su2_parity(\n",
    "    x, init_theta, theta, W, omega: float = 0.0\n",
    "):\n",
    "    \"\"\"\n",
    "    Quantum function that calculates the expectation value\n",
    "    of the parity of Pauli Z operators.\n",
    "\n",
    "    Args:\n",
    "        x (Tensor): Input tensor of shape (num_qubits,)\n",
    "        init_theta (Tensor): Initial rotation angles for each qubit,\n",
    "            of shape (reps, num_qubits)\n",
    "        theta (Tensor): Rotation angles for each layer and each qubit,\n",
    "            of shape (reps, num_layers, num_qubits-1, 2)\n",
    "        W (Tensor): Observable weights of shape (2^num_qubits,)\n",
    "        omega (float, optional): Exponential feature scaling factor. Defaults to 0.0.\n",
    "\n",
    "    Returns:\n",
    "        QFuncOutput: Expectation value of the parity of Pauli Z operators\n",
    "    \"\"\"\n",
    "\n",
    "    shape_init = init_theta.shape\n",
    "    shape = theta.shape\n",
    "    if len(shape_init) != 2:\n",
    "        raise ValueError(\"Initial theta must be a 2-dim tensor\")\n",
    "    if len(shape) != 4:\n",
    "        raise ValueError(\"Theta must be a 4-dim tensor\")\n",
    "\n",
    "    num_qubits = len(x)\n",
    "    reps = shape_init[0]\n",
    "    wires = range(num_qubits)\n",
    "\n",
    "    for layer in range(reps):\n",
    "        features = 2 ** (omega * layer) * x\n",
    "        initial_layer_weights = init_theta[layer]\n",
    "        weights = theta[layer]\n",
    "\n",
    "        qml.IQPEmbedding(features=features, wires=wires)\n",
    "        qml.SimplifiedTwoDesign(\n",
    "            initial_layer_weights=initial_layer_weights,\n",
    "            weights=weights,\n",
    "            wires=wires,\n",
    "        )\n",
    "\n",
    "def iqpe_reupload_su2_meas(\n",
    "    x, init_theta, theta, W, omega: float = 0.0\n",
    "):\n",
    "    iqpe_reupload_su2_parity(x, init_theta, theta, W, omega)\n",
    "    obs = parities(len(x))\n",
    "    H = qml.Hamiltonian(W, obs)\n",
    "\n",
    "    return qml.sample()\n",
    "\n",
    "#qnn_model = IQPEReuploadSU2Parity(params, omega=1.0)\n",
    "\n",
    "dev = qml.device(\"default.qubit\", wires=num_qubits, shots=None)\n",
    "qnode = qml.QNode(iqpe_reupload_su2_meas, dev, interface=\"torch\")\n",
    "#drawer = qml.draw(qnode, expansion_strategy=\"device\")\n",
    "#print(drawer(x, init_theta, theta, W))\n",
    "probs = qnode(x, init_theta, theta, W, omega)\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = probs\n",
    "bitstrings = [''.join(str(b.item()) for b in sample) for sample in samples]\n",
    "bitstring_counts = {bs: bitstrings.count(bs) for bs in set(bitstrings)}\n",
    "print(samples)\n",
    "print(bitstrings)\n",
    "print(bitstring_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qml_mor.models import IQPEReuploadSU2Parity\n",
    "\n",
    "model = IQPEReuploadSU2Parity()\n",
    "\n",
    "qnode = qml.QNode(model.probabilities, dev, interface=\"torch\")\n",
    "probs = qnode(x, params)\n",
    "print(probs)\n",
    "print(model.Hamiltonian(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = model.Hamiltonian(params)\n",
    "sum = 0.0\n",
    "b = \"110\"\n",
    "\n",
    "for idx, O in enumerate(H.ops):\n",
    "\n",
    "    if not isinstance(O.name, list):\n",
    "        if O.name == \"Identity\":\n",
    "            sum += H.coeffs[idx]\n",
    "        elif O.name == \"PauliZ\":\n",
    "            i = O.wires[0]\n",
    "            sign = (-1)**(int(b[-1-i]))\n",
    "            sum += sign*H.coeffs[idx]\n",
    "        else:\n",
    "            raise ValueError(\"All operators must be PauliZ or Identity.\")\n",
    "    else:\n",
    "        if not all(name==\"PauliZ\" for name in O.name):\n",
    "            raise ValueError(\"All operators must be PauliZ or Identity.\")\n",
    "        \n",
    "        sign = 1\n",
    "        for w in O.wires:\n",
    "            sign *= (-1)**(int(b[-1-w]))\n",
    "\n",
    "        sum += sign*H.coeffs[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(probs)\n",
    "marginal = qml.math.marginal_prob(probs, axis=[0])\n",
    "print(marginal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qml_mor.models import parities\n",
    "\n",
    "n = 3\n",
    "test = parities(n)\n",
    "H = qml.Hamiltonian(W, test)\n",
    "print(H)\n",
    "print(H.ops)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature layer\n",
    "def feature_layer(x):\n",
    "    num_qubits = len(x)\n",
    "    qml.IQPEmbedding(x, wires=range(num_qubits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variational layer\n",
    "def variational_layer(init_theta, theta, num_qubits):\n",
    "    qml.SimplifiedTwoDesign(initial_layer_weights=init_theta, weights=theta, wires=range(num_qubits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observable / output layer\n",
    "def sequence_generator(n):\n",
    "    if n == 0:\n",
    "        return [[]]\n",
    "    else:\n",
    "        sequences = []\n",
    "        for sequence in sequence_generator(n-1):\n",
    "            sequences.append(sequence + [n-1])\n",
    "            sequences.append(sequence)\n",
    "        return sequences\n",
    "    \n",
    "def parities(n):\n",
    "    \n",
    "    seq = sequence_generator(n)\n",
    "    ops = []\n",
    "    for par in seq:\n",
    "        if par:\n",
    "            tmp = qml.PauliZ(par[0])\n",
    "            if len(par) > 1:\n",
    "                for i in par[1:]:\n",
    "                    tmp = tmp @ qml.PauliZ(i)\n",
    "\n",
    "            ops.append(tmp)\n",
    "\n",
    "    ops.append(qml.Identity(0))\n",
    "\n",
    "    return ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pennylane.templates import IQPEmbedding, SimplifiedTwoDesign\n",
    "# QNN model\n",
    "@qml.qnode(dev, interface='torch')\n",
    "def qnn_model(x, init_theta, theta, W, omega=0.):\n",
    "\n",
    "    num_qubits = len(x)\n",
    "    shape_init = init_theta.shape\n",
    "    reps       = 1\n",
    "    if len(shape_init) < 1:\n",
    "        init_theta = [init_theta]\n",
    "        shape_init = init_theta.shape\n",
    "    reps       = shape_init[0]\n",
    "\n",
    "    shape_theta = theta.shape\n",
    "    reps_       = 1\n",
    "    if len(shape_theta) < 3:\n",
    "        theta       = [theta]\n",
    "        shape_theta = theta.shape\n",
    "    reps_       = shape_theta[0]\n",
    "\n",
    "    assert reps == reps_\n",
    "    for l in range(reps):\n",
    "        qml.IQPEmbedding(features=2**(omega*l)*x, wires=range(num_qubits))\n",
    "        qml.SimplifiedTwoDesign(initial_layer_weights=init_theta[l], weights=theta[l], wires=range(num_qubits))\n",
    "\n",
    "    obs = parities(num_qubits)\n",
    "    H   = qml.Hamiltonian(W, obs)\n",
    "\n",
    "    return qml.expval(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane.templates import IQPEmbedding\n",
    "\n",
    "n_wires = 3\n",
    "n_layers = 2\n",
    "\n",
    "dev = qml.device(\"default.qubit\", wires=n_wires)\n",
    "@qml.qnode(dev, interface='torch')\n",
    "def iqpe_circuit(features):\n",
    "    for layer in range(n_layers):\n",
    "        # Apply the IQPEmbedding template in a loop\n",
    "        IQPEmbedding(features=features[layer], wires=range(n_wires))\n",
    "\n",
    "    return [qml.expval(qml.PauliZ(wires=i)) for i in range(n_wires)]\n",
    "\n",
    "features = np.random.random((n_layers, n_wires))\n",
    "\n",
    "result1 = iqpe_circuit(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_qubits  = 3\n",
    "num_reps    = 0\n",
    "num_layers  = 0\n",
    "omega       = 1.\n",
    "x           = torch.randn(num_qubits, requires_grad=False)\n",
    "init_theta  = torch.randn(num_reps, num_qubits, requires_grad=True)\n",
    "theta       = torch.randn(num_reps, num_layers, num_qubits-1, 2, requires_grad=True)\n",
    "W           = torch.randn(2**num_qubits, requires_grad=True)\n",
    "\n",
    "result1 = qnn_model(x, init_theta, theta, W)\n",
    "result2 = qnn_model(x, init_theta, theta, W)\n",
    "\n",
    "ret = torch.stack([result1, result2])\n",
    "result1.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import qmc\n",
    "def generate_samples_r(d, S):\n",
    "    sampler = qmc.LatinHypercube(d=d)\n",
    "    r_samples = sampler.random(n=S)\n",
    "    return r_samples\n",
    "r = generate_samples_r(10, 2)\n",
    "print(len(r[0]))\n",
    "\n",
    "tmp = set()\n",
    "rng = np.random.default_rng(seed=0)\n",
    "b1 = tuple(rng.integers(0, 2, size=4))\n",
    "b2 = tuple(rng.integers(0, 2, size=4))\n",
    "tmp.add(b1)\n",
    "tmp.add(b2)\n",
    "print(tmp)\n",
    "arr = np.array(list(tmp))\n",
    "print(arr)\n",
    "arr[0, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Original list of tensors\n",
    "tensor_list = [torch.tensor([1., 2., 3.], requires_grad=True),\n",
    "               torch.tensor([4., 5., 6.], requires_grad=False)]\n",
    "\n",
    "est_params = [\n",
    "                        t.detach().clone().requires_grad_(t.requires_grad)\n",
    "                        for t in tensor_list\n",
    "                    ]\n",
    "tensor_list *= 2\n",
    "print(tensor_list)\n",
    "print(est_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = (f\"Stopping early\\n\"\n",
    "       \"Loss not improving\")\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the quantum device\n",
    "dev = qml.device(\"default.qubit\", wires=2)\n",
    "\n",
    "# Define the custom model as a PennyLane QNode\n",
    "@qml.qnode(dev, interface=\"torch\")\n",
    "def custom_model(x, y):\n",
    "    # Apply your quantum circuit here, which uses input x and trainable parameters y\n",
    "    # As an example, we'll use a simple circuit with one rotation gate parameterized by y:\n",
    "    qml.RY(y[0], wires=0)\n",
    "    qml.RX(x, wires=1)\n",
    "    qml.CNOT(wires=[0, 1])\n",
    "    return qml.expval(qml.PauliZ(1))\n",
    "\n",
    "# Define the dataset (x_data, y_data)\n",
    "x_data = torch.tensor([0.1, 0.2, 0.3, 0.4, 0.5], dtype=torch.float32)\n",
    "y_data = torch.tensor([0.5, 0.4, 0.3, 0.2, 0.1], dtype=torch.float32)\n",
    "\n",
    "# Initialize the trainable parameters\n",
    "params = torch.tensor([0.0], dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "# Set the hyperparameters\n",
    "learning_rate = 0.01\n",
    "epochs = 100\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam([params], lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    predictions = torch.tensor([custom_model(x, params) for x in x_data], dtype=torch.float32)\n",
    "    loss = loss_fn(predictions, y_data)\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")\n",
    "\n",
    "print(f\"Trained parameters: {params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_qubits  = 3\n",
    "num_reps    = 3\n",
    "num_layers  = 0\n",
    "omega       = 1.\n",
    "x           = torch.randn(num_qubits, requires_grad=False)\n",
    "init_theta  = torch.randn(num_reps, num_qubits, requires_grad=True)\n",
    "theta       = torch.randn(num_reps, num_layers, num_qubits-1, 2, requires_grad=True)\n",
    "W           = torch.randn(2**num_qubits, requires_grad=True)\n",
    "def qnn_model(x, init_theta, theta, W, omega=0.):\n",
    "\n",
    "    num_qubits = len(x)\n",
    "    shape_init = init_theta.shape\n",
    "    reps       = 1\n",
    "    if len(shape_init) < 1:\n",
    "        init_theta = [init_theta]\n",
    "        shape_init = init_theta.shape\n",
    "    reps       = shape_init[0]\n",
    "\n",
    "    shape_theta = theta.shape\n",
    "    reps_       = 1\n",
    "    if len(shape_theta) < 3:\n",
    "        theta       = [theta]\n",
    "        shape_theta = theta.shape\n",
    "    reps_       = shape_theta[0]\n",
    "\n",
    "    assert reps == reps_\n",
    "    for l in range(reps):\n",
    "        qml.IQPEmbedding(features=2**(omega*l)*x, wires=range(num_qubits))\n",
    "        qml.SimplifiedTwoDesign(initial_layer_weights=init_theta[l], weights=theta[l], wires=range(num_qubits))\n",
    "\n",
    "    obs = parities(num_qubits)\n",
    "    H   = qml.Hamiltonian(W, obs)\n",
    "\n",
    "    return qml.expval(H)\n",
    "\n",
    "result = qnn_model(x, init_theta, theta, W)\n",
    "print(result.shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = parities(3)\n",
    "for x in tmp:\n",
    "    print(type(x))\n",
    "    print(issubclass(type(x), qml.operation.Observable))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "num_qubits  = 3\n",
    "num_reps    = 3\n",
    "num_layers  = 0\n",
    "omega       = 1.\n",
    "x           = torch.randn(num_qubits, requires_grad=False)\n",
    "init_theta  = torch.randn(num_reps, num_qubits, requires_grad=True)\n",
    "theta       = torch.randn(num_reps, num_layers, num_qubits-1, 2, requires_grad=True)\n",
    "W           = torch.randn(2**num_qubits, requires_grad=True)\n",
    "\n",
    "print(qml.draw_mpl(qnn_model)(x, init_theta, theta, W, omega))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets for Capacity Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_dataset(N, samples=10, seed=0):\n",
    "    sizex   = num_qubits\n",
    "    scale   = 2.\n",
    "    shift   = -1.\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    x       = scale*torch.rand(N, sizex, requires_grad=False) + shift\n",
    "    y       = scale*torch.rand(samples, N, requires_grad=False) + shift\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model specs\n",
    "num_qubits  = 3\n",
    "num_reps    = 2\n",
    "num_layers  = 2\n",
    "omega       = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial parameters\n",
    "seed = 0\n",
    "torch.manual_seed(seed)\n",
    "init_theta  = torch.randn(num_reps, num_qubits, requires_grad=True)\n",
    "theta       = torch.randn(num_reps, num_layers, num_qubits-1, 2, requires_grad=True)\n",
    "W           = torch.randn(2**num_qubits, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "def square_loss(targets, predictions):\n",
    "    loss = 0\n",
    "    for t, p in zip(targets, predictions):\n",
    "        loss += (t - p) ** 2\n",
    "    loss = loss / len(targets)\n",
    "    return 0.5*loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# capacity estimation parameters\n",
    "Nmin     = 1\n",
    "Nmax     = 5\n",
    "samples  = 10\n",
    "steps    = 300\n",
    "eps_stop = 1e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = {}\n",
    "for N in range(Nmin, Nmax):\n",
    "    x, y = gen_dataset(N, samples)\n",
    "    \n",
    "    mre_sample = []\n",
    "    for s in range(samples):\n",
    "        print('===================================')\n",
    "        def cost(init_theta, theta, W):\n",
    "            pred = [qnn_model(x[k], init_theta, theta, W) for k in range(N)]\n",
    "            loss = square_loss(y[s], pred)\n",
    "            return loss\n",
    "        \n",
    "        # optimize\n",
    "        opt = torch.optim.Adam([init_theta, theta, W], lr=0.1, amsgrad=True)\n",
    "        for n in range(steps):\n",
    "            opt.zero_grad()\n",
    "            loss = cost(init_theta, theta, W)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            if n%10 == 9 or n == steps - 1:\n",
    "                print(f'{n+1}: {loss}')\n",
    "\n",
    "            if loss <= eps_stop:\n",
    "                break\n",
    "\n",
    "        # compute prediction errors\n",
    "        y_pred = torch.tensor([qnn_model(x[k], init_theta, theta, W) for k in range(N)], requires_grad=False)\n",
    "        mre    = torch.mean(torch.abs((y[s]-y_pred)/y_pred))\n",
    "        mre_sample.append(mre)\n",
    "\n",
    "    mre_N = torch.mean(torch.tensor(mre_sample))\n",
    "    summary[f'N = {N}'] = mre_N.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for count, eps in enumerate(summary.values()):\n",
    "    m = int(np.log2(1./eps.item()))\n",
    "    C = (count+1)*m\n",
    "    print(C)\n",
    "print(torch.numel(init_theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = [-0.5, 13.1, 2]\n",
    "max(C)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = torch.tensor([qnn_model(x[k], init_theta, theta, W) for k in range(N)], requires_grad=False)\n",
    "mre    = torch.mean(torch.abs((y[s]-y_pred)/y_pred))\n",
    "print(mre.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cutoff precision converted to bits of precision\n",
    "cutoff = np.sqrt(eps_stop)\n",
    "m      = np.log2(1./cutoff)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x)\n",
    "print(init_theta)\n",
    "print(theta)\n",
    "print(W)\n",
    "print(y[s])\n",
    "print(y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QML-MOR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "46e7eb4246c13550057ff7606884a772512028b1851bd0c4d2a0ba2e0c036465"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
