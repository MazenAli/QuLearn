{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import pennylane as qml\n",
    "import torch\n",
    "\n",
    "# We create our data and labels\n",
    "\n",
    "x_train = torch.tensor([0.2, 0.1, 0.14])\n",
    "\n",
    "# We define the circuit we are going to use\n",
    "\n",
    "dev = qml.device(\"default.qubit\", wires=1)\n",
    "\n",
    "\n",
    "# @qml.qnode(dev, interface=\"torch\")\n",
    "def simple_qubit_circuit(theta, input_value):\n",
    "    qml.RX(input_value, wires=0)\n",
    "    qml.RY(theta, wires=0)\n",
    "    return qml.expval(qml.PauliZ(0))\n",
    "\n",
    "\n",
    "theta = 0.2\n",
    "y = simple_qubit_circuit(theta, x_train)\n",
    "print(x_train.shape)\n",
    "print(y.shape)\n",
    "print(y)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "source": [
    "import torch\n",
    "\n",
    "def find_grid_points(x, n):\n",
    "    num_segments = 2 ** (n-1)\n",
    "    segment_length = 2 / num_segments\n",
    "\n",
    "    # Ensure x is a torch tensor\n",
    "    if not isinstance(x, torch.Tensor):\n",
    "        x = torch.tensor(x, dtype=torch.float64)\n",
    "\n",
    "    # Validate that x is in the range [-1, 1]\n",
    "    if torch.any(x < -1) or torch.any(x > 1):\n",
    "        raise ValueError(\"Input x must be in the range [-1, 1]\")\n",
    "\n",
    "    # Calculate the position for each x\n",
    "    position = ((x + 1) / segment_length).floor()\n",
    "\n",
    "    # Determine the grid points\n",
    "    left_point = -1 + position * segment_length\n",
    "    right_point = left_point + segment_length\n",
    "\n",
    "    return left_point, right_point, position\n",
    "\n",
    "# Example usage\n",
    "x = torch.tensor([0.5, -0.3, 0.9])\n",
    "n = 3\n",
    "left_points, right_points, position = find_grid_points(x, n)\n",
    "print(\"Left Points:\", left_points)\n",
    "print(\"Right Points:\", right_points)\n",
    "print(\"Position:\", position)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "source": [
    "import torch\n",
    "\n",
    "import torch\n",
    "\n",
    "def sawtooth_vector(x, n):\n",
    "    if not isinstance(x, torch.Tensor):\n",
    "        x = torch.tensor(x, dtype=torch.float64)\n",
    "\n",
    "    if torch.any(x < -1) or torch.any(x > 1):\n",
    "        raise ValueError(\"Input x must be in the range [-1, 1]\")\n",
    "\n",
    "    num_elements = 2 ** n\n",
    "    num_x = x.shape[0]\n",
    "    vector = torch.zeros(num_x, num_elements, dtype=torch.float64)\n",
    "\n",
    "    # Initialize the vector with the first two entries\n",
    "    vector[:, 0] = torch.sqrt(0.5 * (1 + x))\n",
    "    vector[:, 1] = torch.sqrt(0.5 * (1 - x))\n",
    "\n",
    "    count = 2\n",
    "    for k in range(1, 2**(n-1), 1):\n",
    "        left_node, right_node, position = find_grid_points(x, k+1)\n",
    "\n",
    "        sawtooth_up = (x - left_node) / (right_node - left_node)\n",
    "        sawtooth_down = (right_node - x) / (right_node - left_node)\n",
    "        sawtooth_up = torch.sqrt(sawtooth_up)\n",
    "        sawtooth_down = torch.sqrt(sawtooth_down)\n",
    "\n",
    "        for i in range(num_x):\n",
    "            odd = position[i].long() % 2\n",
    "            if not odd:\n",
    "               vector[i, count] = sawtooth_up[i]\n",
    "               vector[i, count+1] = sawtooth_down[i]\n",
    "            else:\n",
    "               vector[i, count] = sawtooth_down[i]\n",
    "               vector[i, count+1] = sawtooth_up[i]\n",
    "                \n",
    "        count += 2\n",
    "\n",
    "    return vector\n",
    "\n",
    "\n",
    "# Example usage\n",
    "x = torch.tensor([0.5])\n",
    "n = 3\n",
    "print(sawtooth_vector(x, n))\n",
    "print(sawtooth_vector(x, n).shape)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def linear_FEM_basis(x, n):\n",
    "    num_nodes = 2 ** n\n",
    "    nodes = np.linspace(-1, 1, num_nodes)\n",
    "    nodes = torch.tensor(nodes, dtype=torch.float64)\n",
    "\n",
    "    # Initialize the output tensor\n",
    "    values = torch.zeros(x.shape[0], num_nodes, dtype=torch.float64)\n",
    "    \n",
    "    # Distance between nodes\n",
    "    h = 2 / (num_nodes - 1)\n",
    "\n",
    "    # Handle tensor input for x\n",
    "    for i in range(1, num_nodes):\n",
    "        mask = (nodes[i - 1] <= x) & (x <= nodes[i])\n",
    "        values[mask, i - 1] = (nodes[i] - x[mask]) / h\n",
    "        values[mask, i] = (x[mask] - nodes[i - 1]) / h\n",
    "\n",
    "    #values = torch.sqrt(values)\n",
    "    return values.squeeze(0)\n",
    "\n",
    "# Example usage with tensor input\n",
    "x_tensor = torch.tensor([0.0, 0.5], dtype=torch.float64)\n",
    "n = 1\n",
    "result = linear_FEM_basis(x_tensor, n)\n",
    "print(result)\n",
    "print(result.shape)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "source": [
    "import torchtt as tntt\n",
    "full_tensor = result.reshape(2, 2, 2)\n",
    "tens_tt = tntt.TT(full_tensor)\n",
    "print('TT cores', tens_tt.cores)\n",
    "print('Mode size ', tens_tt.N)\n",
    "print('TT rank ', tens_tt.R)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "source": [
    "# Reshape the tensor into a 2x2 matrix\n",
    "matrix = result.reshape(2, 2)\n",
    "\n",
    "# Perform QR decomposition\n",
    "q, r = torch.linalg.qr(matrix)\n",
    "\n",
    "# Print the outputs\n",
    "print(\"Original Matrix:\\n\", matrix)\n",
    "print(\"Q Matrix:\\n\", q)\n",
    "print(\"R Matrix:\\n\", r)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "def plot_basis_combinations(x_values, basis_functions, n):\n",
    "    grid_size=(3, 3)\n",
    "    num_plots = grid_size[0] * grid_size[1]\n",
    "    _, axs = plt.subplots(grid_size[0], grid_size[1], figsize=(15, 15))\n",
    "    axs = axs.flatten()\n",
    "\n",
    "    # Generate all unique combinations of basis functions\n",
    "    for idx in range(basis_functions.shape[1]):\n",
    "        axs[idx].plot(x_values, basis_functions[:, idx])\n",
    "        axs[idx].set_title(f\"bf {idx}\")\n",
    "        axs[idx].grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Generate x values for plotting\n",
    "x_plot = torch.tensor(np.linspace(-1, 1, 1000))\n",
    "\n",
    "# Generate the basis functions for each x in x_plot\n",
    "basis_functions = linear_FEM_basis(x_plot, n)\n",
    "basis_functions = sawtooth_vector(x_plot, n)\n",
    "plot_basis_combinations(x_plot, basis_functions, n)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "def plot_basis_combinations(x_values, basis_functions, n):\n",
    "    grid_size=(3, 3)\n",
    "    num_plots = grid_size[0] * grid_size[1]\n",
    "    _, axs = plt.subplots(grid_size[0], grid_size[1], figsize=(15, 15))\n",
    "    axs = axs.flatten()\n",
    "\n",
    "    # Generate all unique combinations of basis functions\n",
    "    for idx in range(basis_functions.shape[1]):\n",
    "        bf = basis_functions[:, idx]\n",
    "        axs[idx].plot(x_values, bf**2)\n",
    "        axs[idx].set_title(f\"bf**2 {idx}\")\n",
    "        axs[idx].grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Generate x values for plotting\n",
    "x_plot = torch.tensor(np.linspace(-1, 1, 1000))\n",
    "\n",
    "# Generate the basis functions for each x in x_plot\n",
    "basis_functions = linear_FEM_basis(x_plot, n)\n",
    "basis_functions = sawtooth_vector(x_plot, n)\n",
    "plot_basis_combinations(x_plot, basis_functions, n)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import itertools\n",
    "\n",
    "def plot_basis_combinations(x_values, basis_functions, n):\n",
    "    s = 2**n\n",
    "    grid_size=(s, s)\n",
    "    num_plots = grid_size[0] * grid_size[1]\n",
    "    _, axs = plt.subplots(grid_size[0], grid_size[1], figsize=(15, 15))\n",
    "\n",
    "    # Generate all unique combinations of basis functions\n",
    "    all_combinations = list(itertools.combinations_with_replacement(range(2**n), 2))\n",
    "    selected_combinations = all_combinations[:num_plots]\n",
    "\n",
    "    for idx, (i, j) in enumerate(selected_combinations):\n",
    "        combined_basis = basis_functions[:, i]*basis_functions[:, j]\n",
    "        axs[i, j].plot(x_values, combined_basis)\n",
    "        axs[i, j].set_title(f\"bf {i} x {j}\")\n",
    "        axs[i, j].grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Generate x values for plotting\n",
    "x_plot = torch.tensor(np.linspace(-1, 1, 1000))\n",
    "\n",
    "# Generate the basis functions for each x in x_plot\n",
    "basis_functions = linear_FEM_basis(x_plot, n)\n",
    "basis_functions = sawtooth_vector(x_plot, n)\n",
    "plot_basis_combinations(x_plot, basis_functions, n)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "source": [
    "import pennylane as qml\n",
    "\n",
    "num_qubits = 3\n",
    "dev = qml.device(\"default.qubit\", wires=num_qubits)\n",
    "\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def circuit(f=None):\n",
    "    qml.AmplitudeEmbedding(features=f, wires=range(num_qubits), normalize=False)\n",
    "    return qml.expval(qml.PauliZ(0))  # qml.state()\n",
    "\n",
    "\n",
    "x = 0.3\n",
    "f = linear_FEM_basis(x, num_qubits)\n",
    "f = f / np.linalg.norm(f)\n",
    "print(f)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "source": [
    "import pennylane as qml\n",
    "from qulearn import qlayer\n",
    "import torch\n",
    "\n",
    "\n",
    "class LinearAmplitudeEmbedding(qlayer.CircuitLayer):\n",
    "    def __init__(self, num_qubits):\n",
    "        super().__init__(num_qubits)\n",
    "        self.num_qubits = num_qubits\n",
    "\n",
    "    def circuit(self, x):\n",
    "        Phi = linear_FEM_basis(x, self.num_qubits)\n",
    "        #Phi = sawtooth_vector(x, self.num_qubits)\n",
    "        Phi = Phi / torch.linalg.norm(Phi)\n",
    "        qml.AmplitudeEmbedding(features=Phi, wires=self.wires, normalize=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "source": [
    "num_qubits = 3\n",
    "var0 = qlayer.AltRotCXLayer(wires=num_qubits, n_layers=3)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "source": [
    "import pennylane as qml\n",
    "from qulearn import qlayer\n",
    "from torch import nn\n",
    "import math\n",
    "\n",
    "class AltRotCRXLayer(qlayer.CircuitLayer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        wires,\n",
    "        n_layers = 1,\n",
    "        cdevice = None,\n",
    "        dtype = None,\n",
    "    ) -> None:\n",
    "        super().__init__(wires)\n",
    "\n",
    "        self.n_layers = n_layers\n",
    "        self.cdevice = cdevice\n",
    "        self.dtype = dtype\n",
    "\n",
    "        # weight parameters\n",
    "        circ_offset = 1 if self.num_wires > 2 else 0\n",
    "        \n",
    "        self.initial_layer_weights = torch.nn.Parameter(\n",
    "            torch.empty((self.num_wires, 3), device=self.cdevice, dtype=self.dtype)\n",
    "        )\n",
    "        \n",
    "        self.one_qubit_weights = torch.nn.Parameter(\n",
    "            torch.empty(\n",
    "                (2*self.n_layers, 2 * (self.num_wires - 1) + 2*circ_offset, 3),\n",
    "                device=self.cdevice,\n",
    "                dtype=self.dtype,\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        self.crx_weights = torch.nn.Parameter(\n",
    "            torch.empty(\n",
    "                (self.n_layers, self.num_wires - 1 + circ_offset),\n",
    "                device=self.cdevice,\n",
    "                dtype=self.dtype,\n",
    "            )\n",
    "        )\n",
    "        self.xx_weights = torch.nn.Parameter(\n",
    "            torch.empty(\n",
    "                (self.n_layers, self.num_wires - 1 + circ_offset),\n",
    "                device=self.cdevice,\n",
    "                dtype=self.dtype,\n",
    "            )\n",
    "        )\n",
    "       # nn.init.zeros_(self.initial_layer_weights)\n",
    "       # nn.init.zeros_(self.one_qubit_weights)\n",
    "       # nn.init.zeros_(self.two_qubit_weights)\n",
    "       \n",
    "        \n",
    "        nn.init.uniform_(self.initial_layer_weights, a=0.0, b=2 * math.pi)\n",
    "        nn.init.uniform_(self.one_qubit_weights, a=0.0, b=2 * math.pi)\n",
    "        nn.init.uniform_(self.crx_weights, a=0.0, b=2 * math.pi)\n",
    "        nn.init.uniform_(self.xx_weights, a=0.0, b=2 * math.pi)\n",
    "\n",
    "\n",
    "    def circuit(self, _ = None):\n",
    "       for index, q in enumerate(self.wires):\n",
    "            qml.Rot(\n",
    "                self.initial_layer_weights[index, 0],\n",
    "                self.initial_layer_weights[index, 1],\n",
    "                self.initial_layer_weights[index, 2],\n",
    "                q,\n",
    "            )\n",
    "\n",
    "       for layer in range(self.n_layers):\n",
    "           for i in range(0, len(self.wires) - 1, 2):\n",
    "               crx_idx = i // 2\n",
    "               qml.CRX(self.crx_weights[layer, crx_idx], wires=[self.wires[i], self.wires[i + 1]])\n",
    "               qml.Rot(\n",
    "                   self.one_qubit_weights[layer, i, 0],\n",
    "                   self.one_qubit_weights[layer, i, 1],\n",
    "                   self.one_qubit_weights[layer, i, 2],\n",
    "                   self.wires[i],\n",
    "               )\n",
    "               qml.Rot(\n",
    "                   self.one_qubit_weights[layer, i + 1, 0],\n",
    "                   self.one_qubit_weights[layer, i + 1, 1],\n",
    "                   self.one_qubit_weights[layer, i + 1, 2],\n",
    "                   self.wires[i + 1],\n",
    "               )\n",
    "\n",
    "           offset_1q = (self.num_wires // 2) * 2\n",
    "           offset_2q = self.num_wires//2\n",
    "           for i in range(1, len(self.wires) - 1, 2):\n",
    "               crx_idx = i // 2\n",
    "               qml.CRX(self.crx_weights[layer, offset_2q + crx_idx], wires=[self.wires[i], self.wires[i + 1]])\n",
    "               qml.Rot(\n",
    "                   self.one_qubit_weights[layer, offset_1q + i - 1, 0],\n",
    "                   self.one_qubit_weights[layer, offset_1q + i - 1, 1],\n",
    "                   self.one_qubit_weights[layer, offset_1q + i - 1, 2],\n",
    "                   self.wires[i],\n",
    "               )\n",
    "               qml.Rot(\n",
    "                   self.one_qubit_weights[layer, offset_1q + i, 0],\n",
    "                   self.one_qubit_weights[layer, offset_1q + i, 1],\n",
    "                   self.one_qubit_weights[layer, offset_1q + i, 2],\n",
    "                   self.wires[i + 1],\n",
    "               )\n",
    "           \n",
    "           if self.num_wires > 2: \n",
    "               qml.CRX(self.crx_weights[layer, -1], wires=[self.wires[-1], self.wires[0]])\n",
    "               qml.Rot(\n",
    "                   self.one_qubit_weights[layer, -2, 0],\n",
    "                   self.one_qubit_weights[layer, -2, 1],\n",
    "                   self.one_qubit_weights[layer, -2, 2],\n",
    "                   self.wires[-1],\n",
    "               )\n",
    "               qml.Rot(\n",
    "                   self.one_qubit_weights[layer, -1, 0],\n",
    "                   self.one_qubit_weights[layer, -1, 1],\n",
    "                   self.one_qubit_weights[layer, -1, 2],\n",
    "                   self.wires[0],\n",
    "               )\n",
    "\n",
    "\n",
    "\n",
    "       for layer in range(self.n_layers):\n",
    "           for i in range(0, len(self.wires) - 1, 2):\n",
    "               crx_idx = i // 2\n",
    "               qml.IsingXX(self.xx_weights[layer, crx_idx], wires=[self.wires[i], self.wires[i + 1]])\n",
    "               qml.Rot(\n",
    "                   self.one_qubit_weights[self.n_layers + layer, i, 0],\n",
    "                   self.one_qubit_weights[self.n_layers + layer, i, 1],\n",
    "                   self.one_qubit_weights[self.n_layers + layer, i, 2],\n",
    "                   self.wires[i],\n",
    "               )\n",
    "               qml.Rot(\n",
    "                   self.one_qubit_weights[self.n_layers + layer, i + 1, 0],\n",
    "                   self.one_qubit_weights[self.n_layers + layer, i + 1, 1],\n",
    "                   self.one_qubit_weights[self.n_layers + layer, i + 1, 2],\n",
    "                   self.wires[i + 1],\n",
    "               )\n",
    "\n",
    "           offset_1q = (self.num_wires // 2) * 2\n",
    "           offset_2q = self.num_wires//2\n",
    "           for i in range(1, len(self.wires) - 1, 2):\n",
    "               crx_idx = i // 2\n",
    "               qml.IsingXX(self.xx_weights[layer, offset_2q + crx_idx], wires=[self.wires[i], self.wires[i + 1]])\n",
    "               qml.Rot(\n",
    "                   self.one_qubit_weights[self.n_layers + layer, offset_1q + i - 1, 0],\n",
    "                   self.one_qubit_weights[self.n_layers + layer, offset_1q + i - 1, 1],\n",
    "                   self.one_qubit_weights[self.n_layers + layer, offset_1q + i - 1, 2],\n",
    "                   self.wires[i],\n",
    "               )\n",
    "               qml.Rot(\n",
    "                   self.one_qubit_weights[self.n_layers + layer, offset_1q + i, 0],\n",
    "                   self.one_qubit_weights[self.n_layers + layer, offset_1q + i, 1],\n",
    "                   self.one_qubit_weights[self.n_layers + layer, offset_1q + i, 2],\n",
    "                   self.wires[i + 1],\n",
    "               )\n",
    "           \n",
    "           if self.num_wires > 2: \n",
    "               qml.IsingXX(self.xx_weights[layer, -1], wires=[self.wires[-1], self.wires[0]])\n",
    "               qml.Rot(\n",
    "                   self.one_qubit_weights[self.n_layers + layer, -2, 0],\n",
    "                   self.one_qubit_weights[self.n_layers + layer, -2, 1],\n",
    "                   self.one_qubit_weights[self.n_layers + layer, -2, 2],\n",
    "                   self.wires[-1],\n",
    "               )\n",
    "               qml.Rot(\n",
    "                   self.one_qubit_weights[self.n_layers + layer, -1, 0],\n",
    "                   self.one_qubit_weights[self.n_layers + layer, -1, 1],\n",
    "                   self.one_qubit_weights[self.n_layers + layer, -1, 2],\n",
    "                   self.wires[0],\n",
    "               )\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "source": [
    "from qulearn import qlayer\n",
    "import pennylane as qml\n",
    "import torch\n",
    "from torch import nn\n",
    "import itertools\n",
    "\n",
    "\n",
    "num_qubits = 3\n",
    "embed = LinearAmplitudeEmbedding(num_qubits)\n",
    "n_layers = 0\n",
    "var1 = qlayer.AltRotCXLayer(wires=num_qubits, n_layers=n_layers)\n",
    "var2 = qlayer.AltRotCXLayer(wires=num_qubits, n_layers=n_layers)\n",
    "var3 = AltRotCRXLayer(num_qubits, n_layers=n_layers)\n",
    "\n",
    "#var3.initial_layer_weights = var1.initial_layer_weights\n",
    "#var3.one_qubit_weights = var1.weights\n",
    "var1.initial_layer_weights = var3.initial_layer_weights\n",
    "var1.weights = var3.one_qubit_weights\n",
    "\n",
    "\n",
    "hads = qlayer.HadamardLayer(num_qubits)\n",
    "obs = qml.PauliZ(0)\n",
    "obs1 = qml.PauliZ(0)\n",
    "obs2 = qml.PauliZ(1)\n",
    "obs3 = qml.PauliZ(2)\n",
    "obs = [qml.Identity(0)] + [qml.PauliZ(j) for j in range(num_qubits)]\n",
    "\n",
    "class CombinedModel(nn.Module):\n",
    "    def __init__(self, *models):\n",
    "        super(CombinedModel, self).__init__()\n",
    "        self.models = nn.ModuleList(models)\n",
    "        self.weights = nn.Parameter(torch.randn(len(models)))\n",
    "        self.bias = nn.Parameter(torch.randn(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = [model(x) * weight for model, weight in zip(self.models, self.weights)]\n",
    "        return sum(outputs) + self.bias\n",
    "    \n",
    "def generate_bitstrings(n):\n",
    "    return list(itertools.product([0, 1], repeat=n))\n",
    "\n",
    "qdev = qml.device(wires=num_qubits, name=\"lightning.qubit\")\n",
    "#qdev = qml.device(wires=num_qubits, name=\"default.qubit\")\n",
    "diff_method = \"adjoint\"\n",
    "#diff_method = \"backprop\"\n",
    "\n",
    "def create_models(bitstrings, embed, var, num_qubits):\n",
    "    models = []\n",
    "    for bitstring in bitstrings:\n",
    "        obs = qml.Projector(basis_state=list(bitstring), wires=range(num_qubits))\n",
    "        model = qlayer.MeasurementLayer(embed, var, observables=obs, measurement_type=qlayer.MeasurementType.Expectation, qdevice=qdev, diff_method=diff_method)\n",
    "        models.append(model)\n",
    "    return models\n",
    "\n",
    "def create_models_1q(embed, var, num_qubits):\n",
    "    models = []\n",
    "    for q in range(num_qubits):\n",
    "        obs = qml.Projector(basis_state=[0], wires=[q])\n",
    "        model = qlayer.MeasurementLayer(embed, var, observables=obs, measurement_type=qlayer.MeasurementType.Expectation, qdevice=qdev, diff_method=diff_method)\n",
    "        models.append(model)\n",
    "        obs = qml.Projector(basis_state=[1], wires=[q])\n",
    "        model = qlayer.MeasurementLayer(embed, var, observables=obs, measurement_type=qlayer.MeasurementType.Expectation, qdevice=qdev, diff_method=diff_method)\n",
    "        models.append(model)\n",
    "    return models\n",
    "\n",
    "states = generate_bitstrings(num_qubits)\n",
    "models = create_models_1q(embed, var3, num_qubits)\n",
    "combined_model = CombinedModel(*models)\n",
    "\n",
    "\n",
    "\n",
    "model1 = qlayer.MeasurementLayer(embed, var3, observables=obs1, measurement_type=qlayer.MeasurementType.Expectation)\n",
    "model2 = qlayer.MeasurementLayer(embed, var3, observables=obs2, measurement_type=qlayer.MeasurementType.Expectation)\n",
    "model3 = qlayer.MeasurementLayer(embed, var3, observables=obs3, measurement_type=qlayer.MeasurementType.Expectation)\n",
    "model = qlayer.HamiltonianLayer(embed, var3, observables=obs, qdevice=qdev, diff_method=diff_method)\n",
    "\n",
    "model = model\n",
    "drawer = qml.draw(model.qnode, show_all_wires=True, expansion_strategy=\"device\")\n",
    "x = torch.rand((1), dtype=torch.float64)\n",
    "print(drawer(x))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "source": [
    "import pennylane as qml\n",
    "import torch\n",
    "#obs = qml.PauliZ(0) @ qml.PauliZ(1)  \n",
    "U = qml.matrix(var1.circuit)\n",
    "O = qml.matrix(obs)\n",
    "O = torch.tensor(O, dtype=torch.complex64)\n",
    "res = torch.mm(torch.mm(U().conj().t(), O), U())\n",
    "print(res)\n",
    "print(O)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define Pauli matrices and Identity\n",
    "X = np.array([[0, 1], [1, 0]], dtype=complex)\n",
    "Y = np.array([[0, -1j], [1j, 0]], dtype=complex)\n",
    "Z = np.array([[1, 0], [0, -1]], dtype=complex)\n",
    "I = np.array([[1, 0], [0, 1]], dtype=complex)\n",
    "\n",
    "#print(\"X:\\n\", X)\n",
    "#print(\"Y:\\n\", Y)\n",
    "#print(\"Z:\\n\", Z)\n",
    "#print(\"I:\\n\", I)\n",
    "\n",
    "# Kronecker product of two matrices (e.g., Pauli X and Pauli Y)\n",
    "ZII = np.kron(Z, np.kron(I, I))\n",
    "XII = np.kron(X, np.kron(I, I))\n",
    "IIX = np.kron(I, np.kron(I, X))\n",
    "IIY = np.kron(I, np.kron(I, Y))\n",
    "YII = np.kron(Y, np.kron(I, I))\n",
    "print(\"ZII:\\n\", ZII)\n",
    "print(\"XII:\\n\", XII)\n",
    "print(\"IIX:\\n\", IIX)\n",
    "print(\"IIY:\\n\", IIY)\n",
    "print(\"YII:\\n\", YII)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "a = 1\n",
    "x_values = torch.linspace(-a, a, steps=200, dtype=torch.float64).unsqueeze(\n",
    "    1\n",
    ")\n",
    "with torch.no_grad():\n",
    "    y_values = model(x_values)\n",
    "    y1 = model1(x_values)\n",
    "    y2 = model2(x_values)\n",
    "    y3 = model3(x_values)\n",
    "\n",
    "# Convert to numpy for plotting\n",
    "x_values_np = x_values.numpy()\n",
    "y_values_np = y_values.squeeze().numpy()\n",
    "y1 = y1.squeeze().numpy()\n",
    "y2 = y2.squeeze().numpy()\n",
    "y3 = y3.squeeze().numpy()\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(x_values_np, y_values_np, label=\"model\")\n",
    "plt.plot(x_values_np, y1, label=\"model1\")\n",
    "plt.plot(x_values_np, y2, label=\"model2\")\n",
    "plt.plot(x_values_np, y3, label=\"model3\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"model(x)\")\n",
    "plt.title(\"Plot of the function (x, model(x))\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "a = 0.3\n",
    "b = 0.5\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def lambda1(beta1, beta2):\n",
    "    nom = (b - a) * (beta1 - beta2)\n",
    "    denom = (b - a - 1) * beta2 - (b - a) * beta1\n",
    "\n",
    "    return nom / denom\n",
    "\n",
    "\n",
    "def lambda2(beta1, beta2):\n",
    "    nom = (b - a - 1) * (beta1 - beta2)\n",
    "    denom = (b - a - 1) * beta2 - (b - a) * beta1\n",
    "\n",
    "    return nom / denom\n",
    "\n",
    "\n",
    "def effbeta(beta1, beta2):\n",
    "    lam1 = lambda1(beta1, beta2)\n",
    "    lam2 = lambda2(beta1, beta2)\n",
    "\n",
    "    beta = beta1 * (lam1 + 1) * (1 + a - b) + beta2 * (b - a) * (lam2 + 1)\n",
    "    # beta = np.cos(beta1) + np.sin(beta2)\n",
    "    return beta"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Create a meshgrid for the range of beta1 and beta2 values\n",
    "beta1_range = np.linspace(0.01, 1000, 100)\n",
    "beta2_range = np.linspace(0.01, 1000, 100)\n",
    "beta1, beta2 = np.meshgrid(beta1_range, beta2_range)\n",
    "\n",
    "# Compute effbeta for each combination of beta1 and beta2\n",
    "eff_beta_values = effbeta(beta1, beta2)\n",
    "\n",
    "# Create a heat plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(\n",
    "    eff_beta_values,\n",
    "    extent=(0.05, 400, 0.05, 400),\n",
    "    origin=\"lower\",\n",
    "    aspect=\"auto\",\n",
    ")\n",
    "plt.colorbar(label=\"effbeta\")\n",
    "plt.xlabel(\"beta1\")\n",
    "plt.ylabel(\"beta2\")\n",
    "plt.title(\"Heat Plot of effbeta\")\n",
    "plt.show()\n",
    "\n",
    "# Create a surface plot\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "surf = ax.plot_surface(beta1, beta2, eff_beta_values, cmap=\"viridis\")\n",
    "fig.colorbar(surf, ax=ax, shrink=0.5, aspect=5)\n",
    "ax.set_xlabel(\"beta1\")\n",
    "ax.set_ylabel(\"beta2\")\n",
    "ax.set_zlabel(\"effbeta\")\n",
    "ax.set_title(\"Surface Plot of effbeta\")\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from qulearn.qlayer import CircuitLayer\n",
    "import pennylane as qml\n",
    "\n",
    "\n",
    "class QFTLayer(CircuitLayer):\n",
    "    def __init__(self, wires) -> None:\n",
    "        super().__init__(wires)\n",
    "\n",
    "    def circuit(self, _):\n",
    "        qml.QFT(wires=self.wires)\n",
    "\n",
    "\n",
    "class RYLayer(CircuitLayer):\n",
    "    def __init__(self, wires) -> None:\n",
    "        super().__init__(wires)\n",
    "\n",
    "    def circuit(self, x):\n",
    "        for xj, w in zip(x, self.wires):\n",
    "            qml.RY(xj, w)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import pennylane as qml\n",
    "from qulearn.qlayer import (\n",
    "    AltRotCXLayer,\n",
    "    ParallelEntangledIQPEncoding,\n",
    "    ParallelIQPEncoding,\n",
    "    MeasurementLayer,\n",
    "    MeasurementType,\n",
    "    IQPERYCZLayer,\n",
    "    RYCZLayer,\n",
    "    IQPEAltRotCXLayer,\n",
    "    HadamardLayer,\n",
    "    HamiltonianLayer,\n",
    "    IQPEmbeddingLayer,\n",
    "    AltRXCXLayer,\n",
    ")\n",
    "from qulearn.qkernel import QKernel\n",
    "from qulearn.trainer import RidgeRegression\n",
    "import torch\n",
    "from torch.nn import MSELoss\n",
    "import logging\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "num_features = 2\n",
    "num_feature_repeat = 2\n",
    "wires = num_features * num_feature_repeat\n",
    "embed = ParallelIQPEncoding(\n",
    "    wires, num_features=num_features, base=3.0, omega=1.0, n_repeat=1\n",
    ")\n",
    "hads = HadamardLayer(wires=wires)\n",
    "var1 = AltRotCXLayer(wires=wires, n_layers=0)\n",
    "var2 = AltRotCXLayer(wires=wires, n_layers=0)\n",
    "var3 = AltRotCXLayer(wires=wires, n_layers=0)\n",
    "obs = [qml.PauliZ(j) for j in range(wires)]\n",
    "\n",
    "qdevice = qml.device(\"default.qubit\", wires=wires, shots=None)\n",
    "interface = \"torch\"\n",
    "diff_method = \"backprop\"\n",
    "\n",
    "model = MeasurementLayer(\n",
    "    var1,\n",
    "    embed,\n",
    "    var2,\n",
    "    embed,\n",
    "    var3,\n",
    "    observables=obs,\n",
    "    measurement_type=MeasurementType.Expectation,\n",
    ")\n",
    "drawer = qml.draw(model.qnode, show_all_wires=True, expansion_strategy=\"device\")\n",
    "x = 2 * torch.rand(10, num_features) - 1\n",
    "print(drawer(x))\n",
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "print(qml.specs(model.qnode)(x))\n",
    "\n",
    "print(\"x =\", x.shape)\n",
    "y = model(x)\n",
    "print(\"y =\", y.shape)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import itertools\n",
    "\n",
    "\n",
    "class ClassicalSurrogate2(nn.Module):\n",
    "    def __init__(self, num_features, max_frequency):\n",
    "        super(ClassicalSurrogate2, self).__init__()\n",
    "\n",
    "        self.num_features = num_features\n",
    "        self.max_frequency = max_frequency\n",
    "        self.frequency_range = list(range(-max_frequency, max_frequency + 1))\n",
    "        self.num_omegas = len(self.frequency_range) ** num_features\n",
    "\n",
    "        self.alpha = nn.Parameter(\n",
    "            torch.empty(self.num_omegas, dtype=torch.float64)\n",
    "        )\n",
    "        self.beta = nn.Parameter(\n",
    "            torch.empty(self.num_omegas, dtype=torch.float64)\n",
    "        )\n",
    "        nn.init.normal_(self.alpha)\n",
    "        nn.init.normal_(self.beta)\n",
    "\n",
    "        # Assume z_function is identity by default, can be replaced with any transformation\n",
    "        self.z_function = lambda x: x\n",
    "\n",
    "    def forward(self, x):\n",
    "        z_x = self.z_function(x)\n",
    "        outputs = torch.zeros(x.size(0), dtype=torch.float64)\n",
    "\n",
    "        index = 0\n",
    "        for omega in itertools.product(\n",
    "            self.frequency_range, repeat=self.num_features\n",
    "        ):\n",
    "            omega = torch.tensor(omega, dtype=torch.float64)\n",
    "\n",
    "            # Compute dot product\n",
    "            dot_product = torch.matmul(z_x, omega)\n",
    "\n",
    "            # Compute cosine and sine values\n",
    "            cos_value = torch.cos(dot_product)\n",
    "            sin_value = torch.sin(dot_product)\n",
    "\n",
    "            # Weighted sum of cosine and sine values for each sample\n",
    "            outputs += (\n",
    "                self.alpha[index] * cos_value + self.beta[index] * sin_value\n",
    "            )\n",
    "            index += 1\n",
    "\n",
    "        return outputs.unsqueeze(1)\n",
    "\n",
    "    def fit_fourier_coefficients(self, X, Y):\n",
    "        with torch.no_grad():\n",
    "            z_x = self.z_function(X)\n",
    "            features_cos = []\n",
    "            features_sin = []\n",
    "\n",
    "            for omega in itertools.product(\n",
    "                self.frequency_range, repeat=self.num_features\n",
    "            ):\n",
    "                omega = torch.tensor(omega, dtype=torch.float64)\n",
    "\n",
    "                # Compute dot product\n",
    "                dot_product = torch.matmul(z_x, omega)\n",
    "\n",
    "                # Compute cosine and sine values\n",
    "                features_cos.append(torch.cos(dot_product))\n",
    "                features_sin.append(torch.sin(dot_product))\n",
    "\n",
    "            # Stack features\n",
    "            features = torch.cat(\n",
    "                [torch.stack(features_cos).t(), torch.stack(features_sin).t()],\n",
    "                dim=1,\n",
    "            )\n",
    "\n",
    "            # Solve the least squares problem A*c = b\n",
    "            coefficients = torch.linalg.lstsq(\n",
    "                features, Y, driver=\"gelsd\"\n",
    "            ).solution.squeeze()\n",
    "\n",
    "            # Update the parameters with the new coefficients\n",
    "            self.alpha.data = coefficients[: self.num_omegas]\n",
    "            self.beta.data = coefficients[self.num_omegas :]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import itertools\n",
    "\n",
    "\n",
    "class ClassicalSurrogate(nn.Module):\n",
    "    def __init__(self, num_features, max_frequency):\n",
    "        super(ClassicalSurrogate, self).__init__()\n",
    "\n",
    "        # Create the omega spectrum using all combinations of frequencies for each feature dimension\n",
    "        frequency_range = range(-max_frequency, max_frequency + 1)\n",
    "        omega_spectrum = list(\n",
    "            itertools.product(frequency_range, repeat=num_features)\n",
    "        )\n",
    "        self.omegas = torch.tensor(omega_spectrum, dtype=torch.float64)\n",
    "\n",
    "        self.alpha = nn.Parameter(\n",
    "            torch.empty(len(omega_spectrum), dtype=torch.float64)\n",
    "        )\n",
    "        self.beta = nn.Parameter(\n",
    "            torch.empty(len(omega_spectrum), dtype=torch.float64)\n",
    "        )\n",
    "        nn.init.normal_(self.alpha)\n",
    "        nn.init.normal_(self.beta)\n",
    "\n",
    "        # Assume z_function is identity by default, can be replaced with any transformation\n",
    "        self.z_function = lambda x: x\n",
    "\n",
    "    def forward(self, x):\n",
    "        z_x = self.z_function(x)\n",
    "\n",
    "        # Compute dot product\n",
    "        dot_products = torch.mm(z_x, self.omegas.t())\n",
    "\n",
    "        # Compute cosine and sine values\n",
    "        cos_values = torch.cos(dot_products)\n",
    "        sin_values = torch.sin(dot_products)\n",
    "\n",
    "        # Weighted sum of cosine and sine values for each sample\n",
    "        outputs = torch.sum(\n",
    "            self.alpha.squeeze() * cos_values\n",
    "            + self.beta.squeeze() * sin_values,\n",
    "            dim=1,\n",
    "        )\n",
    "        return outputs.unsqueeze(1)\n",
    "\n",
    "    def fit_fourier_coefficients(self, X, Y):\n",
    "        with torch.no_grad():\n",
    "            # Compute the feature vectors for the dataset\n",
    "            z_x = self.z_function(X)\n",
    "            dot_products = torch.mm(z_x, self.omegas.t())\n",
    "            cos_values = torch.cos(dot_products)\n",
    "            sin_values = torch.sin(dot_products)\n",
    "\n",
    "            # Stack features and add a column for the bias term\n",
    "            features = torch.cat([cos_values, sin_values], dim=1)\n",
    "\n",
    "            # Solve the least squares problem A*c = b\n",
    "            coefficients = torch.linalg.lstsq(\n",
    "                features, Y, driver=\"gelsd\"\n",
    "            ).solution.squeeze()\n",
    "\n",
    "            # Update the parameters with the new coefficients\n",
    "            self.alpha.data = coefficients[: self.omegas.size(0)]\n",
    "            self.beta.data = coefficients[self.omegas.size(0) :]\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "def id_z(x):\n",
    "    # For demonstration, we're returning x. Replace this with any required transformation.\n",
    "    return x\n",
    "\n",
    "\n",
    "# Assuming z(x) is a 3-dimensional vector, and each component can take values [1.0, 2.0] or [2.0, 3.0] or [1.0, 3.0]\n",
    "max_frequency = 3\n",
    "num_features = 2\n",
    "model = ClassicalSurrogate(\n",
    "    num_features=num_features, max_frequency=max_frequency\n",
    ")\n",
    "\n",
    "# Example forward pass:\n",
    "x = torch.randn((1, num_features), dtype=torch.float64)\n",
    "output = model(x)\n",
    "print(output)\n",
    "print(output.shape)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import pennylane as qml\n",
    "from qulearn.qlayer import (\n",
    "    AltRotCXLayer,\n",
    "    ParallelIQPEncoding,\n",
    "    MeasurementLayer,\n",
    "    MeasurementType,\n",
    "    HamiltonianLayer,\n",
    ")\n",
    "\n",
    "\n",
    "class LeakyReLUNet(nn.Module):\n",
    "    def __init__(self, num_features, dim=64):\n",
    "        super(LeakyReLUNet, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(num_features, dim, dtype=torch.float64)\n",
    "        self.fc2 = nn.Linear(dim, dim, dtype=torch.float64)\n",
    "        self.fc3 = nn.Linear(dim, 1, dtype=torch.float64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "        x = F.leaky_relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "\n",
    "class QNN(nn.Module):\n",
    "    def __init__(self, num_wires, num_features, n_layers=2):\n",
    "        super().__init__()\n",
    "\n",
    "        var0 = AltRotCXLayer(wires=num_wires, n_layers=n_layers)\n",
    "        embed = ParallelIQPEncoding(\n",
    "            num_wires,\n",
    "            num_features=num_features,\n",
    "            base=3.0,\n",
    "            omega=1.0,\n",
    "            n_repeat=1,\n",
    "        )\n",
    "        var1 = AltRotCXLayer(wires=num_wires, n_layers=n_layers)\n",
    "        obs = [qml.PauliZ(j) for j in range(num_wires)]\n",
    "\n",
    "        qdev = qml.device(wires=num_wires, name=\"lightning.qubit\")\n",
    "        diff_method = \"adjoint\"\n",
    "        self.qnn = MeasurementLayer(\n",
    "            var0,\n",
    "            embed,\n",
    "            var1,\n",
    "            observables=obs,\n",
    "            measurement_type=MeasurementType.Expectation,\n",
    "            qdevice=qdev,\n",
    "            diff_method=diff_method,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        tmp = self.qnn(x)\n",
    "        return tmp\n",
    "\n",
    "\n",
    "class QNN2(nn.Module):\n",
    "    def __init__(self, num_wires, num_features, n_layers=2):\n",
    "        super().__init__()\n",
    "\n",
    "        var0 = AltRotCXLayer(wires=num_wires, n_layers=n_layers)\n",
    "        embed = ParallelIQPEncoding(\n",
    "            num_wires,\n",
    "            num_features=num_features,\n",
    "            base=3.0,\n",
    "            omega=1.0,\n",
    "            n_repeat=1,\n",
    "        )\n",
    "        var1 = AltRotCXLayer(wires=num_wires, n_layers=n_layers)\n",
    "        obs = [qml.Identity(0), qml.PauliZ(0)]\n",
    "\n",
    "        qdev = qml.device(wires=num_wires, name=\"lightning.qubit\")\n",
    "        diff_method = \"adjoint\"\n",
    "        self.qnn = HamiltonianLayer(\n",
    "            var0,\n",
    "            embed,\n",
    "            var1,\n",
    "            observables=obs,\n",
    "            qdevice=qdev,\n",
    "            diff_method=diff_method,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        tmp = self.qnn(x)\n",
    "        return tmp\n",
    "\n",
    "\n",
    "class QNN3(nn.Module):\n",
    "    def __init__(self, num_wires, num_features, n_layers=2):\n",
    "        super().__init__()\n",
    "\n",
    "        var0 = AltRotCXLayer(wires=num_wires, n_layers=n_layers)\n",
    "        embed = ParallelIQPEncoding(\n",
    "            num_wires,\n",
    "            num_features=num_features,\n",
    "            base=3.0,\n",
    "            omega=1.0,\n",
    "            n_repeat=1,\n",
    "        )\n",
    "        var1 = AltRotCXLayer(wires=num_wires, n_layers=n_layers)\n",
    "        self.qnn = MeasurementLayer(\n",
    "            var0, embed, var1, measurement_type=MeasurementType.Probabilities\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        tmp = self.qnn(x)\n",
    "        return tmp\n",
    "\n",
    "\n",
    "class QNN4(nn.Module):\n",
    "    def __init__(self, num_wires, num_features, n_layers=2):\n",
    "        super().__init__()\n",
    "\n",
    "        var0 = AltRotCXLayer(wires=num_wires, n_layers=n_layers)\n",
    "        embed = ParallelIQPEncoding(\n",
    "            num_wires,\n",
    "            num_features=num_features,\n",
    "            base=3.0,\n",
    "            omega=1.0,\n",
    "            n_repeat=1,\n",
    "        )\n",
    "        var1 = AltRotCXLayer(wires=num_wires, n_layers=n_layers)\n",
    "        obs = [qml.PauliZ(j) for j in range(num_wires)]\n",
    "\n",
    "        qdev = qml.device(wires=num_wires, name=\"lightning.qubit\")\n",
    "        diff_method = \"adjoint\"\n",
    "        self.qnn = MeasurementLayer(\n",
    "            var0,\n",
    "            embed,\n",
    "            var1,\n",
    "            observables=obs,\n",
    "            measurement_type=MeasurementType.Expectation,\n",
    "            qdevice=qdev,\n",
    "            diff_method=diff_method,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        tmp = self.qnn(x)\n",
    "        return tmp\n",
    "\n",
    "\n",
    "class QNN5(nn.Module):\n",
    "    def __init__(self, num_wires, n_layers=2):\n",
    "        super().__init__()\n",
    "\n",
    "        var0 = AltRotCXLayer(wires=num_wires, n_layers=n_layers)\n",
    "        obs = [qml.PauliZ(j) for j in range(num_wires)]\n",
    "\n",
    "        qdev = qml.device(wires=num_wires, name=\"lightning.qubit\")\n",
    "        diff_method = \"adjoint\"\n",
    "        self.qnn = MeasurementLayer(\n",
    "            var0,\n",
    "            observables=obs,\n",
    "            measurement_type=MeasurementType.Expectation,\n",
    "            qdevice=qdev,\n",
    "            diff_method=diff_method,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        tmp = self.qnn(x)\n",
    "        return tmp\n",
    "\n",
    "\n",
    "class Hybrid(nn.Module):\n",
    "    def __init__(self, num_wires, num_features, relu_dim=64, n_layers=2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.qnn = QNN(num_wires, num_features, n_layers)\n",
    "        self.lrelu = LeakyReLUNet(\n",
    "            num_features=num_wires + num_features, dim=relu_dim\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # tmp = torch.arccos(x)\n",
    "        tmp = 2.0 * torch.pi * torch.sigmoid(x) - torch.pi\n",
    "        # tmp = 2.0*torch.atan(x)\n",
    "        # tmp = x\n",
    "        tmp = self.qnn(tmp)\n",
    "        tmp = torch.cat((tmp, x), dim=-1)\n",
    "        tmp = self.lrelu(tmp)\n",
    "        return tmp\n",
    "\n",
    "\n",
    "num_features = 2\n",
    "num_repeat = 3\n",
    "num_layers = 2\n",
    "relu_dim = 64\n",
    "num_wires = num_features * num_repeat\n",
    "\n",
    "relu = LeakyReLUNet(num_features, relu_dim)\n",
    "qnn = QNN(num_wires, num_features, num_layers)\n",
    "qnn2 = QNN2(num_wires, num_features, num_layers)\n",
    "qnn3 = QNN3(num_wires, num_features, num_layers)\n",
    "qnn5 = QNN5(num_wires, num_layers)\n",
    "hybrid = Hybrid(num_wires, num_features, relu_dim)\n",
    "x = torch.randn((10, num_features), dtype=torch.float64)\n",
    "print(\"x =\", x.shape)\n",
    "y = qnn2(x)\n",
    "print(\"y =\", y.shape)\n",
    "# tmp = torch.mm(y.t(), y)\n",
    "# print(tmp)\n",
    "# tmp.backward()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "x = torch.randn((num_features), dtype=torch.float64)\n",
    "print(x.shape)\n",
    "x = x.unsqueeze(-1)\n",
    "print(x.shape)\n",
    "x = x.squeeze(-1)\n",
    "print(x.shape)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "# Assuming `model` is your pre-defined model\n",
    "# Assume `x` is a tensor representing your input variable, initialized at some value\n",
    "\n",
    "# Define the objective function\n",
    "a = torch.pi\n",
    "model = qnn\n",
    "x = torch.linspace(-a, a, steps=100, dtype=torch.float64).unsqueeze(1)\n",
    "\n",
    "\n",
    "def compute_variation(Y):\n",
    "    differences = Y[1:] - Y[:-1]\n",
    "\n",
    "    # Square the differences\n",
    "    squared_differences = differences**2\n",
    "\n",
    "    # Sum the squared differences\n",
    "    variation = torch.sum(squared_differences)\n",
    "\n",
    "    return variation\n",
    "\n",
    "\n",
    "def lossfn(x, model, component_indices):\n",
    "    # Forward pass to get the feature vector\n",
    "    feature_vector = model(x)\n",
    "\n",
    "    # Select the components to analyze\n",
    "    component1 = feature_vector[:, component_indices[0]]\n",
    "    component2 = feature_vector[:, component_indices[1]]\n",
    "\n",
    "    # Compute the variation (gradient) of each component w.r.t x and its magnitude\n",
    "    var1 = compute_variation(component1)\n",
    "    var2 = compute_variation(component2)\n",
    "\n",
    "    # Compute the difference in magnitudes of variations\n",
    "    loss = -var1 + var2\n",
    "\n",
    "    # Minimize the absolute difference in magnitudes of variations\n",
    "    return loss\n",
    "\n",
    "\n",
    "# Select indices of components to compare\n",
    "component_indices = [1, 2]  # Replace with your chosen indices\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "# Optimization loop\n",
    "for step in range(30):  # Number of optimization steps\n",
    "    optimizer.zero_grad()\n",
    "    loss = lossfn(x, model, component_indices)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if step % 10 == 0:\n",
    "        print(f\"Step {step}, Loss: {loss.item()}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming `model` is already defined and has a method `forward` that can be called with a torch tensor.\n",
    "# Replace 'model' with your actual model variable.\n",
    "\n",
    "# Define the range for x\n",
    "model = hybrid\n",
    "a = torch.pi\n",
    "# a = 5\n",
    "# a = 1\n",
    "x_values = torch.linspace(-a, a, steps=200, dtype=torch.float64).unsqueeze(\n",
    "    1\n",
    ")  # Replace -10 and 10 with your range of x values.\n",
    "\n",
    "# Calculate model predictions\n",
    "with torch.no_grad():  # We do not need to track gradients for this operation\n",
    "    y_values = model(x_values)\n",
    "    # y_values = 2.0*torch.pi*torch.sigmoid(x_values.unsqueeze(1))-torch.pi\n",
    "    # y_values = torch.sigmoid(x_values.unsqueeze(1))\n",
    "    # y_values1 = model(x_values.unsqueeze(1))[:, 0]\n",
    "    # y_values2 = model(x_values.unsqueeze(1))[:, 1]\n",
    "    # y_values3 = model(x_values.unsqueeze(1))[:, 2]\n",
    "    # y_values_arcsin = torch.arctan(y_values)\n",
    "    # y_values_arcsin = torch.zeros(len(y_values))\n",
    "\n",
    "# Convert to numpy for plotting\n",
    "x_values_np = x_values.numpy()\n",
    "y_values_np = y_values.squeeze().numpy()\n",
    "# y_values_np1 = y_values1.squeeze().numpy()\n",
    "# y_values_np2 = y_values2.squeeze().numpy()\n",
    "# y_values_np3 = y_values3.squeeze().numpy()\n",
    "# y_values_np_arcsin = y_values_arcsin.squeeze().numpy()\n",
    "\n",
    "# Plotting\n",
    "for k in range(1):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(x_values_np, y_values_np, label=\"model\")\n",
    "    # plt.plot(x_values_np, y_values_np1, label='Z_0')\n",
    "    # plt.plot(x_values_np, y_values_np2, label='Z_1')\n",
    "    # plt.plot(x_values_np, y_values_np3, label='Z_2')\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"model(x)\")\n",
    "    plt.title(\"Plot of the function (x, model(x))\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "# Fetch the California housing dataset\n",
    "california_housing = fetch_california_housing()\n",
    "X, Y = california_housing.data, california_housing.target\n",
    "\n",
    "# Rescale the features to the range [-pi, pi]\n",
    "scaler = MinMaxScaler(feature_range=(-np.pi, np.pi))\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset into train and test sets (80% train, 20% test)\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(\n",
    "    X_scaled, Y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Convert arrays to tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float64)\n",
    "Y_train = torch.tensor(Y_train, dtype=torch.float64).view(-1, 1)\n",
    "X_valid = torch.tensor(X_valid, dtype=torch.float64)\n",
    "Y_valid = torch.tensor(Y_valid, dtype=torch.float64).view(-1, 1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "from pyDOE import lhs\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Generate samples using Latin Hypercube Sampling\n",
    "n_train = 500  # Number of samples\n",
    "n_valid = 100\n",
    "lower_bounds = np.array([10, 10])\n",
    "upper_bounds = np.array([300, 300])\n",
    "X_train = lhs(2, samples=n_train)\n",
    "X_train = lower_bounds + (upper_bounds - lower_bounds) * X_train\n",
    "\n",
    "lower_bounds = np.array([0.01, 0.01])\n",
    "upper_bounds = np.array([700, 700])\n",
    "X_valid = lhs(2, samples=n_valid)\n",
    "X_valid = lower_bounds + (upper_bounds - lower_bounds) * X_valid\n",
    "\n",
    "# Evaluate the function at each sample point and add Gaussian noise\n",
    "Y_train = np.array([effbeta(sample[0], sample[1]) for sample in X_train])\n",
    "sigma = 0.001\n",
    "noise = np.random.normal(0, sigma, Y_train.shape)\n",
    "Y_train = Y_train + noise\n",
    "\n",
    "Y_valid = np.array([effbeta(sample[0], sample[1]) for sample in X_valid])\n",
    "\n",
    "# 2D Scatter Heat Map\n",
    "plt.figure(figsize=(8, 6))\n",
    "sc = plt.scatter(X_train[:, 0], X_train[:, 1], c=Y_train, cmap=\"viridis\")\n",
    "plt.colorbar(sc)\n",
    "plt.xlabel(\"Beta 1\")\n",
    "plt.ylabel(\"Beta 2\")\n",
    "plt.title(\"2D Scatter Heat Map\")\n",
    "plt.show()\n",
    "\n",
    "# 3D Scatter Plot\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "sc = ax.scatter(\n",
    "    X_train[:, 0], X_train[:, 1], Y_train, c=Y_train, cmap=\"viridis\"\n",
    ")\n",
    "plt.colorbar(sc)\n",
    "ax.set_xlabel(\"Beta 1\")\n",
    "ax.set_ylabel(\"Beta 2\")\n",
    "ax.set_zlabel(\"Effbeta\")\n",
    "plt.title(\"3D Scatter Plot\")\n",
    "plt.show()\n",
    "\n",
    "# 2D Scatter Heat Map\n",
    "plt.figure(figsize=(8, 6))\n",
    "sc = plt.scatter(X_valid[:, 0], X_valid[:, 1], c=Y_valid, cmap=\"viridis\")\n",
    "plt.colorbar(sc)\n",
    "plt.xlabel(\"Beta 1\")\n",
    "plt.ylabel(\"Beta 2\")\n",
    "plt.title(\"2D Scatter Heat Map\")\n",
    "plt.show()\n",
    "\n",
    "# 3D Scatter Plot\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "sc = ax.scatter(\n",
    "    X_valid[:, 0], X_valid[:, 1], Y_valid, c=Y_valid, cmap=\"viridis\"\n",
    ")\n",
    "plt.colorbar(sc)\n",
    "ax.set_xlabel(\"Beta 1\")\n",
    "ax.set_ylabel(\"Beta 2\")\n",
    "ax.set_zlabel(\"Effbeta\")\n",
    "plt.title(\"3D Scatter Plot\")\n",
    "plt.show()\n",
    "\n",
    "# Convert arrays to tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float64)\n",
    "Y_train = torch.tensor(Y_train, dtype=torch.float64).view(-1, 1)\n",
    "X_valid = torch.tensor(X_valid, dtype=torch.float64)\n",
    "Y_valid = torch.tensor(Y_valid, dtype=torch.float64).view(-1, 1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Rescale the features to the range [-pi, pi]\n",
    "scaler_input = MinMaxScaler(feature_range=(-2, 2))\n",
    "scaler_output = MinMaxScaler(feature_range=(-2, 2))\n",
    "scaler_input.fit(X_train)\n",
    "scaler_output.fit(Y_train)\n",
    "X_train = scaler_input.transform(X_train)\n",
    "X_valid = scaler_input.transform(X_valid)\n",
    "Y_train = scaler_output.transform(Y_train)\n",
    "Y_valid = scaler_output.transform(Y_valid)\n",
    "\n",
    "# plots\n",
    "# 2D Scatter Heat Map\n",
    "plt.figure(figsize=(8, 6))\n",
    "sc = plt.scatter(X_train[:, 0], X_train[:, 1], c=Y_train, cmap=\"viridis\")\n",
    "plt.colorbar(sc)\n",
    "plt.xlabel(\"Beta 1\")\n",
    "plt.ylabel(\"Beta 2\")\n",
    "plt.title(\"2D Scatter Heat Map\")\n",
    "plt.show()\n",
    "\n",
    "# 3D Scatter Plot\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "sc = ax.scatter(\n",
    "    X_train[:, 0], X_train[:, 1], Y_train, c=Y_train, cmap=\"viridis\"\n",
    ")\n",
    "plt.colorbar(sc)\n",
    "ax.set_xlabel(\"Beta 1\")\n",
    "ax.set_ylabel(\"Beta 2\")\n",
    "ax.set_zlabel(\"Effbeta\")\n",
    "plt.title(\"3D Scatter Plot\")\n",
    "plt.show()\n",
    "\n",
    "# 2D Scatter Heat Map\n",
    "plt.figure(figsize=(8, 6))\n",
    "sc = plt.scatter(X_valid[:, 0], X_valid[:, 1], c=Y_valid, cmap=\"viridis\")\n",
    "plt.colorbar(sc)\n",
    "plt.xlabel(\"Beta 1\")\n",
    "plt.ylabel(\"Beta 2\")\n",
    "plt.title(\"2D Scatter Heat Map\")\n",
    "plt.show()\n",
    "\n",
    "# 3D Scatter Plot\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "sc = ax.scatter(\n",
    "    X_valid[:, 0], X_valid[:, 1], Y_valid, c=Y_valid, cmap=\"viridis\"\n",
    ")\n",
    "plt.colorbar(sc)\n",
    "ax.set_xlabel(\"Beta 1\")\n",
    "ax.set_ylabel(\"Beta 2\")\n",
    "ax.set_zlabel(\"Effbeta\")\n",
    "plt.title(\"3D Scatter Plot\")\n",
    "plt.show()\n",
    "\n",
    "# Convert arrays to tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float64)\n",
    "Y_train = torch.tensor(Y_train, dtype=torch.float64).view(-1, 1)\n",
    "X_valid = torch.tensor(X_valid, dtype=torch.float64)\n",
    "Y_valid = torch.tensor(Y_valid, dtype=torch.float64).view(-1, 1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import torch\n",
    "import logging\n",
    "from torch.optim import Adam, LBFGS\n",
    "from qulearn.trainer import SupervisedTrainer\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Data\n",
    "X_train = torch.tensor(X_train, dtype=torch.float64)\n",
    "X_valid = torch.tensor(X_valid, dtype=torch.float64)\n",
    "Y_train = torch.tensor(Y_train, dtype=torch.float64).unsqueeze(1)\n",
    "Y_valid = torch.tensor(Y_valid, dtype=torch.float64).unsqueeze(1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "source": [
    "import torch\n",
    "\n",
    "# Generate a sample of inputs\n",
    "X = torch.linspace(-1, 1, 1000).reshape(-1, 1)\n",
    "\n",
    "\n",
    "# Define a function to add Gaussian noise\n",
    "def add_gaussian_noise(tensor, mean=0.0, std=0.01):\n",
    "    return tensor + torch.randn(tensor.size()) * std + mean\n",
    "\n",
    "\n",
    "# 1. Linear Relationship\n",
    "def linear(X, m=2, c=3):\n",
    "    return m * X + c\n",
    "\n",
    "\n",
    "Y_linear = add_gaussian_noise(linear(X))\n",
    "\n",
    "\n",
    "# 2. Polynomial Relationship (Quadratic for demonstration)\n",
    "def polynomial(X, a=3, b=2, c=-5):\n",
    "    return a * X**2 + b * X + c\n",
    "\n",
    "\n",
    "Y_polynomial = add_gaussian_noise(polynomial(X))\n",
    "\n",
    "\n",
    "# 3. Exponential Relationship\n",
    "def exponential(X, a=2, b=0.5):\n",
    "    return a * torch.exp(b * X)\n",
    "\n",
    "\n",
    "Y_exponential = add_gaussian_noise(exponential(X))\n",
    "\n",
    "\n",
    "# 4. Logarithmic Relationship\n",
    "def logarithmic(X, a=3, b=2):\n",
    "    return a * torch.log(X) + b\n",
    "\n",
    "\n",
    "Y_logarithmic = add_gaussian_noise(logarithmic(X))\n",
    "\n",
    "\n",
    "# 5. Trigonometric Relationship\n",
    "def trigonometric(X, a=5, b=2, c=0.5):\n",
    "    return a * torch.sin(b * X + c)\n",
    "\n",
    "\n",
    "Y_trigonometric = add_gaussian_noise(trigonometric(X))\n",
    "\n",
    "\n",
    "# 6. Power-law Relationship\n",
    "def power_law(X, a=2, b=1.5):\n",
    "    return a * X**b\n",
    "\n",
    "\n",
    "Y_power_law = add_gaussian_noise(power_law(X))\n",
    "\n",
    "\n",
    "# 7. Sigmoidal Relationship\n",
    "def sigmoidal(X, L=1, k=0.5, x0=5):\n",
    "    return L / (1 + torch.exp(-k * (X - x0)))\n",
    "\n",
    "\n",
    "Y_sigmoidal = add_gaussian_noise(sigmoidal(X))\n",
    "\n",
    "\n",
    "# 8. Gaussian Relationship\n",
    "def gaussian(X, a=1.0, b=0, c=1):\n",
    "    return a * torch.exp(-((X - b) ** 2) / (2 * c**2))\n",
    "\n",
    "\n",
    "Y_gaussian = add_gaussian_noise(gaussian(X))\n",
    "\n",
    "\n",
    "# 9. Step Function\n",
    "def step_function(\n",
    "    X, threshold1=-0.5, threshold2=0.5, low_value=-1, mid_value=1, high_value=0\n",
    "):\n",
    "    condition1 = X < threshold1\n",
    "    condition2 = (X >= threshold1) & (X < threshold2)\n",
    "    condition3 = X >= threshold2\n",
    "\n",
    "    values = torch.zeros_like(X)\n",
    "    values[condition1] = low_value\n",
    "    values[condition2] = mid_value\n",
    "    values[condition3] = high_value\n",
    "\n",
    "    return values\n",
    "\n",
    "\n",
    "Y_step = add_gaussian_noise(step_function(X))\n",
    "\n",
    "\n",
    "def piecewise_linear_3segments(X, a=-1, b=1, m1=2, c1=0, m2=-3, m3=1):\n",
    "    # Define linear functions for each segment\n",
    "    linear_before_a = m1 * X + c1\n",
    "    linear_between_a_b = m1 * a + c1 + m2 * (X - a)\n",
    "    linear_after_b = m1 * a + c1 + m2 * (b - a) + m3 * (X - b)\n",
    "\n",
    "    # Apply conditions for each segment\n",
    "    conditions = [(X < a), (X >= a) & (X < b), (X >= b)]\n",
    "    functions = [linear_before_a, linear_between_a_b, linear_after_b]\n",
    "\n",
    "    output = torch.zeros_like(X)\n",
    "    for condition, function in zip(conditions, functions):\n",
    "        output[condition] = function[condition]\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "Y_piecewise_spiked = add_gaussian_noise(piecewise_linear_3segments(X))\n",
    "\n",
    "\n",
    "def multidimstep(X, a=1.0):\n",
    "    # Extract the first and second features\n",
    "    X0 = X[:, 0]\n",
    "    X1 = X[:, 1]\n",
    "\n",
    "    # Check the condition X[1] > a * X[0]\n",
    "    condition = X1 > a * X0\n",
    "\n",
    "    # Initialize the output tensor Y\n",
    "    Y = torch.zeros_like(X1)\n",
    "\n",
    "    # Set Y values based on the condition\n",
    "    Y[condition] = 1  # Set to +1 where condition is True\n",
    "    Y[~condition] = -1  # Set to -1 where condition is False\n",
    "\n",
    "    return Y.view(-1, 1)  # Reshape to make it a column vector\n",
    "\n",
    "\n",
    "def high_low(X, low=1.0, high=30.0):\n",
    "    return torch.sin(low * X) + 0.5 * torch.sin(high * X)\n",
    "\n",
    "\n",
    "Y_high_low = add_gaussian_noise(high_low(X))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create the scatter plot\n",
    "func = step_function\n",
    "func = gaussian\n",
    "sigma = 0.01\n",
    "Y = add_gaussian_noise(func(X), std=sigma)\n",
    "plt.plot(X, Y)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "source": [
    "import torch\n",
    "import logging\n",
    "from torch.optim import Adam\n",
    "from qulearn.trainer import SupervisedTrainer\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Data\n",
    "N_train = 100\n",
    "N_valid = 5\n",
    "batch_size = 25\n",
    "X_train = torch.linspace(-1, 1, N_train, dtype=torch.float64).reshape(-1, 1)\n",
    "Y_train = add_gaussian_noise(func(X_train), std=sigma)\n",
    "X_valid = torch.linspace(-1, 1, N_valid, dtype=torch.float64).reshape(-1, 1)\n",
    "Y_valid = func(X_valid)\n",
    "data_train = TensorDataset(X_train, Y_train)\n",
    "data_valid = TensorDataset(X_valid, Y_valid)\n",
    "loader_train = DataLoader(data_train, batch_size=batch_size, shuffle=False)\n",
    "loader_valid = DataLoader(data_valid, batch_size=batch_size, shuffle=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "model = relu\n",
    "y = model(X_train)\n",
    "print(y.shape)\n",
    "model = qnn\n",
    "y = model(X_train)\n",
    "print(y.shape)\n",
    "model = qnn2\n",
    "y = model(X_train)\n",
    "print(y.shape)\n",
    "model = hybrid\n",
    "y = model(X_train)\n",
    "print(y.shape)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import torch\n",
    "import logging\n",
    "from torch.optim import Adam, LBFGS\n",
    "from qulearn.trainer import SupervisedTrainer\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchmetrics.regression import MeanAbsolutePercentageError\n",
    "\n",
    "batch_size = 50\n",
    "data_train = TensorDataset(X_train, Y_train)\n",
    "data_valid = TensorDataset(X_valid, Y_valid)\n",
    "loader_train = DataLoader(data_train, batch_size=batch_size, shuffle=True)\n",
    "loader_valid = DataLoader(data_valid, batch_size=batch_size, shuffle=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "source": [
    "import torch\n",
    "import logging\n",
    "from torch.optim import Adam, LBFGS\n",
    "from qulearn.trainer import SupervisedTrainer\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchmetrics.regression import MeanAbsolutePercentageError\n",
    "\n",
    "# Trainer\n",
    "lr = 0.1\n",
    "#model = combined_model\n",
    "optimizer = Adam(model.parameters(), lr=lr, amsgrad=True)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "metric = MeanAbsolutePercentageError()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "source": [
    "logger = logging.getLogger(\"train_function\")\n",
    "logger.setLevel(level=logging.INFO)\n",
    "num_epochs = 200\n",
    "trainer = SupervisedTrainer(\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=loss_fn,\n",
    "    metrics={\"MARE\": metric},\n",
    "    num_epochs=num_epochs,\n",
    "    logger=logger,\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "source": [
    "# Train\n",
    "trainer.train(model, train_data=loader_train, valid_data=loader_valid)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "source": [
    "# Plotting\n",
    "X = torch.linspace(-1, 1, 1000, dtype=torch.float64).reshape(-1, 1)\n",
    "Y_exact = func(X)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    Y_model = model(X)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(X, Y_exact, label=\"exact\", color=\"blue\")\n",
    "plt.plot(X, Y_model, label=\"predicted\", color=\"red\")\n",
    "\n",
    "# Adding title and labels\n",
    "plt.title(\"Exact vs. Model\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from torchmetrics.regression import MeanAbsolutePercentageError\n",
    "\n",
    "predicted_train = model(X_train)\n",
    "predicted_valid = model(X_valid)\n",
    "\n",
    "metric = MeanAbsolutePercentageError()\n",
    "loss_train = metric(predicted_train, Y_train)\n",
    "loss_valid = metric(predicted_valid, Y_valid)\n",
    "print(\"train loss: \", loss_train)\n",
    "print(\"valid_loss: \", loss_valid)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from torchmetrics.regression import MeanAbsolutePercentageError\n",
    "\n",
    "model.fit_fourier_coefficients(X_train, Y_train)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "predicted_train = model(X_train)\n",
    "predicted_valid = model(X_valid)\n",
    "\n",
    "metric = MeanAbsolutePercentageError()\n",
    "metric = torch.nn.MSELoss()\n",
    "loss_train = metric(predicted_train, Y_train)\n",
    "loss_valid = metric(predicted_valid, Y_valid)\n",
    "print(\"train loss: \", loss_train)\n",
    "print(\"valid_loss: \", loss_valid)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = ClassicalSurrogate(id_z, all_combinations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(model.omegas)\n",
    "alphas = np.zeros(9)\n",
    "betas = np.zeros(9)\n",
    "alphas[8] = 1.0\n",
    "betas[5] = 1\n",
    "#model.alpha.data = torch.tensor(alphas)\n",
    "#model.beta.data = torch.tensor(betas)\n",
    "\n",
    "grid_size = 10\n",
    "x = np.linspace(1, 2, grid_size)\n",
    "y = np.linspace(1, 2, grid_size)\n",
    "X_train = np.transpose([np.tile(x, len(y)), np.repeat(y, len(x))])\n",
    "Y_train = np.sin(X_train[:, 1])\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float64)\n",
    "Y_train = torch.tensor(Y_train, dtype=torch.float64).unsqueeze(1)\n",
    "\n",
    "predicted = model(X_train)\n",
    "loss = loss_fn(predicted, Y_train)\n",
    "print(\"Before fitting: \", loss)\n",
    "\n",
    "model.fit_fourier_coefficients(X_train, Y_train)\n",
    "\n",
    "predicted = model(X_train)\n",
    "loss = loss_fn(predicted, Y_train)\n",
    "print(\"After fitting: \", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Create a meshgrid for the range of beta1 and beta2 values\n",
    "beta1_range = np.linspace(0.01, 700, 100)\n",
    "beta2_range = np.linspace(0.01, 700, 100)\n",
    "\n",
    "beta1, beta2 = np.meshgrid(beta1_range, beta2_range)\n",
    "betas = np.vstack([beta1.ravel(), beta2.ravel()]).T\n",
    "betas = scaler_input.transform(betas)\n",
    "betas_tensor = torch.tensor(betas, dtype=torch.float64)\n",
    "\n",
    "# Compute effbeta for each combination of beta1 and beta2\n",
    "with torch.no_grad():\n",
    "    predicted = model(betas_tensor)\n",
    "\n",
    "predicted_reshaped = predicted.reshape(beta1.shape)\n",
    "\n",
    "# Create a surface plot\n",
    "beta1_original_flat, beta2_original_flat = np.split(betas, 2, axis=1)\n",
    "# Reshape back to the original meshgrid format\n",
    "beta1 = beta1_original_flat.reshape(beta1.shape)\n",
    "beta2 = beta2_original_flat.reshape(beta2.shape)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "surf = ax.plot_surface(beta1, beta2, predicted_reshaped, cmap=\"viridis\")\n",
    "fig.colorbar(surf, ax=ax, shrink=0.5, aspect=5)\n",
    "ax.set_xlabel(\"beta1\")\n",
    "ax.set_ylabel(\"beta2\")\n",
    "ax.set_zlabel(\"effbeta\")\n",
    "ax.set_title(\"Surface Plot of effbeta\")\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Create a meshgrid for the range of beta1 and beta2 values\n",
    "beta1_range = np.linspace(0.05, 400, 100)\n",
    "beta2_range = np.linspace(0.05, 400, 100)\n",
    "beta1, beta2 = np.meshgrid(beta1_range, beta2_range)\n",
    "\n",
    "exact = effbeta(beta1, beta2)\n",
    "exact_flat = exact.ravel().reshape(-1, 1)\n",
    "exact_scaled_flat = scaler_output.transform(exact_flat)\n",
    "exact_scaled = exact_scaled_flat.reshape(beta1.shape)\n",
    "\n",
    "betas = np.vstack([beta1.ravel(), beta2.ravel()]).T\n",
    "betas = scaler_input.transform(betas)\n",
    "betas_tensor = torch.tensor(betas, dtype=torch.float64)\n",
    "\n",
    "# Create a surface plot\n",
    "beta1_original_flat, beta2_original_flat = np.split(betas, 2, axis=1)\n",
    "# Reshape back to the original meshgrid format\n",
    "beta1 = beta1_original_flat.reshape(beta1.shape)\n",
    "beta2 = beta2_original_flat.reshape(beta2.shape)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "surf = ax.plot_surface(beta1, beta2, exact_scaled, cmap=\"viridis\")\n",
    "fig.colorbar(surf, ax=ax, shrink=0.5, aspect=5)\n",
    "ax.set_xlabel(\"beta1\")\n",
    "ax.set_ylabel(\"beta2\")\n",
    "ax.set_zlabel(\"effbeta\")\n",
    "ax.set_title(\"Surface Plot of effbeta\")\n",
    "plt.show()"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QuLearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
