{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import tntorch as tn\n",
    "import pennylane as qml"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "source": [
    "tt = tn.randn([2]*5, ranks_tt=[2, 10, 5, 4])\n",
    "tt /= tt.norm()\n",
    "print(tt)\n",
    "print(\"TT norm\", tt.norm())\n",
    "\n",
    "c = tt.cores[0]\n",
    "cm = c.reshape(-1, 1)\n",
    "norm = torch.sqrt(torch.mm(cm.T, cm))\n",
    "print(\"Norm core 0: \", norm)\n",
    "\n",
    "c = tt.cores[4]\n",
    "cm = c.reshape(-1, 1)\n",
    "norm = torch.sqrt(torch.mm(cm.T, cm))\n",
    "print(\"Norm core 4: \", norm)\n",
    "\n",
    "c = tt.cores[0]\n",
    "rows = [0, 1]\n",
    "cols = [2]\n",
    "new = rows + cols\n",
    "row_size = torch.prod(torch.tensor(c.shape)[rows]).item()\n",
    "col_size = torch.prod(torch.tensor(c.shape)[cols]).item()\n",
    "cp = c.permute(*new)\n",
    "cr = cp.reshape(row_size, col_size)\n",
    "cm = torch.mm(cr.T, cr)\n",
    "print(\"ID core 0: \", cm)\n",
    "\n",
    "c = tt.cores[4]\n",
    "rows = [1, 2]\n",
    "cols = [0]\n",
    "new = rows + cols\n",
    "row_size = torch.prod(torch.tensor(c.shape)[rows]).item()\n",
    "col_size = torch.prod(torch.tensor(c.shape)[cols]).item()\n",
    "cp = c.permute(*new)\n",
    "cr = cp.reshape(row_size, col_size)\n",
    "cm = torch.mm(cr.T, cr)\n",
    "print(\"ID core 4: \", cm)\n",
    "\n",
    "c = tt.cores[2]\n",
    "rows = [0, 1]\n",
    "cols = [2]\n",
    "new = rows + cols\n",
    "row_size = torch.prod(torch.tensor(c.shape)[rows]).item()\n",
    "col_size = torch.prod(torch.tensor(c.shape)[cols]).item()\n",
    "cp = c.permute(*new)\n",
    "cr = cp.reshape(row_size, col_size)\n",
    "cm = torch.mm(cr.T, cr)\n",
    "print(\"ID core 2 right: \", cm)\n",
    "\n",
    "c = tt.cores[2]\n",
    "rows = [1, 2]\n",
    "cols = [0]\n",
    "new = rows + cols\n",
    "row_size = torch.prod(torch.tensor(c.shape)[rows]).item()\n",
    "col_size = torch.prod(torch.tensor(c.shape)[cols]).item()\n",
    "cp = c.permute(*new)\n",
    "cr = cp.reshape(row_size, col_size)\n",
    "cm = torch.mm(cr.T, cr)\n",
    "print(\"ID core 2 left: \", cm)\n",
    "\n",
    "\n",
    "tt.orthogonalize(4)\n",
    "print(\"------------AFTER------------\")\n",
    "\n",
    "\n",
    "c = tt.cores[0]\n",
    "cm = c.reshape(-1, 1)\n",
    "norm = torch.sqrt(torch.mm(cm.T, cm))\n",
    "print(\"Norm core 0: \", norm)\n",
    "\n",
    "c = tt.cores[4]\n",
    "cm = c.reshape(-1, 1)\n",
    "norm = torch.sqrt(torch.mm(cm.T, cm))\n",
    "print(\"Norm core 4: \", norm)\n",
    "\n",
    "c = tt.cores[0]\n",
    "rows = [0, 1]\n",
    "cols = [2]\n",
    "new = rows + cols\n",
    "row_size = torch.prod(torch.tensor(c.shape)[rows]).item()\n",
    "col_size = torch.prod(torch.tensor(c.shape)[cols]).item()\n",
    "cp = c.permute(*new)\n",
    "cr = cp.reshape(row_size, col_size)\n",
    "cm = torch.mm(cr.T, cr)\n",
    "print(\"ID core 0: \", cm)\n",
    "\n",
    "c = tt.cores[4]\n",
    "rows = [1, 2]\n",
    "cols = [0]\n",
    "new = rows + cols\n",
    "row_size = torch.prod(torch.tensor(c.shape)[rows]).item()\n",
    "col_size = torch.prod(torch.tensor(c.shape)[cols]).item()\n",
    "cp = c.permute(*new)\n",
    "cr = cp.reshape(row_size, col_size)\n",
    "cm = torch.mm(cr.T, cr)\n",
    "print(\"ID core 4: \", cm)\n",
    "\n",
    "c = tt.cores[2]\n",
    "rows = [0, 1]\n",
    "cols = [2]\n",
    "new = rows + cols\n",
    "row_size = torch.prod(torch.tensor(c.shape)[rows]).item()\n",
    "col_size = torch.prod(torch.tensor(c.shape)[cols]).item()\n",
    "cp = c.permute(*new)\n",
    "cr = cp.reshape(row_size, col_size)\n",
    "cm = torch.mm(cr.T, cr)\n",
    "print(\"ID core 2 right: \", cm)\n",
    "\n",
    "c = tt.cores[2]\n",
    "rows = [1, 2]\n",
    "cols = [0]\n",
    "new = rows + cols\n",
    "row_size = torch.prod(torch.tensor(c.shape)[rows]).item()\n",
    "col_size = torch.prod(torch.tensor(c.shape)[cols]).item()\n",
    "cp = c.permute(*new)\n",
    "cr = cp.reshape(row_size, col_size)\n",
    "cm = torch.mm(cr.T, cr)\n",
    "print(\"ID core 2 left: \", cm)\n",
    "\n",
    "print(type(tt))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "source": [
    "def contract(tt, L):\n",
    "    cores = tt.cores\n",
    "    result = cores[0].clone().detach()\n",
    "    for i in range(1, L):\n",
    "        result = torch.tensordot(result, cores[i], dims=([result.dim() - 1], [0]))\n",
    "        \n",
    "    return result\n",
    "\n",
    "tmp = contract(tt, L=2)\n",
    "print(tmp.shape)\n",
    "print(type(tmp))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "source": [
    "core = tt.cores[1]\n",
    "print(core.shape)\n",
    "\n",
    "def embed2unitary(Q):\n",
    "    k = Q.shape[-1] # this always assumes Q is a tall matrix\n",
    "    U, _, _ = torch.linalg.svd(Q, full_matrices=True)\n",
    "    Q_ = torch.cat((Q, U[:, k:]), dim=1)\n",
    "    return Q_"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "source": [
    "dev = qml.device('default.qubit', wires=1)\n",
    "U = 1 / np.sqrt(2) * np.array([[1, 1], [1, -1]])\n",
    "U = 2*np.array([[0, 1], [1, 0]])\n",
    "\n",
    "print(qml.math.einsum(\"...ij,...kj->...ik\", U, qml.math.conj(U)))\n",
    "dim = 2\n",
    "print(qml.math.allclose(\n",
    "                qml.math.einsum(\"...ij,...kj->...ik\", U, qml.math.conj(U)),\n",
    "                qml.math.eye(dim),\n",
    "                atol=1e-6,\n",
    "            ))\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def example_circuit():\n",
    "    qml.QubitUnitary(U, wires=0, unitary_check=False)\n",
    "    return qml.expval(qml.PauliZ(0))\n",
    "print(example_circuit())\n",
    "drawer = qml.draw(example_circuit, show_all_wires=True, expansion_strategy=\"device\")\n",
    "print(drawer())"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "source": [
    "tt = tn.randn([2]*5, ranks_tt=[4, 4, 4, 2])\n",
    "\n",
    "def compute_s(tt):\n",
    "    s = int(torch.ceil(torch.log2(max(tt.ranks_tt))))\n",
    "    return s\n",
    "\n",
    "s = compute_s(tt)\n",
    "def pad_cores(tt):\n",
    "    s = compute_s(tt)\n",
    "    chi = 2**s\n",
    "    cores = tt.cores.copy()\n",
    "    \n",
    "    core = cores[0]\n",
    "    rankR = chi - core.shape[-1]\n",
    "    pad = (0, rankR)\n",
    "    cores[0] = F.pad(core, pad)\n",
    "    \n",
    "    core = cores[-1]\n",
    "    rankL = chi - core.shape[0]\n",
    "    pad = (0, 0, 0, 0, 0, rankL)\n",
    "    cores[-1] = F.pad(core, pad)\n",
    "\n",
    "    for j in range(1, len(cores)-1):\n",
    "        core = cores[j]\n",
    "        rankL = chi - core.shape[0]\n",
    "        rankR = chi - core.shape[-1]\n",
    "        pad = (0, rankR, 0, 0, 0, rankL)\n",
    "        cores[j] = F.pad(core, pad)\n",
    "\n",
    "    tt_ = tn.Tensor(cores)      \n",
    "    return tt_\n",
    "\n",
    "tt_ = pad_cores(tt)\n",
    "print(tt)\n",
    "print(tt_)\n",
    "\n",
    "diff = tt - tt_\n",
    "print(diff.norm())\n",
    "\n",
    "#print(tt.cores[0])\n",
    "#print(tt.cores[0][0, 0, 0])\n",
    "#print(tt.cores[0][0, 1, 0])\n",
    "#print(tt_.cores[0])\n",
    "#print(tt.cores[0][0, 0, 0])\n",
    "#print(tt.cores[0][0, 1, 0])\n",
    "\n",
    "#print(tt.cores[2])\n",
    "#print(tt.cores[2][0, 0, 0])\n",
    "#print(tt.cores[2][0, 1, 0])\n",
    "#print(tt_.cores[2])\n",
    "#print(tt.cores[2][0, 0, 0])\n",
    "#print(tt.cores[2][0, 1, 0])\n",
    "\n",
    "#print(tt.cores[4])\n",
    "#print(tt.cores[4][0, 0, 0])\n",
    "#print(tt.cores[4][0, 1, 0])\n",
    "#print(tt_.cores[4])\n",
    "#print(tt.cores[4][0, 0, 0])\n",
    "#print(tt.cores[4][0, 1, 0])\n",
    "\n",
    "tt_.orthogonalize(4)\n",
    "tt.orthogonalize(4)\n",
    "print(tt_)\n",
    "diff = tt - tt_\n",
    "print(diff.norm())"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "source": [
    "print(s)\n",
    "print(tt_)\n",
    "core = contract(tt_, L=s+1)\n",
    "print(core.shape)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "source": [
    "# left, inner and right reshapings\n",
    "def left_core_reshape(core, s):\n",
    "    rows = list(range(0, s+2))\n",
    "    row_size = torch.prod(torch.tensor(core.shape)[rows]).item()\n",
    "    Q = core.reshape(row_size, -1)\n",
    "    return Q\n",
    "\n",
    "def reg_core_reshape(core):\n",
    "    rows = [0, 1]\n",
    "    row_size = torch.prod(torch.tensor(core.shape)[rows]).item()\n",
    "    Q = core.reshape(row_size, -1)\n",
    "    return Q\n",
    "\n",
    "#Q = left_core_reshape(core, s)\n",
    "print(type(core))\n",
    "Q = reg_core_reshape(core)\n",
    "print(Q.shape)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "source": [
    "# tt to unitary list\n",
    "def tt2unitaries(tt):\n",
    "    N = tt.dim()\n",
    "    tt_ = pad_cores(tt)\n",
    "    tt_.orthogonalize(N-1)\n",
    "    \n",
    "    s = compute_s(tt)\n",
    "    Us = []\n",
    "    \n",
    "    core = contract(tt_, L=s+1)\n",
    "    Q0 = left_core_reshape(core, s)\n",
    "    Us.append(embed2unitary(Q0))\n",
    "    \n",
    "    cores = tt_.cores.copy()\n",
    "    for j in range(s+1, N):\n",
    "        core = cores[j]\n",
    "        Q = reg_core_reshape(core)\n",
    "        Us.append(embed2unitary(Q))\n",
    "\n",
    "    return Us\n",
    "\n",
    "tt = tn.randn([2]*5, ranks_tt=[4, 4, 4, 2])\n",
    "tt /= tt.norm()\n",
    "print(tt)\n",
    "Us = tt2unitaries(tt)\n",
    "print(len(Us))\n",
    "\n",
    "for U in Us:\n",
    "    print(U.shape)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "source": [
    "from qulearn.mps import MPSQGates\n",
    "mpsgates = MPSQGates(tt)\n",
    "Us = mpsgates.qgates()\n",
    "print(len(Us))\n",
    "\n",
    "for U in Us:\n",
    "    print(U.shape)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "source": [
    "# unitary list to circuit\n",
    "num_qubits = 5\n",
    "tt = tn.randn([2]*num_qubits, ranks_tt=4)\n",
    "tt /= tt.norm()\n",
    "\n",
    "# pad\n",
    "tt_ = pad_cores(tt)\n",
    "diff = tt - tt_\n",
    "print(diff.norm())\n",
    "\n",
    "# orthog\n",
    "N = tt.dim()\n",
    "tt_.orthogonalize(N-1)\n",
    "print(tt_)\n",
    "\n",
    "# unitaries\n",
    "Us = tt2unitaries(tt)\n",
    "U = Us[-3]\n",
    "core = tt_.cores[-3]\n",
    "core = contract(tt_, 3)\n",
    "print(U.shape)\n",
    "print(core.shape)\n",
    "\n",
    "Q1 = U.T[:, :4]\n",
    "Q2 = core.reshape(8, 4)\n",
    "Q2_ = embed2unitary(Q2)\n",
    "print(Q1.shape)\n",
    "print(Q2.shape)\n",
    "print(Q1)\n",
    "print(Q2)\n",
    "print(Q2_.T[:, :4])\n",
    "\n",
    "print(torch.mm(U.T, U))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "source": [
    "num_qubits = 5\n",
    "tt = tn.randn([2]*num_qubits, ranks_tt=4)\n",
    "tt /= tt.norm()\n",
    "s = compute_s(tt)\n",
    "dev = qml.device('default.qubit', wires=num_qubits)\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def ttunitaries2circuit(Us, num_qubits, s):\n",
    "    N = len(Us)\n",
    "    count = 0\n",
    "    for k in range(N-1, -1, -1):\n",
    "        wires = list(range(num_qubits-count-s-1, num_qubits-count))\n",
    "        qml.QubitUnitary(Us[k], wires=wires, unitary_check=False)\n",
    "        count += 1\n",
    "\n",
    "    return qml.state()\n",
    "\n",
    "print(tt)\n",
    "s = compute_s(tt)\n",
    "Us = tt2unitaries(tt)\n",
    "drawer = qml.draw(ttunitaries2circuit, wire_order=range(num_qubits), show_all_wires=True, expansion_strategy=\"device\")\n",
    "print(drawer(Us, num_qubits, s))\n",
    "print(\"circuit: \", ttunitaries2circuit(Us, num_qubits, s).real)\n",
    "\n",
    "psi = torch.zeros(32, 1)\n",
    "psi[0] = 1.0\n",
    "\n",
    "I = torch.eye(4)\n",
    "U3 = Us[-1]\n",
    "U3 = torch.kron(I, U3)\n",
    "U2 = Us[-2]\n",
    "I = torch.eye(2)\n",
    "U2 = torch.kron(torch.kron(I, U2), I)\n",
    "I = torch.eye(4)\n",
    "U1 = Us[-3]\n",
    "U1 = torch.kron(U1, I)\n",
    "\n",
    "psi = torch.mm(U3, psi)\n",
    "psi = torch.mm(U2, psi)\n",
    "#psi = torch.mm(U1, psi)\n",
    "print(\"psi.T: \", psi.T)\n",
    "\n",
    "tt_ = pad_cores(tt)\n",
    "tt_.orthogonalize(num_qubits-1)\n",
    "print(tt_)\n",
    "newcore = contract(tt_, s+1)\n",
    "print(newcore.shape)\n",
    "I = torch.eye(8)\n",
    "Q3 = tt_.cores[-1]\n",
    "\n",
    "print(\"=====================================\")\n",
    "print(\"Q3 reshaped: \", Q3.reshape(8, 1).T)\n",
    "zero = torch.zeros(8, 1)\n",
    "zero[0] = 1\n",
    "tmp = torch.mm(Us[-1], zero)\n",
    "print(\"U3: \", tmp.T)\n",
    "print(\"=====================================\")\n",
    "\n",
    "Q2 = I[:, :4]\n",
    "Q2 = Q2.reshape(4, 2, 4)\n",
    "Q2 = tt_.cores[-2]\n",
    "\n",
    "print(\"=====================================\")\n",
    "print(\"Q2 reshaped: \", Q2.reshape(8, 4))\n",
    "U = Us[-2]\n",
    "U = U.reshape(4, 2, 2, 4)\n",
    "zero = torch.zeros(2, 1)\n",
    "zero[0] = 1\n",
    "U = torch.tensordot(U, zero, dims=([2], [0]))\n",
    "#U = torch.permute(U, (0, 1, 2, 5, 4, 3))\n",
    "print(U.shape)\n",
    "U = U.reshape(8, 4)\n",
    "print(\"U2: \", U)\n",
    "print(\"=====================================\")\n",
    "\n",
    "print(\"Q2 shape\", Q2.shape)\n",
    "Q1 = I[:, :4]\n",
    "Q1 = Q1.reshape(2, 2, 2, 4)\n",
    "\n",
    "print(Q1.shape)\n",
    "print(Q2.shape)\n",
    "print(Q3.shape)\n",
    "\n",
    "vec = torch.tensordot(Q1, Q2, dims=([-1], [0]))\n",
    "vec = torch.tensordot(vec, Q3, dims=([-1], [0]))\n",
    "print(vec.shape)\n",
    "vec = vec.reshape(32)\n",
    "\n",
    "print(\"psi = \", psi.T)\n",
    "print(\"vec = \", vec)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "source": [
    "psi = ttunitaries2circuit(Us, num_qubits, s)\n",
    "ttfull = tt.torch().reshape(2**num_qubits)\n",
    "print(tt)\n",
    "print(psi.shape)\n",
    "print(ttfull.shape)\n",
    "print(psi.real)\n",
    "print(\"=======\")\n",
    "print(ttfull)\n",
    "print(\"================DIFF===================\")\n",
    "diff = torch.tensor(psi.real) - ttfull\n",
    "print(torch.linalg.norm(diff))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def linear_FEM_basis(x, n):\n",
    "    num_nodes = 2 ** n\n",
    "    nodes = np.linspace(-1, 1, num_nodes)\n",
    "    nodes = torch.tensor(nodes, dtype=torch.float64)\n",
    "\n",
    "    # Initialize the output tensor\n",
    "    values = torch.zeros(x.shape[0], num_nodes, dtype=torch.float64)\n",
    "    \n",
    "    # Distance between nodes\n",
    "    h = 2 / (num_nodes - 1)\n",
    "\n",
    "    # Handle tensor input for x\n",
    "    for i in range(1, num_nodes):\n",
    "        mask = (nodes[i - 1] <= x) & (x <= nodes[i])\n",
    "        values[mask, i - 1] = (nodes[i] - x[mask]) / h\n",
    "        values[mask, i] = (x[mask] - nodes[i - 1]) / h\n",
    "\n",
    "    #values = torch.sqrt(values)\n",
    "    #norms = torch.linalg.norm(values, dim=1, keepdim=True)\n",
    "    #values /= norms\n",
    "    return values.squeeze(0)#, norms"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "source": [
    "def find_grid_points(x, n, a=-1.0, b=1.0):\n",
    "    num_segments = 2**n - 1\n",
    "    length = b - a\n",
    "    segment_length = length / num_segments\n",
    "\n",
    "    # Ensure x is a torch tensor\n",
    "    if not isinstance(x, torch.Tensor):\n",
    "        x = torch.tensor(x, dtype=torch.float64)\n",
    "\n",
    "    # Initialize left_point and right_point\n",
    "    left_point = torch.zeros_like(x)\n",
    "    right_point = torch.zeros_like(x)\n",
    "\n",
    "    # Handle the case where x is left of a\n",
    "    left_of_a = x < a\n",
    "    left_point[left_of_a] = a - segment_length\n",
    "    right_point[left_of_a] = a\n",
    "\n",
    "    # Handle the case where x is right of b\n",
    "    right_of_b = x > b\n",
    "    left_point[right_of_b] = b\n",
    "    right_point[right_of_b] = b + segment_length\n",
    "\n",
    "    # Calculate position for values within the range [a, b]\n",
    "    within_range = torch.logical_not(torch.logical_or(left_of_a, right_of_b))\n",
    "    position = torch.zeros_like(x)\n",
    "    position[within_range] = ((x[within_range] - a) / segment_length).floor()\n",
    "    left_point[within_range] = a + position[within_range] * segment_length\n",
    "    right_point[within_range] = left_point[within_range] + segment_length\n",
    "\n",
    "    # Assign -1 to position where x is left of a, and -2 where x is right of b\n",
    "    position[left_of_a] = -1\n",
    "    position[right_of_b] = -2\n",
    "\n",
    "    return left_point, right_point, position\n",
    "\n",
    "# determine values \\Phi(x) for k, k+1\n",
    "def lin1dfembasis_nonz_vals(x, left, right, h):\n",
    "    first = (right-x)/h\n",
    "    second = (x-left)/h\n",
    "    return first, second\n",
    "\n",
    "# check if correct\n",
    "n = 3\n",
    "x = torch.tensor([-2.0, -1.0, -0.99, 0.0, -0.3, 0.9, 1.0, 1.3], dtype=torch.float64)\n",
    "h = torch.tensor(2/(2**n-1), dtype=torch.float64)\n",
    "left, right, pos = find_grid_points(x, n)\n",
    "first, second = lin1dfembasis_nonz_vals(x, left, right, h)\n",
    "\n",
    "print(\"x =\", x)\n",
    "print(\"Left Points:\", left)\n",
    "print(\"Right Points:\", right)\n",
    "print(\"Position:\", pos)\n",
    "print(\"First: \", first)\n",
    "print(\"Second: \", second)\n",
    "print(\"Should sum to one: \", first+second)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "source": [
    "# TT for even case\n",
    "def tt_lin1dfembasis_evenidx(first, second, idx, n):\n",
    "    binidx = format(idx, '0{}b'.format(n))\n",
    "    # check if not too long\n",
    "    \n",
    "    cores = []\n",
    "    for j in range(n-1):\n",
    "        k = int(binidx[j])\n",
    "        core = torch.zeros((1, 2, 1))\n",
    "        core[0, k, 0] = 1.0\n",
    "        cores.append(core)\n",
    "        \n",
    "    core = torch.zeros(1, 2, 1)\n",
    "    core[0, 0, 0] = first\n",
    "    core[0, 1, 0] = second\n",
    "    cores.append(core)\n",
    "    tt = tn.Tensor(cores)\n",
    "    \n",
    "    return tt\n",
    "\n",
    "n = 3\n",
    "x = torch.tensor([-0.7], dtype=torch.float64)\n",
    "left, right, pos = find_grid_points(x, n)\n",
    "pos = int(pos.item())\n",
    "h = 2.0/(2**n-1)\n",
    "first, second = lin1dfembasis_nonz_vals(x, left, right, h)\n",
    "tt = tt_lin1dfembasis_evenidx(first, second, pos, n)\n",
    "print(tt)\n",
    "\n",
    "# check\n",
    "print(\"pos:\", pos)\n",
    "print(\"tt vectorized:\")\n",
    "print(tt.torch().reshape(2**n))\n",
    "Phi = linear_FEM_basis(x, n)\n",
    "print(Phi)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "source": [
    "print(\"hello \"\\\n",
    "    \"there\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "source": [
    "# TT for odd case\n",
    "import math\n",
    "\n",
    "def zerobit_position_odd(k, n):\n",
    "    if k % 2 == 0:\n",
    "        m = 0\n",
    "    else :\n",
    "        m = int(math.log2((-k) & (k + 1)))\n",
    "    pos = n - m - 1\n",
    "    return int(pos)\n",
    "\n",
    "k = 13\n",
    "n = 5\n",
    "binidx = format(k, '0{}b'.format(n))\n",
    "zerobit = zerobit_position_odd(k, n)\n",
    "\n",
    "print(\"k:\", k)\n",
    "print(\"binary:\", binidx)\n",
    "print(\"zero bit:\", zerobit)\n",
    "\n",
    "def tt_lin1dfembasis_oddidx(first, second, idx, n):\n",
    "    binidx = format(idx, '0{}b'.format(n))\n",
    "    zerobit = zerobit_position_odd(idx, n)\n",
    "    # check if not too long\n",
    "    \n",
    "    cores = []\n",
    "    for j in range(zerobit):\n",
    "        k = int(binidx[j])\n",
    "        core = torch.zeros((1, 2, 1))\n",
    "        core[0, k, 0] = 1.0\n",
    "        cores.append(core)\n",
    "\n",
    "    if zerobit != n-1:\n",
    "        core = torch.zeros(1, 2, 2)\n",
    "        core[0, 0, 1] = 1.0\n",
    "        core[0, 1, 0] = 1.0 \n",
    "        cores.append(core)\n",
    "    \n",
    "    for j in range(zerobit+1, n-1):\n",
    "        core = torch.zeros((2, 2, 2))\n",
    "        core[0, 0, 0] = 1.0\n",
    "        core[1, 1, 1] = 1.0\n",
    "        cores.append(core)\n",
    "    \n",
    "    if zerobit != n-1:\n",
    "        core = torch.zeros(2, 2, 1)\n",
    "        core[0, 0, 0] = second\n",
    "        core[1, 1, 0] = first\n",
    "        cores.append(core)\n",
    "    else:\n",
    "        core = torch.zeros(1, 2, 1)\n",
    "        core[0, 0, 0] = second\n",
    "        core[0, 1, 0] = first\n",
    "        cores.append(core)\n",
    "    \n",
    "    tt = tn.Tensor(cores)\n",
    "    \n",
    "    return tt\n",
    "\n",
    "n = 3\n",
    "x = torch.tensor([0.65], dtype=torch.float64)\n",
    "left, right, pos = find_grid_points(x, n)\n",
    "pos = int(pos.item())\n",
    "h = 2.0/(2**n-1)\n",
    "first, second = lin1dfembasis_nonz_vals(x, left, right, h)\n",
    "tt_even = tt_lin1dfembasis_evenidx(first, second, pos, n)\n",
    "tt_odd = tt_lin1dfembasis_oddidx(first, second, pos, n)\n",
    "print(\"TT EVEN\")\n",
    "print(tt_even)\n",
    "print(\"TT ODD\")\n",
    "print(tt_odd)\n",
    "\n",
    "# check\n",
    "print(\"pos:\", pos)\n",
    "print(\"tt_even vectorized:\")\n",
    "print(tt_even.torch().reshape(2**n))\n",
    "print(\"tt_odd vectorized:\")\n",
    "print(tt_odd.torch().reshape(2**n))\n",
    "Phi = linear_FEM_basis(x, n)\n",
    "print(\"exact Phi:\")\n",
    "print(Phi)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "source": [
    "num_qubits = 2\n",
    "dev = qml.device('default.qubit', wires=num_qubits)\n",
    "@qml.qnode(dev)\n",
    "def linear1dFEMcircuit(x, num_qubits, sqrt=False, normalize=False):\n",
    "    left, right, pos = find_grid_points(x, num_qubits)\n",
    "    pos = int(pos.item())\n",
    "    h = 2.0/(2**num_qubits-1)\n",
    "    first, second = lin1dfembasis_nonz_vals(x, left, right, h)\n",
    "    \n",
    "    if sqrt:\n",
    "        first = torch.sqrt(first)\n",
    "        second = torch.sqrt(second)\n",
    "        \n",
    "    if normalize:\n",
    "        norm = torch.sqrt(first*first + second*second)\n",
    "        first /= norm\n",
    "        second /= norm\n",
    "    \n",
    "    even = pos%2 == 0\n",
    "    \n",
    "    if even:\n",
    "        tt = tt_lin1dfembasis_evenidx(first, second, pos, num_qubits)\n",
    "    else:\n",
    "        tt = tt_lin1dfembasis_oddidx(first, second, pos, num_qubits)\n",
    "        \n",
    "    s = compute_s(tt)\n",
    "    Us = tt2unitaries(tt)\n",
    "    N = len(Us)\n",
    "    count = 0\n",
    "    for k in range(N-1, -1, -1):\n",
    "        wires = list(range(num_qubits-count-s-1, num_qubits-count))\n",
    "        qml.QubitUnitary(Us[k], wires=wires, unitary_check=False)\n",
    "        count += 1\n",
    "\n",
    "    return qml.state()\n",
    "\n",
    "x = torch.tensor([0.4], dtype=torch.float64)\n",
    "Phi = linear_FEM_basis(x, num_qubits)\n",
    "psi = linear1dFEMcircuit(x, num_qubits)\n",
    "print(\"Phi\")\n",
    "print(Phi)\n",
    "print(\"psi\")\n",
    "print(psi.real)\n",
    "print(torch.tensor(psi.real)-Phi)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import itertools\n",
    "\n",
    "def plot_basis_combinations(x_values, basis_functions, n):\n",
    "    s = 2**n\n",
    "    grid_size=(s, s)\n",
    "    num_plots = grid_size[0] * grid_size[1]\n",
    "    _, axs = plt.subplots(grid_size[0], grid_size[1], figsize=(15, 15))\n",
    "\n",
    "    # Generate all unique combinations of basis functions\n",
    "    all_combinations = list(itertools.combinations_with_replacement(range(2**n), 2))\n",
    "    selected_combinations = all_combinations[:num_plots]\n",
    "\n",
    "    for idx, (i, j) in enumerate(selected_combinations):\n",
    "        combined_basis = basis_functions[:, i]*basis_functions[:, j]\n",
    "        axs[i, j].plot(x_values, combined_basis)\n",
    "        axs[i, j].set_title(f\"bf {i} x {j}\")\n",
    "        axs[i, j].grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "# Generate x values for plotting\n",
    "x_plot = torch.tensor(np.linspace(-1, 0.9999, 10))\n",
    "\n",
    "# Generate the basis functions for each x in x_plot\n",
    "M = len(x_plot)\n",
    "basis_functions = torch.zeros(M, 2**num_qubits)\n",
    "for m in range(M):\n",
    "    basis_functions[m, :] = torch.tensor(linear1dFEMcircuit(x_plot[m], num_qubits, sqrt=True))\n",
    "plot_basis_combinations(x_plot, basis_functions, num_qubits)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "source": [
    "import pennylane as qml\n",
    "from qulearn import qlayer\n",
    "import torch\n",
    "\n",
    "\n",
    "class Linear1DFEMEmbedding(qlayer.CircuitLayer):\n",
    "    def __init__(self, num_qubits, a=-1.0, b=1.0, sqrt=False, normalize=False):\n",
    "        super().__init__(num_qubits)\n",
    "        self.num_qubits = num_qubits\n",
    "        self.sqrt = sqrt\n",
    "        self.normalize = normalize\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "        self.norm = 1.0\n",
    "\n",
    "    def circuit(self, x):\n",
    "        left, right, pos = find_grid_points(x, self.num_qubits, a=self.a, b=self.b)\n",
    "        pos = int(pos.item())\n",
    "        length = self.b - self.a\n",
    "        h = length/(2**self.num_qubits-1)\n",
    "        first, second = lin1dfembasis_nonz_vals(x, left, right, h)\n",
    "    \n",
    "        if self.sqrt:\n",
    "            first = torch.sqrt(first)\n",
    "            second = torch.sqrt(second)\n",
    "        \n",
    "        if pos == -1:\n",
    "            self.norm = second\n",
    "            for q in range(num_qubits):\n",
    "                qml.Identity(wires=self.wires[q])\n",
    "            return None    \n",
    "        \n",
    "        elif pos == -2:\n",
    "            self.norm = first\n",
    "            for q in range(num_qubits):\n",
    "                qml.PauliX(wires=self.wires[q])\n",
    "            return None\n",
    "\n",
    "        self.norm = torch.sqrt(first*first + second*second)\n",
    "        if self.normalize:\n",
    "            first /= self.norm\n",
    "            second /= self.norm\n",
    "    \n",
    "        even = pos%2 == 0\n",
    "\n",
    "        if even:\n",
    "            tt = tt_lin1dfembasis_evenidx(first, second, pos, num_qubits)\n",
    "        else:\n",
    "            tt = tt_lin1dfembasis_oddidx(first, second, pos, num_qubits)\n",
    "            \n",
    "        s = compute_s(tt)\n",
    "        Us = tt2unitaries(tt)\n",
    "        N = len(Us)\n",
    "        count = 0\n",
    "        for k in range(N-1, -1, -1):\n",
    "            wires_idx = list(range(self.num_qubits-count-s-1, self.num_qubits-count))\n",
    "            subwires = [self.wires[idx] for idx in wires_idx]\n",
    "            qml.QubitUnitary(Us[k], wires=subwires, unitary_check=False)\n",
    "            count += 1\n",
    "            \n",
    "            \n",
    "    def compute_norm(self, x):\n",
    "        left, right, pos = find_grid_points(x, self.num_qubits, a=self.a, b=self.b)\n",
    "        pos = int(pos.item())\n",
    "        length = self.b - self.a\n",
    "        h = length/(2**self.num_qubits-1)\n",
    "        first, second = lin1dfembasis_nonz_vals(x, left, right, h)\n",
    "    \n",
    "        if self.sqrt:\n",
    "            first = torch.sqrt(first)\n",
    "            second = torch.sqrt(second)\n",
    "        \n",
    "        if pos == -1:\n",
    "            self.norm = second\n",
    "            return self.norm\n",
    "        elif pos == -2:\n",
    "            self.norm = first\n",
    "            return self.norm\n",
    "\n",
    "        self.norm = torch.sqrt(first*first + second*second)\n",
    "        return self.norm"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "source": [
    "from qulearn.hat_basis import HatBasis\n",
    "from qulearn.mps import HatBasisMPS, MPSQGates\n",
    "\n",
    "num_qubits = 5\n",
    "num_nodes = 2**num_qubits\n",
    "a = -1.0\n",
    "b = 1.0\n",
    "basis = HatBasis(a, b, num_nodes)\n",
    "hatmps = HatBasisMPS(basis)\n",
    "\n",
    "x = torch.tensor(0.0)\n",
    "mps = hatmps(x)\n",
    "\n",
    "mpsgates = MPSQGates(mps)\n",
    "Us = mpsgates.qgates()\n",
    "print(mps)\n",
    "print(len(Us))\n",
    "for U in Us:\n",
    "    print(U.shape)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "source": [
    "import pennylane as qml\n",
    "from qulearn import qlayer\n",
    "from torch import nn\n",
    "import math\n",
    "\n",
    "class TwoQubitRotCXMPSLayer(qlayer.CircuitLayer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        wires,\n",
    "        n_layers_mps = 1,\n",
    "        n_layers_block = 1,\n",
    "        reverse = False,\n",
    "        cdevice = None,\n",
    "        dtype = None,\n",
    "    ) -> None:\n",
    "        super().__init__(wires)\n",
    "\n",
    "        self.n_layers_mps = n_layers_mps\n",
    "        self.n_layers_block = n_layers_block\n",
    "        self.reverse = reverse\n",
    "        self.cdevice = cdevice\n",
    "        self.dtype = dtype\n",
    "        self.n_blocks = self.num_wires - 1\n",
    "        \n",
    "        self.weights = torch.nn.Parameter(\n",
    "            torch.empty((self.n_layers_mps, self.n_blocks, 2,\n",
    "                         self.n_layers_block, 3),\n",
    "                        device=self.cdevice, dtype=self.dtype)\n",
    "        )\n",
    "        self.weights_post = torch.nn.Parameter(\n",
    "            torch.empty((self.num_wires, 3),\n",
    "                        device=self.cdevice, dtype=self.dtype)\n",
    "        )\n",
    "        \n",
    "        nn.init.uniform_(self.weights, a=0.0, b=2 * math.pi)\n",
    "        nn.init.uniform_(self.weights_post, a=0.0, b=2 * math.pi)\n",
    "\n",
    "\n",
    "    def circuit(self, _ = None):\n",
    "        \n",
    "        for mps_layer_idx in range(self.n_layers_mps):\n",
    "            for block_idx in range(self.n_blocks-1, -1, -1) if self.reverse else range(self.n_blocks):\n",
    "                self._block(mps_layer_idx, block_idx)\n",
    "        \n",
    "        for i, q in enumerate(self.wires): \n",
    "            qml.Rot(\n",
    "                self.weights_post[i, 0],\n",
    "                self.weights_post[i, 1],\n",
    "                self.weights_post[i, 2],\n",
    "                q)\n",
    "    \n",
    "    def _block(self, mps_layer_idx, block_idx):\n",
    "        qprev = self.wires[block_idx]\n",
    "        qnext = self.wires[block_idx+1]\n",
    "        \n",
    "        for block_layer in range(self.n_layers_block):\n",
    "            qml.Rot(\n",
    "                self.weights[mps_layer_idx, block_idx, 0, block_layer, 0],\n",
    "                self.weights[mps_layer_idx, block_idx, 0, block_layer, 1],\n",
    "                self.weights[mps_layer_idx, block_idx, 0, block_layer, 2],\n",
    "                qprev)\n",
    "            qml.Rot(\n",
    "                self.weights[mps_layer_idx, block_idx, 1, block_layer, 0],\n",
    "                self.weights[mps_layer_idx, block_idx, 1, block_layer, 1],\n",
    "                self.weights[mps_layer_idx, block_idx, 1, block_layer, 2],\n",
    "                qnext)\n",
    "            qml.CNOT(wires=(qprev, qnext))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "source": [
    "import pennylane as qml\n",
    "from qulearn import qlayer\n",
    "from torch import nn\n",
    "import math\n",
    "\n",
    "class embedU(qlayer.CircuitLayer):\n",
    "    def __init__(self, num_qubits, U):\n",
    "        super().__init__(num_qubits)\n",
    "        self.num_qubits = num_qubits\n",
    "        self.U = U \n",
    "\n",
    "    def circuit(self, _):\n",
    "        qml.QubitUnitary(self.U, wires=self.wires, unitary_check=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "source": [
    "from qulearn import qlayer\n",
    "import pennylane as qml\n",
    "import torch\n",
    "from qulearn.hat_basis import HatBasis\n",
    "\n",
    "num_qubits = 3\n",
    "embed = Linear1DFEMEmbedding(num_qubits, sqrt=True)\n",
    "\n",
    "a = -1.0\n",
    "b = 1.0\n",
    "num_nodes = 2**num_qubits\n",
    "basis = HatBasis(a, b, num_nodes)\n",
    "embed2 = qlayer.HatBasisQFE(num_qubits, basis, sqrt=True)\n",
    "#embed = qlayer.ParallelIQPEncoding(num_qubits, num_features=1, n_repeat=1, base=3.0, omega=1.0)\n",
    "n_layers = 1\n",
    "var = qlayer.AltRotCXLayer(num_qubits, n_layers=n_layers)\n",
    "\n",
    "num_mps_layers = 1\n",
    "num_block_layers = 3\n",
    "reverse = True\n",
    "var = TwoQubitRotCXMPSLayer(num_qubits,  n_layers_mps=num_mps_layers, n_layers_block=num_block_layers, reverse=reverse)\n",
    "var = embedU(num_qubits, U.conj().T)\n",
    "\n",
    "hads = qlayer.HadamardLayer(num_qubits)\n",
    "obs = qml.PauliZ(4)\n",
    "I = qml.Identity(0)\n",
    "Z0 = qml.PauliZ(0)\n",
    "Z1 = qml.PauliZ(1)\n",
    "Z2 = qml.PauliZ(2)\n",
    "Z3 = qml.PauliZ(3)\n",
    "Zn = qml.PauliZ(num_qubits-1)\n",
    "#obs = [I, Z0, Z1, Z2, Z3, Zn]\n",
    "obs = [I, Z0]\n",
    "\n",
    "#obs = qml.Projector(basis_state=[1, 1, 1], wires=list(range(num_qubits)))\n",
    "model = qlayer.MeasurementLayer(embed, observables=obs, measurement_type=qlayer.MeasurementType.Expectation)\n",
    "model2 = qlayer.MeasurementLayer(embed2, observables=obs, measurement_type=qlayer.MeasurementType.Expectation)\n",
    "model = qlayer.HamiltonianLayer(embed, var, observables=obs)\n",
    "\n",
    "drawer = qml.draw(model.qnode, show_all_wires=True, expansion_strategy=\"device\")\n",
    "x = torch.tensor([0.1])\n",
    "print(drawer(x))\n",
    "\n",
    "drawer = qml.draw(model2.qnode, show_all_wires=True, expansion_strategy=\"device\")\n",
    "x = torch.tensor([0.1])\n",
    "print(drawer(x))\n",
    "\n",
    "nump = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Number of parameters: \", nump)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_values = torch.linspace(-1.5, 2.5, steps=100, dtype=torch.float64).reshape(-1, 1)\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_values = model2(x_values)\n",
    "\n",
    "# Convert to numpy for plotting\n",
    "x_values_np = x_values.numpy()\n",
    "y_values_np = y_values.squeeze().numpy()\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(x_values_np, y_values_np, label=\"model\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"model(x)\")\n",
    "plt.title(\"Plot of the function (x, model(x))\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import torch\n",
    "\n",
    "# Generate a sample of inputs\n",
    "X = torch.linspace(-1, 1, 1000).reshape(-1, 1)\n",
    "\n",
    "\n",
    "# Define a function to add Gaussian noise\n",
    "def add_gaussian_noise(tensor, mean=0.0, std=0.01):\n",
    "    return tensor + torch.randn(tensor.size()) * std + mean\n",
    "\n",
    "\n",
    "# 1. Linear Relationship\n",
    "def linear(X, m=2, c=3):\n",
    "    return m * X + c\n",
    "\n",
    "\n",
    "Y_linear = add_gaussian_noise(linear(X))\n",
    "\n",
    "\n",
    "# 2. Polynomial Relationship (Quadratic for demonstration)\n",
    "def polynomial(X, a=3, b=2, c=-5):\n",
    "    return a * X**2 + b * X + c\n",
    "\n",
    "\n",
    "Y_polynomial = add_gaussian_noise(polynomial(X))\n",
    "\n",
    "\n",
    "# 3. Exponential Relationship\n",
    "def exponential(X, a=2, b=0.5):\n",
    "    return a * torch.exp(b * X)\n",
    "\n",
    "\n",
    "Y_exponential = add_gaussian_noise(exponential(X))\n",
    "\n",
    "\n",
    "# 4. Logarithmic Relationship\n",
    "def logarithmic(X, a=3, b=2):\n",
    "    return a * torch.log(X) + b\n",
    "\n",
    "\n",
    "Y_logarithmic = add_gaussian_noise(logarithmic(X))\n",
    "\n",
    "\n",
    "# 5. Trigonometric Relationship\n",
    "def trigonometric(X, a=1, b=math.pi, c=0.):\n",
    "    return a * torch.sin(b * X + c)\n",
    "\n",
    "\n",
    "Y_trigonometric = add_gaussian_noise(trigonometric(X))\n",
    "\n",
    "\n",
    "# 6. Power-law Relationship\n",
    "def power_law(X, a=2, b=1.5):\n",
    "    return a * X**b\n",
    "\n",
    "\n",
    "Y_power_law = add_gaussian_noise(power_law(X))\n",
    "\n",
    "\n",
    "# 7. Sigmoidal Relationship\n",
    "def sigmoidal(X, L=1, k=0.5, x0=5):\n",
    "    return L / (1 + torch.exp(-k * (X - x0)))\n",
    "\n",
    "\n",
    "Y_sigmoidal = add_gaussian_noise(sigmoidal(X))\n",
    "\n",
    "\n",
    "# 8. Gaussian Relationship\n",
    "def gaussian(X, a=1.0, b=0, c=1):\n",
    "    return a * torch.exp(-((X - b) ** 2) / (2 * c**2))\n",
    "\n",
    "\n",
    "Y_gaussian = add_gaussian_noise(gaussian(X))\n",
    "\n",
    "\n",
    "# 9. Step Function\n",
    "def step_function(\n",
    "    X, threshold1=-1.0, threshold2=0.0, low_value=0.0, mid_value=2, high_value=-1.0\n",
    "):\n",
    "    condition1 = X < threshold1\n",
    "    condition2 = (X >= threshold1) & (X < threshold2)\n",
    "    condition3 = X >= threshold2\n",
    "\n",
    "    values = torch.zeros_like(X)\n",
    "    values[condition1] = low_value\n",
    "    values[condition2] = mid_value\n",
    "    values[condition3] = high_value\n",
    "\n",
    "    return values\n",
    "\n",
    "\n",
    "Y_step = add_gaussian_noise(step_function(X))\n",
    "\n",
    "\n",
    "def piecewise_linear_3segments(X, a=-0.714, b=0.143, m1=2, c1=0, m2=-3, m3=1):\n",
    "    # Define linear functions for each segment\n",
    "    linear_before_a = m1 * X + c1\n",
    "    linear_between_a_b = m1 * a + c1 + m2 * (X - a)\n",
    "    linear_after_b = m1 * a + c1 + m2 * (b - a) + m3 * (X - b)\n",
    "\n",
    "    # Apply conditions for each segment\n",
    "    conditions = [(X < a), (X >= a) & (X < b), (X >= b)]\n",
    "    functions = [linear_before_a, linear_between_a_b, linear_after_b]\n",
    "\n",
    "    output = torch.zeros_like(X)\n",
    "    for condition, function in zip(conditions, functions):\n",
    "        output[condition] = function[condition]\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "Y_piecewise_spiked = add_gaussian_noise(piecewise_linear_3segments(X))\n",
    "\n",
    "\n",
    "def multidimstep(X, a=1.0):\n",
    "    # Extract the first and second features\n",
    "    X0 = X[:, 0]\n",
    "    X1 = X[:, 1]\n",
    "\n",
    "    # Check the condition X[1] > a * X[0]\n",
    "    condition = X1 > a * X0\n",
    "\n",
    "    # Initialize the output tensor Y\n",
    "    Y = torch.zeros_like(X1)\n",
    "\n",
    "    # Set Y values based on the condition\n",
    "    Y[condition] = 1  # Set to +1 where condition is True\n",
    "    Y[~condition] = -1  # Set to -1 where condition is False\n",
    "\n",
    "    return Y.view(-1, 1)  # Reshape to make it a column vector\n",
    "\n",
    "\n",
    "def high_low(X, low=1.0, high=30.0):\n",
    "    return torch.sin(low * X) + 0.5 * torch.sin(high * X)\n",
    "\n",
    "\n",
    "Y_high_low = add_gaussian_noise(high_low(X))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create the scatter plot\n",
    "#func = step_function\n",
    "func = trigonometric\n",
    "sigma = 0.0\n",
    "Y = add_gaussian_noise(func(X), std=sigma)\n",
    "plt.plot(X, Y)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import torch\n",
    "import logging\n",
    "from torch.optim import Adam\n",
    "from qulearn.trainer import SupervisedTrainer\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Data\n",
    "N_train = 50\n",
    "N_valid = 5\n",
    "batch_size = 10\n",
    "X_train = torch.linspace(-1, 1, N_train, dtype=torch.float64).reshape(-1, 1)\n",
    "Y_train = add_gaussian_noise(func(X_train), std=sigma)\n",
    "X_valid = torch.linspace(-1, 1, N_valid, dtype=torch.float64).reshape(-1, 1)\n",
    "Y_valid = func(X_valid)\n",
    "data_train = TensorDataset(X_train, Y_train)\n",
    "data_valid = TensorDataset(X_valid, Y_valid)\n",
    "loader_train = DataLoader(data_train, batch_size=batch_size, shuffle=False)\n",
    "loader_valid = DataLoader(data_valid, batch_size=batch_size, shuffle=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import torch\n",
    "import logging\n",
    "from torch.optim import Adam, LBFGS\n",
    "from qulearn.trainer import SupervisedTrainer\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchmetrics.regression import MeanAbsolutePercentageError\n",
    "\n",
    "# Trainer\n",
    "lr = 0.1\n",
    "optimizer = Adam(model.parameters(), lr=lr, amsgrad=True)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "metric = MeanAbsolutePercentageError()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "logger = logging.getLogger(\"train_function\")\n",
    "logger.setLevel(level=logging.INFO)\n",
    "num_epochs = 100\n",
    "trainer = SupervisedTrainer(\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=loss_fn,\n",
    "    metrics={\"MARE\": metric},\n",
    "    num_epochs=num_epochs,\n",
    "    logger=logger,\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Train\n",
    "trainer.train(model, train_data=loader_train, valid_data=loader_valid)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plotting\n",
    "X = torch.linspace(-1, 1, 300, dtype=torch.float64).reshape(-1, 1)\n",
    "Y_exact = func(X)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    Y_model = model(X)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(X, Y_exact, label=\"exact\", color=\"blue\")\n",
    "plt.plot(X, Y_model, label=\"predicted\", color=\"red\")\n",
    "\n",
    "# Adding title and labels\n",
    "plt.title(\"Exact vs. Model\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define purely complex numbers for the off-diagonal elements\n",
    "nums = np.random.randn(6)\n",
    "a = 0 + nums[0]*1j   # Example: purely imaginary number with imaginary part 1\n",
    "b = 0 +nums[1]*1j   # Example: purely imaginary number with imaginary part 2\n",
    "c = 0 +nums[2]*1j   # Example: purely imaginary number with imaginary part 3\n",
    "d = 0 +nums[3]*1j   # Example: purely imaginary number with imaginary part 4\n",
    "e = 0 +nums[4]*1j   # Example: purely imaginary number with imaginary part 5\n",
    "f = 0 +nums[5]*1j   # Example: purely imaginary number with imaginary part 6\n",
    "\n",
    "# Define your Hermitian matrix\n",
    "H = np.array([[ 1,    a,    b,    c ],\n",
    "              [ np.conj(a), 0,    d,    e ],\n",
    "              [ np.conj(b), np.conj(d), 0,    f ],\n",
    "              [ np.conj(c), np.conj(e), np.conj(f), -1 ]])\n",
    "\n",
    "# Diagonalize the matrix\n",
    "eigenvalues, eigenvectors = np.linalg.eigh(H)\n",
    "\n",
    "# Print the eigenvalues\n",
    "print(\"Matrix:\", H)\n",
    "print(\"Eigenvalues:\", eigenvalues)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import scipy.optimize\n",
    "\n",
    "def generate_random_hermitian(n, specified_diagonal):\n",
    "    # Create a matrix with random complex entries\n",
    "    H = np.random.randn(n, n) + 1j * np.random.randn(n, n)\n",
    "    # Make the matrix Hermitian\n",
    "    H = (H + H.conj().T) / 2\n",
    "    # Set the specified diagonal entries\n",
    "    np.fill_diagonal(H, specified_diagonal)\n",
    "    return H\n",
    "\n",
    "def generate_random_unitary(n):\n",
    "    # Generate a random nxn matrix\n",
    "    X = np.random.randn(n, n) + 1j * np.random.randn(n, n)\n",
    "    # Perform QR decomposition to get a unitary matrix\n",
    "    Q, R = np.linalg.qr(X)\n",
    "    return Q\n",
    "\n",
    "def cost_function(U_flat, A, D_diagonal):\n",
    "    U = U_flat.reshape(A.shape)\n",
    "    transformed_matrix = np.dot(U.conj().T, np.dot(A, U))\n",
    "    # Only compare diagonal elements\n",
    "    cost = np.sum((np.diag(transformed_matrix) - D_diagonal)**2)\n",
    "    return cost\n",
    "\n",
    "def flatten_unitary_and_hermitian(U, D):\n",
    "    # Flatten U\n",
    "    U_flat = U.flatten()\n",
    "    # Flatten upper triangular part of D (excluding diagonal)\n",
    "    D_upper_flat = D[np.triu_indices_from(D, k=1)]\n",
    "    return np.concatenate([U_flat, D_upper_flat])\n",
    "\n",
    "def reconstruct_unitary_and_hermitian(x, n):\n",
    "    # Reconstruct U\n",
    "    U = x[:n**2].reshape((n, n))\n",
    "    # Reconstruct D\n",
    "    D = np.zeros((n, n), dtype=complex)\n",
    "    D[np.triu_indices_from(D, k=1)] = x[n**2:]\n",
    "    D += D.conj().T\n",
    "    np.fill_diagonal(D, specified_diagonal)\n",
    "    return U, D\n",
    "\n",
    "def cost_function(x, A, n):\n",
    "    U, D = reconstruct_unitary_and_hermitian(x, n)\n",
    "    transformed_matrix = np.dot(U.conj().T, np.dot(A, U))\n",
    "    return np.linalg.norm(transformed_matrix - D, 'fro')\n",
    "\n",
    "# Example: 4x4 matrix\n",
    "n = 4\n",
    "A = np.diag([3, -1, 2, 4])  # Your specified diagonal matrix\n",
    "specified_diagonal = np.array([1, 1, -1, -1])  # Specified diagonal entries of D\n",
    "\n",
    "# Initial guess for U and D\n",
    "U_initial = generate_random_unitary(n)\n",
    "D_initial = generate_random_hermitian(n, specified_diagonal)\n",
    "x_initial = flatten_unitary_and_hermitian(U_initial, D_initial)\n",
    "\n",
    "# Optimize\n",
    "result = scipy.optimize.minimize(cost_function, x_initial, args=(A, n), method='BFGS')\n",
    "\n",
    "# Check the result\n",
    "if result.success:\n",
    "    U_optimal, D_optimal = reconstruct_unitary_and_hermitian(result.x, n)\n",
    "    print(\"Found a unitary matrix U:\")\n",
    "    print(U_optimal)\n",
    "    print(\"Resulting Hermitian matrix D:\")\n",
    "    print(D_optimal)\n",
    "else:\n",
    "    print(\"Optimization failed.\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import sympy as sp\n",
    "\n",
    "# Define the symbolic complex variables\n",
    "c1, c2, c3, c4, c5, c6 = sp.symbols('c1 c2 c3 c4 c5 c6', complex=True)\n",
    "c1 = 1j\n",
    "c2 = 0.0\n",
    "c3 = 0.0\n",
    "c4 = 0.0\n",
    "c5 = 0.0\n",
    "c6 = 0.0\n",
    "\n",
    "# Construct the Hermitian matrix\n",
    "H = sp.Matrix([[1, c1, c2, c3],\n",
    "               [sp.conjugate(c1), 0, c4, c5],\n",
    "               [sp.conjugate(c2), sp.conjugate(c4), 0, c6],\n",
    "               [sp.conjugate(c3), sp.conjugate(c5), sp.conjugate(c6), -1]])\n",
    "\n",
    "# Diagonalize the matrix and compute eigenvalues\n",
    "eigenvalues = H.eigenvals()\n",
    "\n",
    "# Output the eigenvalues\n",
    "print(eigenvalues)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the numerical values for c1 to c6\n",
    "c1 = complex(0, 0)  # Example: 1 + 2j\n",
    "c2 = complex(0, 0)  # Example: 3 + 4j\n",
    "c3 = complex(0, 0)  # Example: 5 + 6j\n",
    "c4 = complex(0, 1)  # Example: 7 + 8j\n",
    "c5 = complex(0, 0) # Example: 9 + 10j\n",
    "c6 = complex(0, 0)# Example: 11 + 12j\n",
    "\n",
    "# Construct the numerical matrix\n",
    "H_num = np.array([[1, c1, c2, c3],\n",
    "                  [np.conj(c1), 0, c4, c5],\n",
    "                  [np.conj(c2), np.conj(c4), 0, c6],\n",
    "                  [np.conj(c3), np.conj(c5), np.conj(c6), -1]])\n",
    "\n",
    "# Compute eigenvalues and eigenvectors\n",
    "eigenvalues, eigenvectors = np.linalg.eig(H_num)\n",
    "\n",
    "# Output the eigenvalues and eigenvectors\n",
    "print(\"Eigenvalues:\", np.real(eigenvalues))\n",
    "print(\"Eigenvectors:\", eigenvectors)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def objective_function(c):\n",
    "    # Construct the matrix\n",
    "    H = np.array([[1, complex(0, c[0]), complex(0, c[1]), complex(0, c[2])],\n",
    "                  [complex(0, -c[0]), 0, complex(0, c[3]), complex(0, c[4])],\n",
    "                  [complex(0, -c[1]), complex(0, -c[3]), 0, complex(0, c[5])],\n",
    "                  [complex(0, -c[2]), complex(0, -c[4]), complex(0, -c[5]), -1]])\n",
    "\n",
    "    # Compute eigenvalues and eigenvectors\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(H)\n",
    "\n",
    "    # Sort the eigenvalues in descending order and reorder eigenvectors\n",
    "    idx = eigenvalues.argsort()[::-1]\n",
    "    eigenvalues_sorted = eigenvalues[idx]\n",
    "    eigenvectors_sorted = eigenvectors[:,idx]\n",
    "\n",
    "    # Compute the error compared to target eigenvalues\n",
    "    target_eigenvalues = [1, 1, -1, -1]\n",
    "    error = sum((eigenvalues_sorted - target_eigenvalues)**2)\n",
    "\n",
    "    return error\n",
    "\n",
    "def returnU(c):\n",
    "    # Construct the matrix\n",
    "    H = np.array([[1, complex(0, c[0]), complex(0, c[1]), complex(0, c[2])],\n",
    "                  [complex(0, -c[0]), 0, complex(0, c[3]), complex(0, c[4])],\n",
    "                  [complex(0, -c[1]), complex(0, -c[3]), 0, complex(0, c[5])],\n",
    "                  [complex(0, -c[2]), complex(0, -c[4]), complex(0, -c[5]), -1]])\n",
    "\n",
    "    # Compute eigenvalues and eigenvectors\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(H)\n",
    "\n",
    "    # Sort the eigenvalues in descending order and reorder eigenvectors\n",
    "    idx = eigenvalues.argsort()[::-1]\n",
    "    eigenvalues_sorted = eigenvalues[idx]\n",
    "    eigenvectors_sorted = eigenvectors[:,idx]\n",
    "\n",
    "    return eigenvectors_sorted\n",
    "\n",
    "\n",
    "# Initial guesses for the imaginary parts of c1 to c6\n",
    "initial_guesses = [0, 0, 0, 0, 0, 0]\n",
    "objective_function(initial_guesses)\n",
    "\n",
    "# Perform the optimization\n",
    "result = minimize(objective_function, initial_guesses, method='BFGS')\n",
    "\n",
    "# Output the optimized values\n",
    "optimized_c = result.x\n",
    "print(\"Optimized values for the imaginary parts of c1 to c6:\", optimized_c)\n",
    "print(\"Cost value:\", result.fun)\n",
    "U = returnU(optimized_c)\n",
    "check = np.dot(U.conj().T, U)\n",
    "print(\"Unitary:\", U)\n",
    "print(\"Check:\", check)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def construct_matrix(c):\n",
    "    # Initialize an 8x8 matrix with zeros\n",
    "    H = np.zeros((8, 8), dtype=complex)\n",
    "\n",
    "    # Set the diagonal elements\n",
    "    np.fill_diagonal(H, [1, 1, 0, 0, 0, 0, -1, -1])\n",
    "\n",
    "    # Counter for c elements\n",
    "    counter = 0\n",
    "\n",
    "    # Fill the upper triangle of the matrix\n",
    "    for i in range(8):\n",
    "        for j in range(i+1, 8):\n",
    "            H[i, j] = complex(0, c[counter])\n",
    "            counter += 1\n",
    "\n",
    "    # Fill the lower triangle with the conjugate\n",
    "    H = H + H.conj().T - np.diag(H.diagonal())\n",
    "\n",
    "    return H\n",
    "\n",
    "def objective_function(c):\n",
    "    # Construct the matrix\n",
    "    H = construct_matrix(c)\n",
    "\n",
    "    # Compute eigenvalues\n",
    "    eigenvalues = np.linalg.eigvalsh(H)\n",
    "\n",
    "    # Sort the eigenvalues in descending order\n",
    "    eigenvalues_sorted = np.sort(eigenvalues)[::-1]\n",
    "\n",
    "    # Target eigenvalues\n",
    "    target_eigenvalues = [1, 1, 1, 1, -1, -1, -1, -1]\n",
    "\n",
    "    # Sum of squared differences from the target eigenvalues\n",
    "    error = np.sum((eigenvalues_sorted - target_eigenvalues)**2)\n",
    "\n",
    "    return error\n",
    "\n",
    "# Initial guesses for the imaginary parts of c1 to c28\n",
    "initial_guesses = np.ones(28)\n",
    "\n",
    "# Perform the optimization\n",
    "result = minimize(objective_function, initial_guesses, method='BFGS')\n",
    "\n",
    "# Optimized values\n",
    "optimized_c = result.x\n",
    "print(\"Optimized values for the imaginary parts of c1 to c28:\", optimized_c)\n",
    "print(\"Cost value:\", result.fun)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "H = construct_matrix(optimized_c)\n",
    "print(H)\n",
    "eigs, U = np.linalg.eigh(H)\n",
    "print(eigs)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pennylane as qml\n",
    "from scipy.stats import unitary_group\n",
    "\n",
    "num_qubits = 5\n",
    "\n",
    "def generate_random_unitary(n):\n",
    "    matrix_size = 2 ** n\n",
    "    unitary_matrix = unitary_group.rvs(matrix_size)\n",
    "    return unitary_matrix\n",
    "\n",
    "# Example usage\n",
    "U1 = generate_random_unitary(num_qubits)\n",
    "U2 = generate_random_unitary(num_qubits)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "source": [
    "import pennylane as qml\n",
    "\n",
    "@qml.qnode(qml.device('default.qubit', wires=range(num_qubits+1)), interface=\"torch\")\n",
    "def innerp_circuit(U1, U2):\n",
    "    qml.Hadamard(0)\n",
    "    qml.ControlledQubitUnitary(U1, control_wires=[0], wires=range(1, num_qubits+1))\n",
    "    qml.PauliX(0)\n",
    "    qml.ControlledQubitUnitary(U2, control_wires=[0], wires=range(1, num_qubits+1))\n",
    "    qml.Hadamard(0)\n",
    "    \n",
    "    return qml.expval(qml.PauliZ(0))\n",
    "\n",
    "def Uf(num_qubits):\n",
    "    qml.PauliX(0)\n",
    "    for idx in range(num_qubits):\n",
    "        qml.Hadamard(wires=idx)\n",
    "\n",
    "def psi(initlayer_weights, weights, num_qubits, num_layers):\n",
    "    wires = list(range(num_qubits))\n",
    "    for i, q in enumerate(wires):\n",
    "        qml.RY(initlayer_weights[i], q)\n",
    "    \n",
    "    for layer in range(num_layers):\n",
    "        for i in range(0, len(wires) - 1, 2):\n",
    "            qml.CZ(wires=[wires[i], wires[i + 1]])\n",
    "            qml.RY(\n",
    "                weights[layer, i],\n",
    "                wires[i],\n",
    "            )\n",
    "            qml.RY(\n",
    "                weights[layer, i + 1],\n",
    "                wires[i + 1],\n",
    "            )\n",
    "\n",
    "        offset = int(num_qubits / 2) * 2\n",
    "        for i in range(1, len(wires) - 1, 2):\n",
    "            qml.CZ(wires=[wires[i], wires[i + 1]])\n",
    "            qml.RY(\n",
    "                weights[layer, offset + i - 1],\n",
    "                wires[i],\n",
    "            )\n",
    "            qml.RY(\n",
    "                weights[layer, offset + i],\n",
    "                wires[i + 1],\n",
    "            )\n",
    "            \n",
    "@qml.qnode(qml.device('default.qubit', wires=range(num_qubits)), interface=\"torch\")\n",
    "def Aeven(initlayer_weights, weights, num_qubits, num_layers):\n",
    "    psi(initlayer_weights, weights, num_qubits, num_layers)\n",
    "    qml.Hadamard(num_qubits-1)\n",
    "    return qml.expval(qml.PauliZ(num_qubits-1))\n",
    "\n",
    "@qml.qnode(qml.device('default.qubit', wires=range(num_qubits)), interface=\"torch\")\n",
    "def Aodd_IX(initlayer_weights, weights, num_qubits, num_layers):\n",
    "    psi(initlayer_weights, weights, num_qubits, num_layers)\n",
    "    for idx in range(1, num_qubits):\n",
    "        ctrl_wires = list(range(idx, num_qubits))\n",
    "        qml.ctrl(qml.PauliX, control=ctrl_wires)(idx-1)\n",
    "        \n",
    "    qml.PauliX(num_qubits-1)\n",
    "    qml.Hadamard(num_qubits-1)\n",
    "    return qml.expval(qml.PauliZ(num_qubits-1))\n",
    "\n",
    "@qml.qnode(qml.device('default.qubit', wires=range(num_qubits)), interface=\"torch\")\n",
    "def Aodd_I0X(initlayer_weights, weights, num_qubits, num_layers):\n",
    "    psi(initlayer_weights, weights, num_qubits, num_layers)\n",
    "    for idx in range(1, num_qubits):\n",
    "        ctrl_wires = list(range(idx, num_qubits))\n",
    "        qml.ctrl(qml.PauliX, control=ctrl_wires)(idx-1)\n",
    "        \n",
    "    qml.PauliX(num_qubits-1)\n",
    "    qml.Hadamard(num_qubits-1)\n",
    "    I0 = qml.Projector(basis_state=[0]*(num_qubits-1), wires=list(range(0, num_qubits-1)))   \n",
    "    return qml.expval(I0 @ qml.PauliZ(num_qubits-1))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "source": [
    "import pennylane as qml\n",
    "import torch\n",
    "\n",
    "num_layers = 3\n",
    "def cost_poisson(initlayer_weights, weights):\n",
    "    Uf_mat = qml.matrix(Uf)(num_qubits)\n",
    "    Upsi_mat = qml.matrix(psi)(initlayer_weights, weights, num_qubits, num_layers)\n",
    "    innerp = innerp_circuit(Uf_mat, Upsi_mat)\n",
    "    \n",
    "    even = Aeven(initlayer_weights, weights, num_qubits, num_layers)\n",
    "    odd_IX = Aodd_IX(initlayer_weights, weights, num_qubits, num_layers)\n",
    "    odd_I0X = Aodd_I0X(initlayer_weights, weights, num_qubits, num_layers)\n",
    " \n",
    "    op = 2.0-even-odd_IX+odd_I0X\n",
    "    cost = -0.5*innerp**2/op\n",
    "    \n",
    "    return cost\n",
    "    \n",
    "initlayer_weights = torch.randn(num_qubits, requires_grad=True)\n",
    "weights = torch.randn(num_layers, 2*(num_qubits-1), requires_grad=True)\n",
    "cost = cost_poisson(initlayer_weights, weights)\n",
    "print(initlayer_weights.requires_grad)\n",
    "print(cost.requires_grad)\n",
    "print(cost)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "source": [
    "import torch\n",
    "steps = 100\n",
    "opt = torch.optim.Adam([initlayer_weights, weights], lr = 0.1)\n",
    "\n",
    "def closure():\n",
    "    opt.zero_grad()\n",
    "    loss = cost_poisson(initlayer_weights, weights)\n",
    "    loss.backward()\n",
    "    return loss\n",
    "\n",
    "for it in range(steps):\n",
    "    opt.step(closure)\n",
    "    cost = cost_poisson(initlayer_weights, weights)\n",
    "    print(\"Step {:3d}       cost = {:9.7f}\".format(it, cost))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "source": [
    "import pennylane as qml\n",
    "\n",
    "@qml.qnode(qml.device('default.qubit', wires=range(num_qubits)), interface=\"torch\")\n",
    "def extract_psi(initlayer_weights, weights, num_qubits, num_layers):\n",
    "    psi(initlayer_weights, weights, num_qubits, num_layers)\n",
    "    return qml.state()\n",
    "\n",
    "psi_vec = -extract_psi(initlayer_weights, weights, num_qubits, num_layers)\n",
    "print(psi_vec)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "source": [
    "import pennylane as qml\n",
    "import numpy as np\n",
    "def eval_basis(x, Upsi, num_qubits):\n",
    "    h = 2.0/(2**num_qubits+1)\n",
    "    a = -1.0+h\n",
    "    b = 1.0-h\n",
    "    basis = Linear1DFEMEmbedding(num_qubits, a=a, b=b, sqrt=False, normalize=True)\n",
    "    norm = basis.compute_norm(x)\n",
    "    Ubasis = qml.matrix(basis.circuit, wire_order=list(range(num_qubits)))(x)\n",
    "    result = norm*innerp_circuit(Ubasis, Upsi)\n",
    "    \n",
    "    @qml.qnode(qml.device('default.qubit', wires=range(num_qubits)), interface=\"torch\")\n",
    "    def test():\n",
    "        basis.circuit(x)\n",
    "        return qml.state()\n",
    "    trial = test()\n",
    "    print(\"x\", x)\n",
    "    #print(\"norm\", norm)\n",
    "    print(\"state\", trial)\n",
    "    drawer = qml.draw(test, show_all_wires=True, expansion_strategy=\"device\")\n",
    "    print(drawer())\n",
    "    print(\"==============\")\n",
    "    \n",
    "    N = 2**num_qubits\n",
    "    zero = np.zeros(N)\n",
    "    zero[0] = 1\n",
    "    psi = np.dot(Upsi.detach().numpy(), zero)\n",
    "    Ub = np.dot(Ubasis, zero)\n",
    "    \n",
    "    #print(\"x =\", x)\n",
    "    #print(\"psi\", psi)\n",
    "    #print(\"Basis\", Ub)\n",
    "    \n",
    "    return result"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from scipy.sparse import diags\n",
    "from scipy.linalg import solve\n",
    "import pennylane as qml\n",
    "\n",
    "# Define the size of the matrix\n",
    "N = 2**num_qubits       \n",
    "\n",
    "# Create the tridiagonal matrix A\n",
    "diagonals = [[-1]*(N-1), [2]*N, [-1]*(N-1)]\n",
    "A = diags(diagonals, offsets=[-1, 0, 1]).toarray()\n",
    "\n",
    "# Create the right-hand side vector b\n",
    "b = np.ones(N)\n",
    "b[int(N/2):] *= -1\n",
    "b /= math.sqrt(N)                                                                    \n",
    "\n",
    "# Solve Ax = b\n",
    "u = solve(A, b)\n",
    "u /= np.linalg.norm(u)\n",
    "# Create discrete points x_k\n",
    "x_k = np.linspace(-1, 1, N+2)\n",
    "ub = np.zeros(N+2)\n",
    "ub[1:-1] = u\n",
    "\n",
    "# quantum\n",
    "ubq = torch.zeros(N+2)\n",
    "ubq[1:-1] = psi_vec\n",
    "\n",
    "# Plotting\n",
    "plt.plot(x_k, ub, 'o-', label=\"exact\")\n",
    "plt.plot(x_k, ubq.detach().numpy(), 'd-', label=\"quantum\")\n",
    "\n",
    "\n",
    "xk = torch.linspace(-1.0, 1.0, steps=10, dtype=torch.float64).reshape(-1, 1)\n",
    "yk = torch.zeros_like(xk)\n",
    "Upsi = qml.matrix(psi, wire_order=list(range(num_qubits)))(initlayer_weights, weights, num_qubits, num_layers)\n",
    "for i, x in enumerate(xk):\n",
    "    yk[i] = -eval_basis(x, Upsi, num_qubits)\n",
    "    \n",
    "plt.plot(xk, yk.detach().numpy(), 'H-', label=\"quantum eval\")\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Solution values')\n",
    "plt.title('Solution of Au = b on the Interval [-1, 1]')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "source": [
    "x = psi_vec.detach().numpy()\n",
    "innerp_exact = np.dot(x, b)\n",
    "\n",
    "Uf_mat = qml.matrix(Uf)(num_qubits)\n",
    "Upsi_mat = qml.matrix(psi)(initlayer_weights, weights, num_qubits, num_layers)\n",
    "innerp_quantum = innerp_circuit(Uf_mat, Upsi_mat)\n",
    "\n",
    "print(innerp_exact)\n",
    "print(innerp_quantum.item())\n",
    "print(\"=====================\")\n",
    "\n",
    "xAx_exact = np.dot(x, np.dot(A, x))\n",
    "\n",
    "even = Aeven(initlayer_weights, weights, num_qubits, num_layers)\n",
    "odd_IX = Aodd_IX(initlayer_weights, weights, num_qubits, num_layers)\n",
    "odd_I0X = Aodd_I0X(initlayer_weights, weights, num_qubits, num_layers)\n",
    "xAx_quantum = 2.0-even-odd_IX+odd_I0X\n",
    "print(xAx_exact)\n",
    "print(xAx_quantum.item())\n",
    "print(\"=====================\")\n",
    "\n",
    "X = np.array([[0, 1], [1, 0]])\n",
    "I = np.eye(2**(n-1))\n",
    "IX = np.kron(I, X)\n",
    "exact = np.dot(x, np.dot(IX, x))\n",
    "quantum = even\n",
    "print(exact)\n",
    "print(quantum.item())\n",
    "print(\"=====================\")\n",
    "\n",
    "size = 2**num_qubits\n",
    "Odd = np.zeros((size, size))\n",
    "\n",
    "# Set the off-diagonal entries\n",
    "for i in range(1, size):\n",
    "    if i % 2 != 1:\n",
    "        Odd[i, i-1] = -1\n",
    "        Odd[i-1, i] = -1\n",
    "\n",
    "# Set the last element of the first row and first element of the last row\n",
    "Odd[0, -1] = -1\n",
    "Odd[-1, 0] = -1\n",
    "\n",
    "exact = np.dot(x, np.dot(-Odd, x))\n",
    "quantum = odd_IX\n",
    "print(exact)\n",
    "print(quantum.item())"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QuLearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
